{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJQncnNRmwK_",
        "outputId": "7e00d264-148e-47a9-dd1b-b62f790cc8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.17 MiB | 8.79 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 251, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 251 (delta 3), reused 2 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (251/251), 8.93 MiB | 14.30 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n",
            "Cloning into 'BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 277 (delta 137), reused 136 (delta 135), pack-reused 112\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.03 MiB | 13.80 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Collecting torch==2.1.2\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2\n",
            "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.2\n",
            "  Downloading torchaudio-2.1.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja==1.11.1.1\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (9.4.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "Installing collected packages: ninja, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.17.1+cu121\n",
            "    Uninstalling torchvision-0.17.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.17.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.2.1+cu121\n",
            "    Uninstalling torchaudio-2.2.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 torchaudio-2.1.2 torchvision-0.16.2 triton-2.1.0\n",
            "Collecting ftfy==6.1.3\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (2023.12.25)\n",
            "Collecting tqdm==4.66.2\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.1.3) (0.2.13)\n",
            "Installing collected packages: tqdm, ftfy\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ftfy-6.1.3 tqdm-4.66.2\n",
            "Collecting transformers==4.19.4\n",
            "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm==0.9.16\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale==0.4.13\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.4)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.19.4) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm==0.9.16) (2.1.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.9.16) (0.16.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.16) (0.4.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.4) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.4) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm==0.9.16) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm==0.9.16) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.19.4) (2024.2.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.16) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm==0.9.16) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm==0.9.16) (1.3.0)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=7bac8d2e7f610dc0bce7fbb5f4b8f227aa0f554121638dec21693b5bfd1d7708\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "Successfully built fairscale\n",
            "Installing collected packages: tokenizers, transformers, fairscale, timm\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "Successfully installed fairscale-0.4.13 timm-0.9.16 tokenizers-0.12.1 transformers-4.19.4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hfVAbs5nkXcUpG6FCAafid7F7ZsqRRkk\n",
            "To: /content/test.png\n",
            "100% 350k/350k [00:00<00:00, 6.49MB/s]\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    93    0    93    0     0    344      0 --:--:-- --:--:-- --:--:--   344\n",
            "100  347M  100  347M    0     0  43.2M      0  0:00:08  0:00:08 --:--:-- 51.6M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  337M  100  337M    0     0  46.8M      0  0:00:07  0:00:07 --:--:-- 51.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2017M  100 2017M    0     0   170M      0  0:00:11  0:00:11 --:--:--  159M\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1JtRIbZDuZlBEA6vp870eW3ei0r32uYqF\n",
            "From (redirected): https://drive.google.com/uc?id=1JtRIbZDuZlBEA6vp870eW3ei0r32uYqF&confirm=t&uuid=2e02adac-43e4-42c4-8469-44f6c55e5b40\n",
            "To: /content/dataset.zip\n",
            "100% 852M/852M [00:05<00:00, 152MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Clone the repositories\n",
        "!git clone https://github.com/NVlabs/stylegan3\n",
        "!git clone https://github.com/openai/CLIP\n",
        "!git clone https://github.com/salesforce/BLIP\n",
        "# Install the requirements\n",
        "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 ninja==1.11.1.1\n",
        "!pip install ftfy==6.1.3 regex==2023.12.25 tqdm==4.66.2\n",
        "!pip install transformers==4.19.4 timm==0.9.16 fairscale==0.4.13\n",
        "# Download the pre-trained models\n",
        "!mkdir pretrained_models\n",
        "!gdown -O test.png https://drive.google.com/uc?id=1hfVAbs5nkXcUpG6FCAafid7F7ZsqRRkk\n",
        "!curl -L --output pretrained_models/stylegan2-ffhq-512x512.pkl 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/research/stylegan2/1/files?redirect=true&path=stylegan2-ffhq-512x512.pkl'\n",
        "!curl -L --output pretrained_models/ViT-B-32.pt 'https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt'\n",
        "!curl -L --output pretrained_models/model_base_capfilt_large.pth https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# Download dataset:\n",
        "!gdown -O dataset.zip https://drive.google.com/uc?id=1JtRIbZDuZlBEA6vp870eW3ei0r32uYqF\n",
        "# https://drive.google.com/file/d/1JtRIbZDuZlBEA6vp870eW3ei0r32uYqF/view?usp=sharing\n",
        "!unzip -q dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vcGH2mCkC5Vj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import sys\n",
        "import CLIP.clip.clip as clip\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "sys.path.append('BLIP') # a folder BLIP is in the same directory as this notebook\n",
        "from BLIP.models.blip import blip_decoder # to use class in: pwd/BLIP/models/blip.py\n",
        "#### ENCODER\n",
        "class TextToLatentEncoder2(nn.Module):\n",
        "    def __init__(self, input_dim=512, output_dim=512):\n",
        "        super(TextToLatentEncoder, self).__init__()\n",
        "        # Initialize network layers\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 256)\n",
        "        self.fc4 = nn.Linear(256, 512)\n",
        "        self.fc5 = nn.Linear(512, 1024)\n",
        "        self.fc6 = nn.Linear(1024, 2048)\n",
        "        self.fc7 = nn.Linear(2048, 8192)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc5(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc6(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc7(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class TextToLatentEncoder123(nn.Module):\n",
        "    def __init__(self, input_dim=512, output_dim=8192):\n",
        "        super(TextToLatentEncoder, self).__init__()\n",
        "        # Initialize network layers\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.fc1 = nn.Linear(input_dim, 1024)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 2048)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc3 = nn.Linear(2048, 4096)\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc4 = nn.Linear(4096, 8192)  # Expanded to directly go to 8192 if needed\n",
        "        self.dropout4 = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class TextToLatentEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=512, output_dim=8192):\n",
        "        super(TextToLatentEncoder, self).__init__()\n",
        "        # Initialize network layers\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 1024)\n",
        "        self.in1 = nn.InstanceNorm1d(1024)  # Batch normalization for the first layer\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 2048)\n",
        "        self.in2 = nn.InstanceNorm1d(2048)  # Batch normalization for the second layer\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc3 = nn.Linear(2048, 4096)\n",
        "        self.in3 = nn.InstanceNorm1d(4096)  # Batch normalization for the third layer\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc4 = nn.Linear(4096, 8192)\n",
        "        self.in4 = nn.InstanceNorm1d(8192)  # Batch normalization for the fourth layer\n",
        "        self.dropout4 = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        #x = self.in1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        #x = self.in2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        #x = self.in3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        #x = self.in4(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# L2\n",
        "def loss_calc_l2(text_emb, z):\n",
        "  return torch.norm(text_emb - z)\n",
        "\n",
        "# L1\n",
        "def loss_calc_l1(text_emb, z):\n",
        "  return torch.sum(torch.abs(text_emb - z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6c94360be9a44ef9a7f9129731e67e2a",
            "3ece81f008934604ac7810f054cac90b",
            "edc8f770484d4d4485fde4eb64ee98c2",
            "7f2d2ba83b564483857265c48c8d1c8f",
            "d96e2d1df44f408db5c7cbaae92cbe38",
            "12b01514333e4894a15471071bced980",
            "68ed7cb983d843b58a4152ba29225723",
            "730f22de44b44814bf76d2527232804a",
            "9ea253f4e0b341528830123b528fe8b5",
            "bf73982b62634479aaf38e9837deea6a",
            "dfbe50f5921346acba386f00ffd5e3fe",
            "6606198120f04072840da5308cf2ca2f",
            "eb48ae193975454895326d029e080274",
            "95ea1267415d4d4c96ad52ac50489530",
            "b802a0b506b040659e65c3a295df789b",
            "75b91d6673214a9b8b4b426585aa282f",
            "6f7288cb3ee34ce491ce2dfebe4e4549",
            "9910724d208a449fac85118bbf7ab74f",
            "b7182068d03b46adbe0275dd41836c3b",
            "52a319263f214522835592b7b0d609c4",
            "d243ba741b594afe87e605cabf570e0b",
            "8586ab7011214b779322ef0955adb1da",
            "2d03e96f859b474ebc302ebd5dd52ca6",
            "87afe98a96eb4857b67884f0423553c5",
            "99b4efa8045d49bebe53ce58e14ad0e8",
            "82a55a9e87fe448d8ce7e05e8dcdebc9",
            "1229bab150b544cd8e904608442783b1",
            "40ea8a329c024007a8267cf20337a2e3",
            "0d56180eedc948f7a616989a91de7f26",
            "1b2c129c95b94c1fbf6c2bce855037df",
            "7570a9410ce249a9b05e29d65d5f3141",
            "4c24b2b5f2804153b56fa6b3f4b59298",
            "6dcc0d961a854397a7616a5a9a5bb155"
          ]
        },
        "collapsed": true,
        "id": "yyRKx9D7mh4q",
        "outputId": "18f4fdc3-123d-4093-8e90-501e2e5a5b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:05<00:00, 62.8MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c94360be9a44ef9a7f9129731e67e2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6606198120f04072840da5308cf2ca2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d03e96f859b474ebc302ebd5dd52ca6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reshape position embedding from 196 to 1024\n",
            "load checkpoint from pretrained_models/model_base_capfilt_large.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (synthesis): SynthesisNetwork(\n",
              "    w_dim=512, num_ws=16, img_resolution=512, img_channels=3, num_fp16_res=4\n",
              "    (b4): SynthesisBlock(\n",
              "      resolution=4, architecture=skip\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=4, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b8): SynthesisBlock(\n",
              "      resolution=8, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=8, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=8, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b16): SynthesisBlock(\n",
              "      resolution=16, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=16, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=16, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b32): SynthesisBlock(\n",
              "      resolution=32, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=32, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=32, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b64): SynthesisBlock(\n",
              "      resolution=64, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=64, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=512, out_channels=512, w_dim=512, resolution=64, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=512, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b128): SynthesisBlock(\n",
              "      resolution=128, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=512, out_channels=256, w_dim=512, resolution=128, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=512, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=256, out_channels=256, w_dim=512, resolution=128, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=256, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b256): SynthesisBlock(\n",
              "      resolution=256, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=256, out_channels=128, w_dim=512, resolution=256, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=256, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=128, out_channels=128, w_dim=512, resolution=256, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=128, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
              "      )\n",
              "    )\n",
              "    (b512): SynthesisBlock(\n",
              "      resolution=512, architecture=skip\n",
              "      (conv0): SynthesisLayer(\n",
              "        in_channels=128, out_channels=64, w_dim=512, resolution=512, up=2, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=128, activation=linear)\n",
              "      )\n",
              "      (conv1): SynthesisLayer(\n",
              "        in_channels=64, out_channels=64, w_dim=512, resolution=512, up=1, activation=lrelu\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=64, activation=linear)\n",
              "      )\n",
              "      (torgb): ToRGBLayer(\n",
              "        in_channels=64, out_channels=3, w_dim=512\n",
              "        (affine): FullyConnectedLayer(in_features=512, out_features=64, activation=linear)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mapping): MappingNetwork(\n",
              "    z_dim=512, c_dim=0, w_dim=512, num_ws=16\n",
              "    (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc2): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc3): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc4): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc5): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc6): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "    (fc7): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "sys.path.append('stylegan3')  # assuming stylegan3 is in the same directory as this notebook\n",
        "\n",
        "# Load the StyleGAN model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "with open('pretrained_models/stylegan2-ffhq-512x512.pkl', 'rb') as f:\n",
        "    G = pickle.load(f)['G_ema'].to(device)  # Load pretrained StyleGAN model - SYNTHESIS\n",
        "    G.eval()  # Set StyleGAN to eval mode\n",
        "\n",
        "# Load the CLIP model\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "\n",
        "### BLIP\n",
        "blip_model_url = 'pretrained_models/model_base_capfilt_large.pth'\n",
        "med_config_path = os.getcwd() + '/BLIP/configs/med_config.json'\n",
        "blip_model = blip_decoder(pretrained=blip_model_url, image_size=512, vit='base', med_config = med_config_path)\n",
        "#blip_model.eval()\n",
        "blip_model = blip_model.to(device)\n",
        "\n",
        "\n",
        "encoder = TextToLatentEncoder(input_dim=512, output_dim=G.z_dim).to(device)\n",
        "encoder.float()  # Ensure the encoder uses Float dtype\n",
        "optimizer = optim.Adam(encoder.parameters(), lr=0.0005)\n",
        "\n",
        "# Ensure all components are converted to float before training\n",
        "encoder = encoder.float()\n",
        "G = G.float()\n",
        "clip_model = clip_model.float()\n",
        "encoder.train()\n",
        "G.eval()\n",
        "\n",
        "\n",
        "### CLIP\n",
        "\n",
        "  #z = torch.randn([1, G.z_dim]).to(device\n",
        "\n",
        "  #Encoder(text_embedding) ->\n",
        "\n",
        "  #ABC(text) -> CLIP(text) -> Encoder(text_embeddibg): returns z*/w* -> |z*-z| (styleGAN(z/W) return: image/latent_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ulgEpMhh7I7Z",
        "outputId": "a726ff79-878f-4798-8d1f-2a6c8fa2cc5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape is: (2048, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    name                                     caption\n",
              "0  00001                   a man with a black jacket\n",
              "1  00002  a young child with a very look on his face\n",
              "2  00003        a woman with a big smile on her face\n",
              "3  00004                      a man in a white shirt\n",
              "4  00005            a man with a bandana on his head"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a22bc4c9-7277-4531-8e6f-24c7317f51a5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001</td>\n",
              "      <td>a man with a black jacket</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002</td>\n",
              "      <td>a young child with a very look on his face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00003</td>\n",
              "      <td>a woman with a big smile on her face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00004</td>\n",
              "      <td>a man in a white shirt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00005</td>\n",
              "      <td>a man with a bandana on his head</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a22bc4c9-7277-4531-8e6f-24c7317f51a5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a22bc4c9-7277-4531-8e6f-24c7317f51a5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a22bc4c9-7277-4531-8e6f-24c7317f51a5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-062cd14e-afa2-406e-bf05-53f50e5393b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-062cd14e-afa2-406e-bf05-53f50e5393b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-062cd14e-afa2-406e-bf05-53f50e5393b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2048,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2048,\n        \"samples\": [\n          \"01477\",\n          \"00694\",\n          \"00101\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 802,\n        \"samples\": [\n          \"a man with a beard and a woman with a beard\",\n          \"an older woman smiling for the camera\",\n          \"a woman with a cat on her head\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# read dataset\n",
        "import os\n",
        "imagess = os.listdir('dataset')\n",
        "# import txt file as csv file with pandas with comma separator\n",
        "import pandas as pd\n",
        "dtype_dict = {'name': str, 'caption': str}\n",
        "df = pd.read_csv('dataset/image_captions_cleaned.txt', sep=\",\", header=0, dtype=dtype_dict)\n",
        "print('Shape is: ' + str(df.shape))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bf0aa96044584064b4202ab8d55e49ba",
            "b11a83aef5a64d1cbc61dbd30e0736e2",
            "773307f59fa64bbcaf70da54ce56296a",
            "aaf5e6c625e0413f8aebcbcf87cdd2e5",
            "227dde3af3ed428b833aaa037a1d73af",
            "d50d88fbb4ba4b89b3ed550a0cba0011",
            "d019983df5a3446c88f6af58ef1745ea",
            "a1b71d8a307041c598961f34ecb5b052",
            "a8cee7ef8dd14ff383f5cb53dd4d0ff6",
            "bb9f9e508247457d88901314c78aa3f7",
            "7060a7276111461ba60aae986c3beb5d"
          ]
        },
        "id": "3NWtvWsTm62T",
        "outputId": "f3036c74-5210-41d3-b149-cfdfd755f00c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2048 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf0aa96044584064b4202ab8d55e49ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.7163, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 799, Loss: 66.71630096435547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9320, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 800, Loss: 54.932029724121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.0960, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 801, Loss: 55.09601593017578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.6605, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 802, Loss: 42.66053771972656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.9528, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 803, Loss: 39.95280838012695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4437, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 804, Loss: 56.44369125366211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.1229, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 805, Loss: 71.12294006347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7773, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 806, Loss: 50.777286529541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.0274, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 807, Loss: 61.02738952636719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.0480, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 808, Loss: 58.0479850769043\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2260, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 809, Loss: 49.22599792480469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.1638, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 810, Loss: 39.163795471191406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.9098, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 811, Loss: 45.909828186035156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2105, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 812, Loss: 54.210540771484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2805, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 813, Loss: 49.28053283691406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.3264, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 814, Loss: 42.32640838623047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6104, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 815, Loss: 51.610443115234375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.1682, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 816, Loss: 41.168243408203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1141, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 817, Loss: 47.114112854003906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2391, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 818, Loss: 49.23910140991211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7322, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 819, Loss: 48.73216247558594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(78.2190, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 820, Loss: 78.21903991699219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.6459, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 821, Loss: 53.64594268798828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.7139, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 822, Loss: 46.71385955810547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6063, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 823, Loss: 46.60626220703125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.8844, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 824, Loss: 50.88444900512695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.4691, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 825, Loss: 52.46914291381836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.6317, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 826, Loss: 38.631717681884766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.2776, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 827, Loss: 51.277645111083984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9687, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 828, Loss: 43.96870803833008\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3871, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 829, Loss: 47.387088775634766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.0916, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 830, Loss: 63.091590881347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6851, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 831, Loss: 45.685096740722656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1660, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 832, Loss: 50.16599655151367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.3770, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 833, Loss: 60.376956939697266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.6847, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 834, Loss: 60.68467330932617\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.0022, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 835, Loss: 59.002227783203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.0787, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 836, Loss: 53.07868194580078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.8976, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 837, Loss: 50.89757537841797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6975, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 838, Loss: 51.69749069213867\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.0681, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 839, Loss: 47.068119049072266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.7920, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 840, Loss: 63.792030334472656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.7458, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 841, Loss: 44.745765686035156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.0409, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 842, Loss: 70.0408706665039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2542, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 843, Loss: 54.254234313964844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(75.9885, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 844, Loss: 75.98854064941406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5444, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 845, Loss: 45.544395446777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.2723, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 846, Loss: 41.272315979003906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.9053, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 847, Loss: 42.90529251098633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.9928, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 848, Loss: 59.99281692504883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.0259, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 849, Loss: 59.02594757080078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2504, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 850, Loss: 48.25040054321289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.6319, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 851, Loss: 54.63188171386719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.9277, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 852, Loss: 37.92771911621094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.1543, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 853, Loss: 57.154296875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8237, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 854, Loss: 46.823692321777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5348, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 855, Loss: 45.53483581542969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4712, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 856, Loss: 49.4711799621582\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(81.6665, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 857, Loss: 81.66646575927734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9121, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 858, Loss: 48.9120979309082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2810, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 859, Loss: 53.28103256225586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4943, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 860, Loss: 42.494346618652344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.5694, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 861, Loss: 56.569366455078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.4197, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 862, Loss: 50.41965866088867\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7816, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 863, Loss: 42.781551361083984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4310, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 864, Loss: 55.43097686767578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.8125, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 865, Loss: 61.81254959106445\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4744, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 866, Loss: 51.474361419677734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.0276, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 867, Loss: 67.027587890625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.0943, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 868, Loss: 43.094329833984375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6451, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 869, Loss: 47.64511489868164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8882, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 870, Loss: 42.88817596435547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8946, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 871, Loss: 45.89459991455078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3646, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 872, Loss: 51.36463165283203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.2488, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 873, Loss: 60.248783111572266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.6867, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 874, Loss: 39.686744689941406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.0665, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 875, Loss: 67.06649780273438\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.2290, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 876, Loss: 61.22896194458008\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9643, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 877, Loss: 49.96427536010742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.6793, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 878, Loss: 49.67934799194336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2952, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 879, Loss: 42.29518508911133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2786, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 880, Loss: 52.278648376464844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9639, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 881, Loss: 47.96388244628906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.8684, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 882, Loss: 56.868377685546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(32.9708, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 883, Loss: 32.97079086303711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.0779, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 884, Loss: 54.07787322998047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.5963, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 885, Loss: 41.596275329589844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.4639, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 886, Loss: 48.46393966674805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.0565, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 887, Loss: 49.056514739990234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6051, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 888, Loss: 46.605133056640625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(30.3471, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 889, Loss: 30.34710121154785\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.1002, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 890, Loss: 48.100223541259766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.7307, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 891, Loss: 44.730716705322266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.0000, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 892, Loss: 40.9999885559082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.7854, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 893, Loss: 40.78542709350586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9676, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 894, Loss: 43.9676399230957\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.8665, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 895, Loss: 54.866458892822266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3351, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 896, Loss: 51.335086822509766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7444, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 897, Loss: 50.74443435668945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.3407, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 898, Loss: 42.34073257446289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.4483, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 899, Loss: 40.448341369628906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.2107, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 900, Loss: 55.21072769165039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.0834, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 901, Loss: 54.083412170410156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.8056, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 902, Loss: 48.80562973022461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.8067, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 903, Loss: 63.806671142578125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.0395, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 904, Loss: 35.03946304321289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.8294, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 905, Loss: 65.82940673828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6489, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 906, Loss: 45.64885330200195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4316, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 907, Loss: 56.43162155151367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.0426, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 908, Loss: 62.0426025390625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.5052, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 909, Loss: 59.50523376464844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.0123, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 910, Loss: 53.01234817504883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.0282, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 911, Loss: 46.0282096862793\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3939, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 912, Loss: 48.3939208984375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.5579, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 913, Loss: 39.55794906616211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.2476, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 914, Loss: 47.247642517089844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8938, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 915, Loss: 57.89384841918945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0623, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 916, Loss: 45.062252044677734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.1010, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 917, Loss: 44.10102081298828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.5909, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 918, Loss: 57.590877532958984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.3064, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 919, Loss: 49.30636215209961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.0630, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 920, Loss: 53.062984466552734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.1304, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 921, Loss: 45.13044357299805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9282, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 922, Loss: 54.92820739746094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.5209, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 923, Loss: 46.52090835571289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.3421, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 924, Loss: 50.34210968017578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8881, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 925, Loss: 39.88810348510742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.9835, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 926, Loss: 64.98348236083984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.6592, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 927, Loss: 54.6591682434082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.9519, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 928, Loss: 58.95193862915039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1792, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 929, Loss: 52.17915725708008\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.4747, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 930, Loss: 52.47468566894531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6428, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 931, Loss: 50.64278793334961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.9829, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 932, Loss: 38.98292541503906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4996, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 933, Loss: 49.49958419799805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.0889, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 934, Loss: 58.08890151977539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8638, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 935, Loss: 42.8637809753418\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.4000, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 936, Loss: 64.39996337890625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.1727, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 937, Loss: 56.17271041870117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4723, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 938, Loss: 49.47234344482422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2700, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 939, Loss: 53.269962310791016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.3185, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 940, Loss: 43.3184814453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.1755, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 941, Loss: 70.17545318603516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.4107, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 942, Loss: 35.41072082519531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8832, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 943, Loss: 42.883243560791016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.1507, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 944, Loss: 43.150665283203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3939, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 945, Loss: 48.39385223388672\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.4311, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 946, Loss: 50.43113327026367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8687, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 947, Loss: 46.868717193603516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.9099, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 948, Loss: 53.909881591796875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.4346, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 949, Loss: 61.4345703125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.5123, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 950, Loss: 56.51231384277344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.7514, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 951, Loss: 63.751380920410156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.1248, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 952, Loss: 39.124794006347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.9240, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 953, Loss: 44.92402648925781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7098, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 954, Loss: 54.709815979003906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.6700, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 955, Loss: 59.67003631591797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.6024, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 956, Loss: 55.60239028930664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.7288, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 957, Loss: 46.728790283203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.5468, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 958, Loss: 71.54682159423828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.3543, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 959, Loss: 63.35430145263672\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.0002, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 960, Loss: 41.000221252441406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.5693, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 961, Loss: 43.56929016113281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.6358, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 962, Loss: 65.63579559326172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.1553, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 963, Loss: 57.15525436401367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9999, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 964, Loss: 51.99991989135742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7499, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 965, Loss: 42.74989318847656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.6432, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 966, Loss: 53.64315414428711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.3135, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 967, Loss: 59.31349182128906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4910, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 968, Loss: 49.49095153808594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4086, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 969, Loss: 42.40859603881836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7631, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 970, Loss: 42.76308822631836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0124, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 971, Loss: 52.01239013671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.0972, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 972, Loss: 35.09720993041992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6096, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 973, Loss: 45.60955810546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.6256, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 974, Loss: 39.62559127807617\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7544, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 975, Loss: 43.754398345947266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.5759, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 976, Loss: 44.57585906982422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.7802, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 977, Loss: 37.78017807006836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.2039, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 978, Loss: 51.20390319824219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.1475, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 979, Loss: 42.14747619628906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.6832, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 980, Loss: 67.68315124511719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.5364, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 981, Loss: 49.53639602661133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.7808, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 982, Loss: 60.78080749511719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.7617, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 983, Loss: 57.761680603027344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.8108, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 984, Loss: 50.810752868652344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0471, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 985, Loss: 51.04713439941406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(75.3431, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 986, Loss: 75.34309387207031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.4240, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 987, Loss: 46.42399215698242\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.1787, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 988, Loss: 49.17867660522461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.1204, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 989, Loss: 53.12036895751953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.0289, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 990, Loss: 72.0289306640625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8767, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 991, Loss: 42.87666320800781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8878, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 992, Loss: 46.8878059387207\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1373, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 993, Loss: 50.13728332519531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.0415, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 994, Loss: 46.041534423828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8648, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 995, Loss: 39.86479187011719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.2880, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 996, Loss: 47.287994384765625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6461, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 997, Loss: 50.64613342285156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.4822, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 998, Loss: 53.4821662902832\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3177, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 999, Loss: 48.317657470703125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.6217, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1000, Loss: 60.621700286865234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.6755, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1001, Loss: 59.6755256652832\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0186, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1002, Loss: 52.01858901977539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.6540, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1003, Loss: 41.65400695800781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.0013, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1004, Loss: 57.00126266479492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8373, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1005, Loss: 57.83727264404297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.3337, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1006, Loss: 59.33373260498047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.9466, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1007, Loss: 57.94655990600586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8651, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1008, Loss: 41.8651008605957\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.5363, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1009, Loss: 39.53626251220703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.0478, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1010, Loss: 67.04781341552734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.1193, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1011, Loss: 53.11931610107422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6013, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1012, Loss: 50.601287841796875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9539, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1013, Loss: 49.953880310058594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8755, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1014, Loss: 49.87549591064453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2085, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1015, Loss: 48.208492279052734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6429, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1016, Loss: 51.64292907714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7353, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1017, Loss: 54.735286712646484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.3330, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1018, Loss: 57.33296585083008\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.8720, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1019, Loss: 53.872039794921875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2113, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1020, Loss: 46.21128463745117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.9638, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1021, Loss: 50.96375274658203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2483, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1022, Loss: 53.248268127441406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.1627, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1023, Loss: 45.16270446777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.4052, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1024, Loss: 54.40523147583008\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.8036, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1025, Loss: 67.80355834960938\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.7105, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1026, Loss: 58.7104606628418\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2153, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1027, Loss: 42.215293884277344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4479, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1028, Loss: 42.44791030883789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.1946, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1029, Loss: 62.19462966918945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.7353, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1030, Loss: 52.73532485961914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2375, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1031, Loss: 54.23748016357422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.1462, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1032, Loss: 62.14620590209961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.6260, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1033, Loss: 49.62602996826172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(33.8493, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1034, Loss: 33.84925842285156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.2297, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1035, Loss: 44.229671478271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3019, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1036, Loss: 48.301918029785156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.8398, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1037, Loss: 60.83977127075195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.3004, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1038, Loss: 45.300376892089844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.5310, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1039, Loss: 54.53102111816406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2186, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1040, Loss: 46.21860122680664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2876, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1041, Loss: 54.28762435913086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.4320, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1042, Loss: 44.43195724487305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0147, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1043, Loss: 50.01472091674805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8291, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1044, Loss: 46.8291130065918\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.6266, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1045, Loss: 52.62660217285156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8725, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1046, Loss: 45.87248229980469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(69.1896, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1047, Loss: 69.1895523071289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.0493, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1048, Loss: 40.049251556396484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.5213, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1049, Loss: 63.52128601074219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6088, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1050, Loss: 50.608848571777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8305, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1051, Loss: 42.83046340942383\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.5763, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1052, Loss: 52.5762939453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.5364, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1053, Loss: 50.53635025024414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.3763, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1054, Loss: 59.37630081176758\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.7377, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1055, Loss: 40.73774337768555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.1603, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1056, Loss: 43.16028594970703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.8092, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1057, Loss: 53.8091926574707\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5532, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1058, Loss: 45.55324935913086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.4006, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1059, Loss: 65.4006118774414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.2513, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1060, Loss: 39.25125503540039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0391, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1061, Loss: 52.03911209106445\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.5683, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1062, Loss: 53.568328857421875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.8493, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1063, Loss: 52.849327087402344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8470, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1064, Loss: 41.84701919555664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.4442, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1065, Loss: 45.444156646728516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3283, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1066, Loss: 51.32826614379883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.6471, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1067, Loss: 44.64707946777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.6849, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1068, Loss: 53.68485641479492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7183, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1069, Loss: 42.718299865722656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.5861, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1070, Loss: 52.58613967895508\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.4937, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1071, Loss: 53.493736267089844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9769, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1072, Loss: 47.976871490478516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.1737, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1073, Loss: 58.17365264892578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.2957, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1074, Loss: 56.29567337036133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.6490, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1075, Loss: 68.64904022216797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.6170, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1076, Loss: 54.617027282714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.8080, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1077, Loss: 58.80799865722656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.9528, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1078, Loss: 45.95277786254883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.1811, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1079, Loss: 41.18107986450195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.5283, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1080, Loss: 59.52827072143555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2179, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1081, Loss: 46.21793746948242\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9570, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1082, Loss: 54.9570198059082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1990, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1083, Loss: 50.198951721191406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.9886, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1084, Loss: 58.988609313964844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7856, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1085, Loss: 54.785614013671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8592, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1086, Loss: 41.85923767089844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2212, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1087, Loss: 42.22116470336914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.1000, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1088, Loss: 54.09996032714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7949, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1089, Loss: 43.79486846923828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.0658, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1090, Loss: 57.06583023071289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.4326, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1091, Loss: 52.43260192871094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.4773, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1092, Loss: 54.47734069824219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.1256, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1093, Loss: 56.1256103515625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2353, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1094, Loss: 53.23529052734375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.0014, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1095, Loss: 59.001407623291016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.6061, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1096, Loss: 42.60610580444336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.4086, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1097, Loss: 58.40857696533203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.7297, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1098, Loss: 46.72970199584961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3358, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1099, Loss: 47.33578872680664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.5275, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1100, Loss: 55.52750015258789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.9402, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1101, Loss: 42.940189361572266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.9851, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1102, Loss: 50.985084533691406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2798, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1103, Loss: 46.27980422973633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7039, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1104, Loss: 48.70393371582031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.0764, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1105, Loss: 35.07638168334961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7185, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1106, Loss: 50.718505859375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7791, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1107, Loss: 50.77907180786133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.5562, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1108, Loss: 41.55618667602539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.2420, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1109, Loss: 57.24204635620117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.1468, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1110, Loss: 72.14680480957031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9873, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1111, Loss: 51.98733901977539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.7013, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1112, Loss: 57.70132064819336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.4300, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1113, Loss: 44.43003463745117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.2670, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1114, Loss: 50.267024993896484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.8158, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1115, Loss: 53.815792083740234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.8269, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1116, Loss: 38.826934814453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(73.5823, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1117, Loss: 73.58226776123047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7026, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1118, Loss: 48.70263671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2502, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1119, Loss: 42.25018310546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.5587, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1120, Loss: 42.55869674682617\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.4657, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1121, Loss: 53.46574783325195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7569, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1122, Loss: 48.75693893432617\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.2528, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1123, Loss: 58.252769470214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.3818, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1124, Loss: 38.38182067871094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1092, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1125, Loss: 52.109195709228516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.2547, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1126, Loss: 43.25466537475586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.7691, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1127, Loss: 55.76914978027344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.9587, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1128, Loss: 41.95866394042969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.3450, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1129, Loss: 40.34503173828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.0433, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1130, Loss: 62.043312072753906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8508, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1131, Loss: 39.850765228271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.1354, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1132, Loss: 54.135379791259766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8299, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1133, Loss: 46.82989501953125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3235, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1134, Loss: 54.32352828979492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.2940, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1135, Loss: 40.29403305053711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.1121, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1136, Loss: 48.112144470214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.6636, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1137, Loss: 64.66358184814453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(75.0763, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1138, Loss: 75.07633209228516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.5657, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1139, Loss: 49.56570053100586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.6236, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1140, Loss: 34.62359619140625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.5786, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1141, Loss: 47.578636169433594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9340, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1142, Loss: 43.933982849121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.5334, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1143, Loss: 56.533443450927734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.5826, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1144, Loss: 47.58256530761719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.8210, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1145, Loss: 53.82099533081055\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.5427, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1146, Loss: 53.542724609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.5268, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1147, Loss: 56.526763916015625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.6240, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1148, Loss: 41.62400817871094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.9203, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1149, Loss: 63.92034149169922\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.2444, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1150, Loss: 60.244407653808594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.2394, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1151, Loss: 57.239437103271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.3755, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1152, Loss: 40.375545501708984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.5119, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1153, Loss: 54.511898040771484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.0226, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1154, Loss: 60.022579193115234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.2442, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1155, Loss: 43.244171142578125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.3616, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1156, Loss: 56.361576080322266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(69.5468, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1157, Loss: 69.54679107666016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8642, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1158, Loss: 39.86418914794922\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.7295, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1159, Loss: 44.729515075683594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.0543, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1160, Loss: 68.05425262451172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.3261, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1161, Loss: 45.3260612487793\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.6539, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1162, Loss: 48.653873443603516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.2792, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1163, Loss: 70.27922058105469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9943, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1164, Loss: 48.99433898925781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.0854, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1165, Loss: 53.085350036621094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.6139, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1166, Loss: 40.61386489868164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.3003, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1167, Loss: 60.30034637451172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.4643, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1168, Loss: 62.46429443359375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2232, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1169, Loss: 54.22316360473633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3385, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1170, Loss: 48.33850860595703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8745, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1171, Loss: 51.87446212768555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9595, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1172, Loss: 51.95949172973633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.7470, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1173, Loss: 37.74699020385742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.6913, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1174, Loss: 38.691322326660156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8591, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1175, Loss: 41.85907745361328\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.7378, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1176, Loss: 52.737796783447266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4266, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1177, Loss: 51.42664337158203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0034, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1178, Loss: 52.003395080566406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.5305, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1179, Loss: 42.530521392822266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.7190, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1180, Loss: 56.71895980834961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.6861, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1181, Loss: 44.68606948852539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1460, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1182, Loss: 50.14599609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0656, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1183, Loss: 45.06562423706055\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.1169, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1184, Loss: 41.11689758300781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.1079, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1185, Loss: 65.10785675048828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.2040, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1186, Loss: 61.20396041870117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0277, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1187, Loss: 51.02767562866211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.0445, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1188, Loss: 49.04445266723633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.0820, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1189, Loss: 60.08195877075195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0939, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1190, Loss: 45.093910217285156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.5604, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1191, Loss: 40.56038284301758\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.5892, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1192, Loss: 44.589210510253906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.2575, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1193, Loss: 55.2574577331543\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0058, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1194, Loss: 45.005767822265625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.1103, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1195, Loss: 38.110252380371094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.3105, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1196, Loss: 55.310508728027344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.5211, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1197, Loss: 63.52110290527344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.1175, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1198, Loss: 38.11747741699219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1086, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1199, Loss: 50.10857391357422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0839, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1200, Loss: 45.08385467529297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7757, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1201, Loss: 50.77570343017578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.0684, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1202, Loss: 49.06843948364258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.5064, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1203, Loss: 40.506378173828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8989, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1204, Loss: 49.89887619018555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.6818, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1205, Loss: 43.68179702758789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.4940, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1206, Loss: 59.49401092529297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.8074, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1207, Loss: 37.807350158691406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.6335, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1208, Loss: 58.633487701416016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2997, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1209, Loss: 46.299720764160156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(69.0834, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1210, Loss: 69.08340454101562\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.3040, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1211, Loss: 72.3039779663086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.5909, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1212, Loss: 46.590858459472656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.3639, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1213, Loss: 49.36387252807617\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.5627, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1214, Loss: 37.56272506713867\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.2581, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1215, Loss: 34.25810623168945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.4202, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1216, Loss: 47.42015838623047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.5459, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1217, Loss: 68.54588317871094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1480, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1218, Loss: 50.148048400878906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.1980, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1219, Loss: 53.198001861572266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.4610, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1220, Loss: 54.46099853515625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.9075, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1221, Loss: 46.90754699707031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.3493, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1222, Loss: 55.34926223754883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.2966, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1223, Loss: 71.29663848876953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.0573, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1224, Loss: 61.0572624206543\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0810, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1225, Loss: 51.08104705810547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4092, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1226, Loss: 42.40920639038086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8522, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1227, Loss: 46.852237701416016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.0515, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1228, Loss: 66.05148315429688\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.6475, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1229, Loss: 64.64754486083984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.3553, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1230, Loss: 36.35527420043945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.8549, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1231, Loss: 62.85492706298828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6729, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1232, Loss: 47.67285919189453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.1871, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1233, Loss: 58.18714904785156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.0821, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1234, Loss: 43.08205795288086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.5778, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1235, Loss: 63.577796936035156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8089, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1236, Loss: 57.80887222290039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.5489, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1237, Loss: 37.54890823364258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.4878, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1238, Loss: 70.48783111572266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.1590, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1239, Loss: 53.15903854370117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.0146, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1240, Loss: 39.01462173461914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.8097, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1241, Loss: 48.80974197387695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.1212, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1242, Loss: 56.12123107910156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.6031, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1243, Loss: 53.603118896484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.1695, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1244, Loss: 34.169532775878906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0643, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1245, Loss: 51.06425857543945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.5851, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1246, Loss: 46.585140228271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.6742, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1247, Loss: 53.67417526245117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9876, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1248, Loss: 49.98758316040039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.7115, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1249, Loss: 38.711483001708984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3707, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1250, Loss: 51.37071990966797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4730, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1251, Loss: 51.47300338745117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.7529, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1252, Loss: 63.75285720825195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.8268, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1253, Loss: 60.826805114746094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.8310, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1254, Loss: 38.830963134765625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.6530, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1255, Loss: 71.65303039550781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0411, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1256, Loss: 45.04108810424805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2922, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1257, Loss: 52.29218673706055\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.5104, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1258, Loss: 43.51044464111328\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.3478, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1259, Loss: 50.34778594970703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.3102, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1260, Loss: 64.31017303466797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7205, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1261, Loss: 54.72047805786133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.3076, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1262, Loss: 43.307621002197266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.0642, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1263, Loss: 49.064212799072266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.9990, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1264, Loss: 38.9990234375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.4220, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1265, Loss: 43.4219856262207\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.1259, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1266, Loss: 63.12594223022461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.9539, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1267, Loss: 50.95389938354492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.5742, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1268, Loss: 55.574161529541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.8703, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1269, Loss: 66.87032318115234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9106, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1270, Loss: 49.910587310791016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8523, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1271, Loss: 46.85227584838867\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.3872, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1272, Loss: 65.38719940185547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.8128, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1273, Loss: 61.81281661987305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.8676, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1274, Loss: 37.867645263671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.1412, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1275, Loss: 43.141170501708984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7797, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1276, Loss: 54.77973556518555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9352, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1277, Loss: 43.935184478759766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8400, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1278, Loss: 46.840003967285156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4573, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1279, Loss: 55.45734405517578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.1044, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1280, Loss: 51.104400634765625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(78.4936, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1281, Loss: 78.49356079101562\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.6240, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1282, Loss: 36.62396240234375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.2460, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1283, Loss: 44.24604034423828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2978, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1284, Loss: 46.29780960083008\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.3916, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1285, Loss: 55.391605377197266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.2704, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1286, Loss: 47.27044677734375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6796, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1287, Loss: 50.67955780029297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.4402, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1288, Loss: 40.44023895263672\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.1966, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1289, Loss: 44.196556091308594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9583, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1290, Loss: 47.95827865600586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.8712, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1291, Loss: 40.8712272644043\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.6483, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1292, Loss: 49.648277282714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.2562, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1293, Loss: 65.25621032714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.1731, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1294, Loss: 48.173057556152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.4318, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1295, Loss: 40.43180847167969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.1246, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1296, Loss: 61.124603271484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6232, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1297, Loss: 50.62315368652344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3912, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1298, Loss: 47.39115905761719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.5004, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1299, Loss: 43.500396728515625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.9020, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1300, Loss: 46.90201950073242\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.6648, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1301, Loss: 57.664833068847656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7521, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1302, Loss: 43.75210189819336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.1597, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1303, Loss: 49.15967559814453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9703, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1304, Loss: 49.97026824951172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.4758, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1305, Loss: 44.475765228271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.4720, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1306, Loss: 57.47195053100586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.5862, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1307, Loss: 63.58616638183594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.3635, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1308, Loss: 46.363529205322266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.8550, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1309, Loss: 65.85503387451172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4371, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1310, Loss: 51.437068939208984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.4516, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1311, Loss: 54.45158386230469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.3712, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1312, Loss: 66.37120056152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2016, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1313, Loss: 52.20159912109375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9031, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1314, Loss: 48.903133392333984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.1235, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1315, Loss: 44.12351608276367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.4115, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1316, Loss: 50.4114875793457\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.7921, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1317, Loss: 55.79212188720703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2601, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1318, Loss: 49.26005172729492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8126, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1319, Loss: 39.81264114379883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.2425, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1320, Loss: 55.24253845214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7473, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1321, Loss: 54.747276306152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.5137, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1322, Loss: 46.51369857788086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6212, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1323, Loss: 45.6212272644043\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.2974, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1324, Loss: 60.297386169433594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4340, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1325, Loss: 42.43402099609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3979, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1326, Loss: 51.39791488647461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.6841, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1327, Loss: 57.684085845947266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.3779, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1328, Loss: 35.377933502197266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.8773, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1329, Loss: 65.8772964477539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.5322, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1330, Loss: 52.53219985961914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.3463, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1331, Loss: 66.34628295898438\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.4263, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1332, Loss: 47.42628479003906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9674, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1333, Loss: 48.96744918823242\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.6109, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1334, Loss: 49.610939025878906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.3870, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1335, Loss: 55.38703155517578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6017, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1336, Loss: 50.60165786743164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.6222, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1337, Loss: 54.622230529785156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.7518, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1338, Loss: 36.75176239013672\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.8229, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1339, Loss: 56.82286071777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.5985, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1340, Loss: 51.59846878051758\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6107, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1341, Loss: 47.610652923583984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2034, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1342, Loss: 48.20338439941406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2797, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1343, Loss: 53.27965545654297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(84.5211, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1344, Loss: 84.52110290527344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2615, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1345, Loss: 48.26150894165039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.4308, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1346, Loss: 41.43080139160156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.1371, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1347, Loss: 46.137123107910156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.7371, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1348, Loss: 51.737098693847656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.1579, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1349, Loss: 60.15787887573242\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.0071, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1350, Loss: 72.00714874267578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.0885, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1351, Loss: 43.088523864746094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.2548, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1352, Loss: 40.254817962646484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.9468, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1353, Loss: 37.94682693481445\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.3088, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1354, Loss: 67.30882263183594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.4563, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1355, Loss: 46.45629119873047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.1124, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1356, Loss: 71.11235046386719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.8890, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1357, Loss: 60.888973236083984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.1281, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1358, Loss: 40.12808609008789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9834, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1359, Loss: 49.983428955078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6691, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1360, Loss: 45.66911697387695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.1739, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1361, Loss: 49.1739387512207\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.3401, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1362, Loss: 37.34012222290039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.2979, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1363, Loss: 61.29793930053711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.2384, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1364, Loss: 51.238426208496094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(78.8590, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1365, Loss: 78.85896301269531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.0321, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1366, Loss: 38.03208541870117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.0205, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1367, Loss: 41.02049255371094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8480, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1368, Loss: 46.84796142578125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6408, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1369, Loss: 47.640769958496094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8884, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1370, Loss: 51.88839340209961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0955, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1371, Loss: 50.095481872558594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.5292, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1372, Loss: 41.529239654541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.9696, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1373, Loss: 66.9695816040039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.3684, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1374, Loss: 61.36840057373047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0827, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1375, Loss: 44.08267593383789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.3917, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1376, Loss: 50.3917236328125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.3070, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1377, Loss: 41.30704879760742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.6913, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1378, Loss: 63.69126510620117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.6040, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1379, Loss: 48.60398483276367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.5607, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1380, Loss: 56.56073760986328\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.5875, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1381, Loss: 58.587493896484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4109, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1382, Loss: 56.41085433959961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8348, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1383, Loss: 41.8348388671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(69.3134, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1384, Loss: 69.31336975097656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6164, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1385, Loss: 45.616390228271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8077, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1386, Loss: 45.80771255493164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4883, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1387, Loss: 55.48828887939453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9649, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1388, Loss: 49.9648551940918\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.0736, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1389, Loss: 49.07360076904297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.5179, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1390, Loss: 60.517852783203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9738, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1391, Loss: 54.97382354736328\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.4424, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1392, Loss: 71.4423828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.5871, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1393, Loss: 67.58705139160156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.2328, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1394, Loss: 61.23283386230469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.9675, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1395, Loss: 50.96751403808594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.6499, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1396, Loss: 55.64985275268555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.6855, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1397, Loss: 41.68552780151367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.1561, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1398, Loss: 42.15610885620117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.1205, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1399, Loss: 39.12049865722656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6864, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1400, Loss: 45.68641662597656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.9305, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1401, Loss: 42.93050765991211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.6148, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1402, Loss: 41.61478042602539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(73.6954, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1403, Loss: 73.69538879394531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.2873, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1404, Loss: 56.287349700927734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(77.3235, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1405, Loss: 77.32349395751953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3553, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1406, Loss: 51.35526657104492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8227, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1407, Loss: 51.82270812988281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6668, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1408, Loss: 45.666770935058594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6630, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1409, Loss: 46.6629753112793\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.6084, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1410, Loss: 60.608421325683594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.2048, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1411, Loss: 41.20480728149414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0826, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1412, Loss: 52.08256149291992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.2741, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1413, Loss: 51.27412414550781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.4580, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1414, Loss: 52.45804214477539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.5957, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1415, Loss: 52.595733642578125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8069, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1416, Loss: 46.8068733215332\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6663, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1417, Loss: 46.666282653808594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.3017, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1418, Loss: 57.301727294921875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2160, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1419, Loss: 49.215980529785156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.5985, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1420, Loss: 38.59852600097656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9798, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1421, Loss: 49.97983169555664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4634, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1422, Loss: 56.46342468261719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.5265, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1423, Loss: 57.52654266357422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.8691, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1424, Loss: 65.86914825439453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.1294, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1425, Loss: 58.129390716552734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9250, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1426, Loss: 51.925018310546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(73.7817, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1427, Loss: 73.78168487548828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8678, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1428, Loss: 51.86775588989258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.9708, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1429, Loss: 52.970787048339844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6809, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1430, Loss: 46.68086242675781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.5113, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1431, Loss: 47.51126480102539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.0661, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1432, Loss: 55.066097259521484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1588, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1433, Loss: 50.15884017944336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.2341, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1434, Loss: 45.234066009521484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7199, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1435, Loss: 42.7198600769043\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.1081, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1436, Loss: 48.10808563232422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.3686, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1437, Loss: 49.36860275268555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2183, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1438, Loss: 52.21827697753906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8861, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1439, Loss: 57.88608932495117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.5314, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1440, Loss: 49.53136444091797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.0649, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1441, Loss: 40.0649299621582\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0948, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1442, Loss: 50.09480285644531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7299, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1443, Loss: 43.72990417480469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0895, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1444, Loss: 45.08951187133789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0296, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1445, Loss: 50.02962112426758\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.8789, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1446, Loss: 44.87890625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.2440, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1447, Loss: 44.244049072265625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.2767, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1448, Loss: 40.2767219543457\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7978, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1449, Loss: 43.79777908325195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.0047, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1450, Loss: 43.004669189453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.4490, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1451, Loss: 66.44901275634766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.3177, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1452, Loss: 56.317718505859375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.9514, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1453, Loss: 59.951385498046875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.4930, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1454, Loss: 68.4930191040039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.9607, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1455, Loss: 44.96068572998047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.4988, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1456, Loss: 59.498844146728516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3626, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1457, Loss: 54.362613677978516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.8909, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1458, Loss: 54.890869140625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.0217, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1459, Loss: 47.02170944213867\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2293, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1460, Loss: 49.229278564453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.1914, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1461, Loss: 40.19137954711914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2246, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1462, Loss: 42.22462844848633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9925, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1463, Loss: 48.99249267578125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2998, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1464, Loss: 54.299774169921875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.3724, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1465, Loss: 68.37236022949219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.4154, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1466, Loss: 60.415428161621094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7334, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1467, Loss: 48.733421325683594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2782, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1468, Loss: 42.27817916870117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9865, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1469, Loss: 51.98649978637695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.1741, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1470, Loss: 43.17409896850586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.2657, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1471, Loss: 39.26573181152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.1040, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1472, Loss: 35.1039924621582\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.1900, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1473, Loss: 44.189979553222656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.6330, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1474, Loss: 49.63299560546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.7435, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1475, Loss: 46.74345779418945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.4451, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1476, Loss: 61.44511795043945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5190, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1477, Loss: 45.51897048950195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.6713, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1478, Loss: 48.67132568359375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.1540, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1479, Loss: 46.153995513916016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2037, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1480, Loss: 54.20366668701172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.0460, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1481, Loss: 42.04599380493164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.6671, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1482, Loss: 34.66706085205078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.3850, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1483, Loss: 50.384952545166016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.1249, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1484, Loss: 46.12494659423828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.9645, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1485, Loss: 59.96449661254883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7507, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1486, Loss: 43.750675201416016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6615, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1487, Loss: 50.661529541015625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8919, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1488, Loss: 45.89185333251953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.4917, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1489, Loss: 47.4916877746582\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.6595, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1490, Loss: 39.659454345703125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.6647, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1491, Loss: 44.664710998535156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8399, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1492, Loss: 41.83991241455078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.6305, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1493, Loss: 60.63054275512695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.3076, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1494, Loss: 52.30759048461914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.6040, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1495, Loss: 49.60396957397461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.1158, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1496, Loss: 40.115821838378906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.3028, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1497, Loss: 58.30280685424805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4143, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1498, Loss: 49.4143180847168\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.5481, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1499, Loss: 40.54812240600586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.5742, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1500, Loss: 60.57419204711914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1046, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1501, Loss: 52.10457992553711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1454, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1502, Loss: 47.14543151855469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4501, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1503, Loss: 55.45005416870117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.6809, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1504, Loss: 42.680912017822266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.8090, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1505, Loss: 59.80902862548828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.5280, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1506, Loss: 51.527976989746094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.2336, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1507, Loss: 66.23360443115234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8653, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1508, Loss: 57.86531066894531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(79.0315, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1509, Loss: 79.03153991699219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.3506, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1510, Loss: 63.35060501098633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2741, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1511, Loss: 48.27410125732422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.9156, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1512, Loss: 52.91558074951172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.6329, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1513, Loss: 58.63287353515625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.1486, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1514, Loss: 58.14857482910156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.6396, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1515, Loss: 52.63955307006836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.6035, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1516, Loss: 63.6035041809082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0906, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1517, Loss: 44.09062957763672\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.1649, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1518, Loss: 46.16486740112305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.5559, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1519, Loss: 57.55593490600586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.5651, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1520, Loss: 40.56511306762695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.0046, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1521, Loss: 64.00459289550781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.7114, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1522, Loss: 60.711360931396484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.1517, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1523, Loss: 62.15168380737305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.6771, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1524, Loss: 58.67713165283203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.0468, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1525, Loss: 55.046817779541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6376, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1526, Loss: 46.63758850097656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9068, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1527, Loss: 51.90681457519531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.2331, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1528, Loss: 55.233089447021484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.1399, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1529, Loss: 60.13988494873047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.4373, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1530, Loss: 60.43734359741211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.5048, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1531, Loss: 47.50479507446289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3132, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1532, Loss: 48.31321334838867\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.5137, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1533, Loss: 70.513671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.0525, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1534, Loss: 71.05252075195312\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.5399, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1535, Loss: 51.53990173339844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.0718, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1536, Loss: 53.07179260253906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.4300, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1537, Loss: 61.43002700805664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.8103, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1538, Loss: 36.81032943725586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.7116, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1539, Loss: 61.711612701416016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4029, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1540, Loss: 42.40285873413086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.3668, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1541, Loss: 41.36676788330078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.2706, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1542, Loss: 42.27058792114258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.3765, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1543, Loss: 55.37649154663086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.2112, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1544, Loss: 45.21117401123047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6739, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1545, Loss: 46.67387771606445\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9841, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1546, Loss: 51.98408508300781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.2325, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1547, Loss: 62.2325439453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1884, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1548, Loss: 52.188350677490234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5088, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1549, Loss: 45.50878143310547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.3585, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1550, Loss: 64.35851287841797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.6271, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1551, Loss: 48.62708282470703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.8827, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1552, Loss: 52.88272476196289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.6107, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1553, Loss: 64.61067199707031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4500, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1554, Loss: 49.45001220703125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.1292, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1555, Loss: 45.12916564941406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.5100, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1556, Loss: 60.50996780395508\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.1849, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1557, Loss: 59.1849479675293\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.7494, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1558, Loss: 44.74942398071289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6753, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1559, Loss: 51.675254821777344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2241, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1560, Loss: 53.22414779663086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.3966, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1561, Loss: 58.39662551879883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.8893, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1562, Loss: 62.8892936706543\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7050, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1563, Loss: 48.70500183105469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.5739, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1564, Loss: 68.57388305664062\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2361, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1565, Loss: 52.236053466796875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9476, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1566, Loss: 47.94755172729492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.4368, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1567, Loss: 50.436798095703125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.4527, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1568, Loss: 61.45267868041992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.2074, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1569, Loss: 47.207359313964844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1055, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1570, Loss: 47.10547637939453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8396, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1571, Loss: 49.839637756347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.4973, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1572, Loss: 62.497276306152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.6774, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1573, Loss: 43.67735290527344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.4240, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1574, Loss: 42.42397689819336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7650, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1575, Loss: 43.7650146484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3247, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1576, Loss: 54.324737548828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.9448, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1577, Loss: 62.944828033447266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.0562, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1578, Loss: 60.05619812011719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3251, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1579, Loss: 54.3250846862793\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6736, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1580, Loss: 45.673583984375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.9578, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1581, Loss: 41.957847595214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9175, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1582, Loss: 51.917476654052734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.2112, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1583, Loss: 58.211177825927734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.9490, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1584, Loss: 53.948997497558594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.5654, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1585, Loss: 58.56541061401367\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1059, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1586, Loss: 47.10588455200195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.3094, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1587, Loss: 34.30940246582031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.4034, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1588, Loss: 39.40337371826172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.4465, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1589, Loss: 37.44651794433594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.6271, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1590, Loss: 57.62710189819336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.1703, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1591, Loss: 49.17030715942383\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.1866, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1592, Loss: 43.1866340637207\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6813, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1593, Loss: 51.68128204345703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.0193, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1594, Loss: 60.019317626953125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.7754, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1595, Loss: 46.77538299560547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.2200, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1596, Loss: 57.21999740600586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.8693, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1597, Loss: 58.86931228637695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.0381, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1598, Loss: 55.03812789916992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2580, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1599, Loss: 49.25804901123047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(76.6873, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1600, Loss: 76.68727111816406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.5840, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1601, Loss: 48.5839729309082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.1638, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1602, Loss: 59.163795471191406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.6567, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1603, Loss: 37.65673065185547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0596, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1604, Loss: 44.059574127197266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6481, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1605, Loss: 51.64809036254883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(77.7460, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1606, Loss: 77.74595642089844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.9518, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1607, Loss: 50.95182418823242\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9077, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1608, Loss: 47.90772247314453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6648, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1609, Loss: 50.66478729248047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.3694, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1610, Loss: 53.369449615478516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.0316, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1611, Loss: 64.03162384033203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.9115, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1612, Loss: 45.911529541015625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4237, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1613, Loss: 55.42368698120117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.6731, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1614, Loss: 48.673099517822266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.5878, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1615, Loss: 51.58778381347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.7556, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1616, Loss: 67.75560760498047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.7366, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1617, Loss: 57.73663330078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.7282, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1618, Loss: 70.72818756103516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0103, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1619, Loss: 44.010337829589844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1014, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1620, Loss: 50.10142517089844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.6677, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1621, Loss: 43.66774368286133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.0280, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1622, Loss: 71.02799987792969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(73.8183, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1623, Loss: 73.81825256347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.0129, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1624, Loss: 46.01289367675781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.8231, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1625, Loss: 66.82305908203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.5453, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1626, Loss: 54.545326232910156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.5832, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1627, Loss: 42.583229064941406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.2369, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1628, Loss: 62.2369270324707\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.1562, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1629, Loss: 49.156219482421875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3166, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1630, Loss: 47.31661605834961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.8944, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1631, Loss: 47.894432067871094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.1116, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1632, Loss: 60.111637115478516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.3915, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1633, Loss: 40.39154052734375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2408, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1634, Loss: 53.2408447265625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.1546, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1635, Loss: 51.15460205078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.0539, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1636, Loss: 42.05393981933594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.8660, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1637, Loss: 53.865962982177734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.4294, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1638, Loss: 54.429439544677734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.0121, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1639, Loss: 57.01212692260742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2758, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1640, Loss: 48.275794982910156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.0596, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1641, Loss: 59.059593200683594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2363, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1642, Loss: 48.236297607421875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.0263, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1643, Loss: 53.026336669921875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2355, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1644, Loss: 52.23552322387695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(74.0053, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1645, Loss: 74.00531005859375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.4233, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1646, Loss: 47.42328643798828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.7318, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1647, Loss: 63.73177719116211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9518, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1648, Loss: 48.95178985595703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3623, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1649, Loss: 47.36233139038086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8329, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1650, Loss: 49.83289337158203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8964, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1651, Loss: 42.89641571044922\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.4023, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1652, Loss: 59.402286529541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1864, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1653, Loss: 52.18641662597656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.9418, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1654, Loss: 40.94175338745117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.2865, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1655, Loss: 58.286468505859375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9679, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1656, Loss: 54.96786117553711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.7655, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1657, Loss: 58.76552963256836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.4275, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1658, Loss: 58.42753982543945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.5126, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1659, Loss: 49.51256561279297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.9156, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1660, Loss: 45.915618896484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4457, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1661, Loss: 56.44570541381836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.3401, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1662, Loss: 58.340145111083984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.0216, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1663, Loss: 64.02159881591797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7800, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1664, Loss: 48.77995300292969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.0384, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1665, Loss: 70.03840637207031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8985, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1666, Loss: 51.89851379394531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(71.9444, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1667, Loss: 71.94438934326172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7727, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1668, Loss: 48.77272033691406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9623, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1669, Loss: 43.96230697631836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.7395, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1670, Loss: 72.73951721191406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.2457, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1671, Loss: 37.24567413330078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.8187, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1672, Loss: 40.818748474121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3434, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1673, Loss: 48.34335708618164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9855, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1674, Loss: 48.98554992675781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.3465, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1675, Loss: 59.34654235839844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.0667, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1676, Loss: 49.066673278808594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.6060, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1677, Loss: 58.605953216552734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8666, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1678, Loss: 49.866580963134766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.4390, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1679, Loss: 48.43898010253906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1209, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1680, Loss: 47.120880126953125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.9455, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1681, Loss: 50.94551467895508\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0247, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1682, Loss: 44.024662017822266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.5518, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1683, Loss: 61.55180358886719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.6814, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1684, Loss: 56.681419372558594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4013, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1685, Loss: 56.401309967041016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.1596, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1686, Loss: 40.15956115722656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.0068, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1687, Loss: 59.00680923461914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.9740, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1688, Loss: 40.973995208740234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.1305, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1689, Loss: 60.1304931640625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.7101, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1690, Loss: 47.71013259887695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.7689, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1691, Loss: 58.76889419555664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3969, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1692, Loss: 51.39686584472656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.5656, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1693, Loss: 48.56564712524414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.1449, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1694, Loss: 54.144893646240234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8979, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1695, Loss: 45.89787673950195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.2974, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1696, Loss: 45.29737854003906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.3462, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1697, Loss: 49.346187591552734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.4840, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1698, Loss: 50.48396301269531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.8414, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1699, Loss: 48.84138488769531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9547, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1700, Loss: 48.95465850830078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.1720, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1701, Loss: 55.17196273803711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.6098, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1702, Loss: 50.609832763671875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.9035, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1703, Loss: 59.903480529785156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.8911, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1704, Loss: 56.89114761352539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.5546, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1705, Loss: 55.554595947265625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8067, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1706, Loss: 49.80671691894531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.1287, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1707, Loss: 68.12874603271484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.9943, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1708, Loss: 45.9942512512207\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.4979, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1709, Loss: 46.49790954589844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.8272, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1710, Loss: 50.82720947265625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.2780, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1711, Loss: 41.27797317504883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7447, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1712, Loss: 54.74474334716797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.3179, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1713, Loss: 40.31792449951172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0316, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1714, Loss: 44.03160095214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9637, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1715, Loss: 43.963722229003906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.7520, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1716, Loss: 60.75204086303711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(74.0979, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1717, Loss: 74.09786224365234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.7424, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1718, Loss: 49.74235534667969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.6508, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1719, Loss: 43.650779724121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.0142, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1720, Loss: 45.01416015625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.9968, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1721, Loss: 42.99679946899414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.8366, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1722, Loss: 43.83660125732422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.0209, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1723, Loss: 48.0208625793457\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.7650, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1724, Loss: 53.76496505737305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.7948, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1725, Loss: 40.79481506347656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0233, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1726, Loss: 51.02328872680664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.9809, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1727, Loss: 64.98089599609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.5345, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1728, Loss: 34.53446578979492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.1667, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1729, Loss: 48.16671371459961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1476, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1730, Loss: 52.14764404296875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.1771, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1731, Loss: 42.17713928222656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4537, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1732, Loss: 51.45368194580078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.7735, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1733, Loss: 45.77347183227539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.3678, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1734, Loss: 68.36781311035156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1678, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1735, Loss: 52.16778564453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.9780, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1736, Loss: 36.97800064086914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.9582, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1737, Loss: 68.95817565917969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.8298, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1738, Loss: 47.82980728149414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(76.2037, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1739, Loss: 76.20366668701172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.2221, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1740, Loss: 45.22209548950195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7738, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1741, Loss: 43.7738037109375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.3558, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1742, Loss: 49.35581970214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.1592, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1743, Loss: 48.159175872802734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8072, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1744, Loss: 39.807220458984375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.2259, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1745, Loss: 50.225852966308594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9949, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1746, Loss: 47.994873046875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.3231, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1747, Loss: 53.3231086730957\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7410, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1748, Loss: 54.74100875854492\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4689, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1749, Loss: 56.46893310546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(70.3413, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1750, Loss: 70.34127807617188\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.8858, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1751, Loss: 48.885807037353516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.0037, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1752, Loss: 35.00373458862305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.3423, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1753, Loss: 60.3422966003418\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7328, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1754, Loss: 50.732826232910156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.5662, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1755, Loss: 63.566219329833984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.8372, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1756, Loss: 64.83722686767578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.9877, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1757, Loss: 44.98769760131836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.5738, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1758, Loss: 46.57375717163086\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.5998, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1759, Loss: 49.59984588623047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(73.7729, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1760, Loss: 73.77286529541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.1491, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1761, Loss: 38.149078369140625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2314, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1762, Loss: 46.23139572143555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.7887, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1763, Loss: 41.78871536254883\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7179, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1764, Loss: 42.717933654785156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(68.7500, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1765, Loss: 68.74998474121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7554, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1766, Loss: 43.755409240722656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8893, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1767, Loss: 39.88934326171875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(84.0156, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1768, Loss: 84.01560974121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.6912, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1769, Loss: 61.69123458862305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.7169, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1770, Loss: 38.71685791015625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.2270, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1771, Loss: 50.22697448730469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.8575, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1772, Loss: 47.85749435424805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.7620, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1773, Loss: 48.76200866699219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.0948, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1774, Loss: 46.094757080078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.3026, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1775, Loss: 42.30257034301758\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.2643, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1776, Loss: 49.26432800292969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.2500, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1777, Loss: 48.249996185302734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.1631, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1778, Loss: 42.16305160522461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.3050, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1779, Loss: 45.30503845214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.5702, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1780, Loss: 36.57018280029297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(69.6926, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1781, Loss: 69.6926040649414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.1961, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1782, Loss: 58.19612503051758\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.0283, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1783, Loss: 64.02825164794922\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.2932, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1784, Loss: 56.293243408203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.9133, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1785, Loss: 40.913299560546875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.8232, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1786, Loss: 52.823158264160156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.5631, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1787, Loss: 50.56313705444336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.6736, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1788, Loss: 40.6735725402832\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.3321, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1789, Loss: 45.332115173339844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0592, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1790, Loss: 44.05916213989258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.7265, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1791, Loss: 38.726524353027344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.0667, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1792, Loss: 37.066654205322266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.4097, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1793, Loss: 48.40965270996094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.1928, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1794, Loss: 38.19282150268555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(30.4290, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1795, Loss: 30.428997039794922\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.0661, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1796, Loss: 44.06612777709961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3288, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1797, Loss: 54.328758239746094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.4595, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1798, Loss: 48.45954513549805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.7758, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1799, Loss: 39.77579879760742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.4221, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1800, Loss: 52.422115325927734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.3843, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1801, Loss: 56.384300231933594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.4505, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1802, Loss: 43.45051574707031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.1807, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1803, Loss: 46.1806526184082\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.4232, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1804, Loss: 66.4232406616211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6588, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1805, Loss: 47.6588020324707\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.0412, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1806, Loss: 36.041221618652344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4535, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1807, Loss: 55.45347213745117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.2094, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1808, Loss: 46.20936965942383\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1397, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1809, Loss: 52.13972854614258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.7069, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1810, Loss: 49.706939697265625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7548, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1811, Loss: 50.75480270385742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.2906, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1812, Loss: 52.2906494140625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0393, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1813, Loss: 51.039276123046875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3923, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1814, Loss: 54.392295837402344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1520, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1815, Loss: 47.15202331542969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.2470, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1816, Loss: 41.24702453613281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.7169, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1817, Loss: 58.71685028076172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.8741, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1818, Loss: 43.874053955078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.1876, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1819, Loss: 66.18757629394531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.0764, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1820, Loss: 48.076377868652344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4443, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1821, Loss: 51.444271087646484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.3164, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1822, Loss: 43.316402435302734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8511, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1823, Loss: 57.85111618041992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0829, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1824, Loss: 50.08287048339844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(74.9580, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1825, Loss: 74.95800018310547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.8375, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1826, Loss: 54.837467193603516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.0152, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1827, Loss: 72.0152359008789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.1372, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1828, Loss: 61.13718032836914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.4065, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1829, Loss: 51.40650177001953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6834, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1830, Loss: 45.683414459228516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.6787, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1831, Loss: 59.67866134643555\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.8466, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1832, Loss: 55.84659194946289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.6907, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1833, Loss: 43.690738677978516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.7055, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1834, Loss: 54.70552062988281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.3729, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1835, Loss: 37.37293243408203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.3630, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1836, Loss: 66.3630142211914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6102, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1837, Loss: 47.61024856567383\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3106, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1838, Loss: 48.31061553955078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.8814, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1839, Loss: 44.88138198852539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.3405, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1840, Loss: 37.3404541015625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.4252, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1841, Loss: 43.42516326904297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.5611, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1842, Loss: 59.561126708984375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.7550, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1843, Loss: 57.75498580932617\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.9963, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1844, Loss: 52.99634552001953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0182, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1845, Loss: 50.018192291259766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1157, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1846, Loss: 52.11571502685547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.0923, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1847, Loss: 50.092323303222656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6049, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1848, Loss: 46.604923248291016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.5590, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1849, Loss: 48.5589599609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.3098, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1850, Loss: 52.3098258972168\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.1655, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1851, Loss: 41.16552734375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.5190, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1852, Loss: 47.51895523071289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.6597, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1853, Loss: 48.659690856933594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.0874, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1854, Loss: 47.087432861328125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.5233, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1855, Loss: 54.52326202392578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.9276, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1856, Loss: 60.92756271362305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.8737, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1857, Loss: 40.873661041259766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.4146, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1858, Loss: 38.41456985473633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.3377, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1859, Loss: 34.337730407714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.2283, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1860, Loss: 72.2282943725586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.5484, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1861, Loss: 44.54841232299805\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.5254, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1862, Loss: 40.52539825439453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.0982, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1863, Loss: 54.09818649291992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.6207, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1864, Loss: 40.620723724365234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.3779, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1865, Loss: 58.377891540527344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.0616, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1866, Loss: 55.06160354614258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2392, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1867, Loss: 54.23915481567383\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.2298, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1868, Loss: 41.229759216308594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5378, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1869, Loss: 45.537803649902344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.3618, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1870, Loss: 53.36178207397461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.3442, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1871, Loss: 61.34417724609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.9261, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1872, Loss: 55.92607116699219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.9968, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1873, Loss: 39.99678421020508\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(76.1837, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1874, Loss: 76.18367004394531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.6594, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1875, Loss: 36.65937805175781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8797, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1876, Loss: 46.87971496582031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.7487, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1877, Loss: 53.74870681762695\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(32.2244, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1878, Loss: 32.22444152832031\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.0561, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1879, Loss: 60.05610656738281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.7221, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1880, Loss: 49.72211456298828\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.4657, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1881, Loss: 49.46574020385742\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.1612, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1882, Loss: 44.16122817993164\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.2056, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1883, Loss: 39.205604553222656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.8511, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1884, Loss: 61.851051330566406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8319, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1885, Loss: 57.83192825317383\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.8742, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1886, Loss: 42.87424087524414\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(67.5715, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1887, Loss: 67.57146453857422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.0948, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1888, Loss: 62.09480667114258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.1942, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1889, Loss: 42.19416427612305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.9163, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1890, Loss: 57.916297912597656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.3593, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1891, Loss: 55.35927963256836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.5665, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1892, Loss: 45.56648254394531\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.5037, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1893, Loss: 44.50366973876953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.2969, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1894, Loss: 61.29692459106445\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.6729, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1895, Loss: 47.672882080078125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.8380, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1896, Loss: 58.837955474853516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0362, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1897, Loss: 51.036197662353516\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.6935, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1898, Loss: 58.6934814453125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.7833, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1899, Loss: 60.78334045410156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.1163, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1900, Loss: 42.116294860839844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(59.8124, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1901, Loss: 59.812442779541016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.3076, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1902, Loss: 46.30763244628906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.3918, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1903, Loss: 38.391788482666016\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.9031, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1904, Loss: 49.9030647277832\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.8440, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1905, Loss: 44.843994140625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.5692, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1906, Loss: 57.56915283203125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.1915, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1907, Loss: 45.191524505615234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.2318, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1908, Loss: 56.23183822631836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.8147, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1909, Loss: 60.81471633911133\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.0989, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1910, Loss: 46.098899841308594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.6231, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1911, Loss: 51.62308883666992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(36.8361, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1912, Loss: 36.83610534667969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.4829, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1913, Loss: 54.48291778564453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.5292, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1914, Loss: 56.529170989990234\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.0863, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1915, Loss: 34.086326599121094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(66.8549, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1916, Loss: 66.85488891601562\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(37.3808, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1917, Loss: 37.380775451660156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8780, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1918, Loss: 51.877986907958984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.3940, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1919, Loss: 54.39399719238281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1366, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1920, Loss: 50.13664245605469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8802, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1921, Loss: 45.88023376464844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.0136, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1922, Loss: 56.013641357421875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0919, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1923, Loss: 52.09185028076172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.2668, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1924, Loss: 47.26676940917969\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(30.2539, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1925, Loss: 30.25388526916504\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.8057, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1926, Loss: 57.80574417114258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.5184, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1927, Loss: 41.51842498779297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.9136, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1928, Loss: 47.91361999511719\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.1805, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1929, Loss: 52.18053436279297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.4995, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1930, Loss: 46.49946594238281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.5282, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1931, Loss: 43.52821350097656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.3169, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1932, Loss: 53.31690216064453\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.3744, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1933, Loss: 41.374393463134766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.2763, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1934, Loss: 54.276283264160156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.2811, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1935, Loss: 50.281105041503906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.1110, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1936, Loss: 47.11102294921875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.6765, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1937, Loss: 34.67650604248047\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.0172, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1938, Loss: 48.0172004699707\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.3253, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1939, Loss: 62.32526397705078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.8636, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1940, Loss: 39.86359786987305\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.5380, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1941, Loss: 52.53797149658203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.1793, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1942, Loss: 49.17934799194336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.0773, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1943, Loss: 52.07730484008789\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.4852, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1944, Loss: 62.4852294921875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.7532, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1945, Loss: 49.75315856933594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.1465, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1946, Loss: 64.146484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.8593, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1947, Loss: 45.85928726196289\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.4275, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1948, Loss: 40.42751693725586\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.7091, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1949, Loss: 56.709129333496094\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.1312, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1950, Loss: 40.131202697753906\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3901, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1951, Loss: 51.3901481628418\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.4593, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1952, Loss: 41.45933532714844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(72.5151, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1953, Loss: 72.51512908935547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(39.1145, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1954, Loss: 39.11451721191406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.0279, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1955, Loss: 47.02794647216797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.7772, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1956, Loss: 43.77719497680664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.7979, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1957, Loss: 50.79793167114258\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9334, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1958, Loss: 43.93343734741211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.6096, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1959, Loss: 57.60955047607422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.5419, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1960, Loss: 53.54191970825195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.4144, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1961, Loss: 48.41440963745117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3750, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1962, Loss: 47.37497329711914\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.5426, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1963, Loss: 46.54258728027344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.7992, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1964, Loss: 46.79924011230469\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(40.4257, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1965, Loss: 40.42566680908203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.4152, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1966, Loss: 57.41522216796875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.4141, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1967, Loss: 63.41410446166992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.0367, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1968, Loss: 41.03673553466797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.7664, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1969, Loss: 52.76641082763672\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.2666, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1970, Loss: 44.26663589477539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.5225, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1971, Loss: 44.52248001098633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3897, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1972, Loss: 47.3896598815918\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.1237, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1973, Loss: 51.123748779296875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.0288, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1974, Loss: 48.02876281738281\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(61.3363, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1975, Loss: 61.33631896972656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.8988, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1976, Loss: 51.898807525634766\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.9369, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1977, Loss: 41.9368782043457\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.5631, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1978, Loss: 51.56305694580078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9803, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1979, Loss: 54.980281829833984\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.3378, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1980, Loss: 53.33777618408203\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.1480, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1981, Loss: 35.148040771484375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.4914, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1982, Loss: 55.491363525390625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.3019, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1983, Loss: 48.30188751220703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.6631, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1984, Loss: 46.663108825683594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3801, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1985, Loss: 51.38008117675781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.2659, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1986, Loss: 62.265869140625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.3335, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1987, Loss: 47.33349609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.0664, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1988, Loss: 51.06644058227539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.6659, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1989, Loss: 43.6659049987793\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.9346, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1990, Loss: 43.93461227416992\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(57.1702, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1991, Loss: 57.17023468017578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(49.8767, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1992, Loss: 49.87669372558594\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(76.0298, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1993, Loss: 76.02978515625\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.5551, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1994, Loss: 63.555137634277344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(75.6925, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1995, Loss: 75.6925277709961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.9563, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1996, Loss: 48.95631408691406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(64.3986, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1997, Loss: 64.39863586425781\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.1356, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1998, Loss: 63.1356315612793\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.6012, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 1999, Loss: 45.60124969482422\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.1489, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2000, Loss: 46.148860931396484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.8743, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2001, Loss: 50.87427520751953\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.0490, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2002, Loss: 55.04901123046875\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.7120, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2003, Loss: 53.71198272705078\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.6403, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2004, Loss: 52.64026641845703\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.0730, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2005, Loss: 48.0729866027832\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.6631, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2006, Loss: 38.66310501098633\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.1829, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2007, Loss: 45.18292999267578\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.6369, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2008, Loss: 58.63691329956055\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(73.3313, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2009, Loss: 73.33131408691406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(54.9387, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2010, Loss: 54.93873596191406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.9973, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2011, Loss: 42.99728012084961\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.5182, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2012, Loss: 42.51818084716797\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(45.7244, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2013, Loss: 45.72439956665039\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.2442, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2014, Loss: 35.24424743652344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.1025, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2015, Loss: 44.102474212646484\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(34.1353, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2016, Loss: 34.13534164428711\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.7251, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2017, Loss: 42.72513198852539\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.8960, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2018, Loss: 63.89604949951172\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.3439, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2019, Loss: 53.34385681152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(62.0336, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2020, Loss: 62.03363037109375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.3745, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2021, Loss: 56.374507904052734\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.2401, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2022, Loss: 60.24010467529297\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(48.0001, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2023, Loss: 48.00010681152344\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.7729, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2024, Loss: 35.772865295410156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.5825, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2025, Loss: 43.58245849609375\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(35.7620, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2026, Loss: 35.7619743347168\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(43.4755, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2027, Loss: 43.47547912597656\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(65.3501, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2028, Loss: 65.35012817382812\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.4496, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2029, Loss: 47.44955825805664\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.5512, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2030, Loss: 51.55123519897461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(46.8488, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2031, Loss: 46.8487548828125\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(58.9398, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2032, Loss: 58.93984603881836\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(44.5024, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2033, Loss: 44.50237274169922\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.3371, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2034, Loss: 51.33705139160156\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(38.5961, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2035, Loss: 38.59611892700195\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(52.3841, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2036, Loss: 52.38413619995117\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(56.4731, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2037, Loss: 56.473121643066406\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(42.0903, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2038, Loss: 42.09029769897461\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.6185, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2039, Loss: 41.61849594116211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(55.1378, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2040, Loss: 55.13784408569336\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(60.5575, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2041, Loss: 60.557456970214844\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(50.1414, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2042, Loss: 50.14144515991211\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.5908, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2043, Loss: 53.59081268310547\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(53.2096, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2044, Loss: 53.2095832824707\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(63.3076, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2045, Loss: 63.307621002197266\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(41.8406, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2046, Loss: 41.84062576293945\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(51.9021, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2047, Loss: 51.90214538574219\n",
            "Text features (tensor size):  512\n",
            "clipout torch.Size([1, 512])\n",
            "tensor(47.2211, device='cuda:0', grad_fn=<LinalgVectorNormBackward0>)\n",
            "Iter 2048, Loss: 47.221134185791016\n"
          ]
        }
      ],
      "source": [
        "keywords = [\"blonde\", \"bald\", \"brown\", \"black\", \"blue\", \"yellow\", \"green\", \"long\", \"short\", \"eye\", \"angry\", \"sad\", \"happy\", \"excited\", \"red\", \"glasses\", \"pink\", \"gray\", \"grey\", \"bright\", \"dark\", \"curly\", \"straight\", \"beard\"]\n",
        "nb_iter = 2048\n",
        "losses = []\n",
        "for idx in tqdm(range(nb_iter)):\n",
        "\n",
        "  '''\n",
        "  z = torch.randn([1, G.z_dim]).to(device)\n",
        "  w = G.mapping(z, None) # styleGAN output\n",
        "  # w: 1, 16, 512\n",
        "  generated_image = G.synthesis.forward(w)\n",
        "  generated_image = (generated_image.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
        "  width, h = generated_image.size()[1], generated_image.size()[2]\n",
        "\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((width,h),interpolation=InterpolationMode.BICUBIC),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "      ])\n",
        "\n",
        "  generated_image = PIL.Image.fromarray(generated_image[0].cpu().numpy(), 'RGB').resize((256, 256))\n",
        "  image = transform(generated_image).unsqueeze(0).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "      caption = blip_model.generate(image, sample=False, num_beams=3, max_length=20, min_length=10)\n",
        "      num_of_beams = 3\n",
        "      attempts = 0\n",
        "      print('caption: '+caption[0])\n",
        "      while not any(keyword in caption[0] for keyword in keywords) and attempts < 5:\n",
        "        attempts += 1\n",
        "        num_of_beams += 1\n",
        "        caption = blip_model.generate(image, sample=False, num_beams=num_of_beams, max_length=40, min_length=10)\n",
        "        # nucleus sampling\n",
        "        # caption = blip_model.generate(image, sample=True, top_p=0.9, max_length=20, min_length=5)\n",
        "        print('caption: '+caption[0])\n",
        "      print(\"---------------\")\n",
        "  blipout = caption[0] # BLIP's output (description of a StyleGAN-generated image)\n",
        "  '''\n",
        "\n",
        "  blipout = df.iloc[idx, 1] # GET CAPTION FROM DATASET\n",
        "\n",
        "\n",
        "### CLIP\n",
        "  text = clip.tokenize([blipout]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      #image_features = clip_model.encode_image(image)\n",
        "      text_features = clip_model.encode_text(text)\n",
        "      #logits_per_image, logits_per_text = clip_model(image, text)\n",
        "      #probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "  #print(\"Image-text similarity:\", logits_per_image.cpu().numpy())  # prints: [[24.815384]]\n",
        "  #print(\"Label probabilities:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]\n",
        "  #print(\"Image features (tensor size): \",len(image_features[0]))\n",
        "  print(\"Text features (tensor size): \",len(text_features[0]))\n",
        "\n",
        "  #z = torch.randn([1, G.z_dim]).cpu()   # random latent codes\n",
        "  clipout = text_features                # THIS IS OUR AIM #TODO\n",
        "  #it is same size tensor but output of stylegan2 is different imag\n",
        "  print(\"clipout\", clipout.shape)\n",
        "  #----\n",
        "  clipout = clipout.view(1, 1, 512)\n",
        "\n",
        "  #for i in range(3):\n",
        "  optimizer.zero_grad()\n",
        "  a = encoder(clipout)\n",
        "\n",
        "  # GET W LATENT SPACE FROM DATASET\n",
        "  tensor_name = \"dataset/tensors/\" + str(df.iloc[idx, 0]) + \".pt\"\n",
        "  w = torch.load(tensor_name, map_location='cuda:0')\n",
        "  w.to(device)\n",
        "\n",
        "  loss = loss_calc_l2(w, torch.reshape(a, (1,16,512)))\n",
        "  print(loss)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  losses.append(loss.item())\n",
        "  print(f\"Iter {idx+1}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZJJP_KwxyuD9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prompts:\n",
        "captions = ['a man with sunglasses',\n",
        "            'a man with beard',\n",
        "            'a smiling baby',\n",
        "            'a woman with curly hair',\n",
        "            'a man in a suit and a tie',\n",
        "            'a little girl',\n",
        "            'an old man with blue eyes',\n",
        "            'an old woman',\n",
        "            'an angry man',\n",
        "            'a woman with long black hair',\n",
        "            'a child with brown hair']\n",
        "# Read dataset/image_captions_cleaned captions with pandas:\n",
        "dtype_dict = {'name': str, 'caption': str}\n",
        "df2 = pd.read_csv('dataset/image_captions_cleaned.txt', sep=\",\", header=0, dtype=dtype_dict)\n",
        "saved_captions = df2['caption'].tolist()\n",
        "\n",
        "# \"a man with glasses\", \"a child\", \"a child with black hairs and blue eyes\"\n",
        "\n",
        "def Inference(caption, current_time, save_fig = True, show_pic = True, index = None):\n",
        "    encoder.eval()  # Ensure the encoder is in eval mode\n",
        "    G.eval()  # Ensure the StyleGAN generator is in eval modee\n",
        "    # Tokenize and encode the text description using CLIP\n",
        "    #caption = \"a child with black hairs and blue eyes\"\n",
        "    tokens = clip.tokenize([caption]).to(device)\n",
        "    text_embedding = clip_model.encode_text(tokens).float()\n",
        "    # Use the trained encoder to predict the latent vector\n",
        "    with torch.no_grad():\n",
        "        #ard(text_embedding, None)  # Unsqueeze to add batch dimensio\n",
        "        latent_vector = encoder(text_embedding)  # Unsqueeze\n",
        "        latent_vector = torch.reshape(latent_vector, (1,16,512)) + 0.3 * G.mapping(torch.randn([1, G.z_dim]).to(device),None)\n",
        "\n",
        "    # Generate an image using the predicted latent vector with StyleGAN\n",
        "    generated_image = G.synthesis(torch.reshape(latent_vector, (1,16,512)))\n",
        "    generated_image = (generated_image.clamp(-1, 1) + 1) / 2  # Normalize to [0, 1]\n",
        "    generated_image = generated_image.cpu().permute(0, 2, 3, 1).numpy()  # Adjust dimensions for image display\n",
        "    generated_image = (generated_image * 255).astype('uint8')  # Convert to uint\n",
        "\n",
        "    # Convert to PIL Image for display\n",
        "    generated_image = Image.fromarray(generated_image[0])\n",
        "\n",
        "    # Display image with caption\n",
        "    #plt.imshow(generated_image)\n",
        "    #plt.title(caption)\n",
        "    #plt.axis('off')  # Turn off axis\n",
        "\n",
        "    # save figure\n",
        "    if save_fig == True and index == None:\n",
        "        try:\n",
        "            generated_image.save(f'inference/{current_time}/{caption}.png') # save image\n",
        "            #PIL.Image.fromarray(generated_image.to(device).numpy(), 'RGB').save(f'inference/{current_time}/{caption}.png') # save image\n",
        "            #plt.savefig(f'inference/{current_time}/{caption}.png')\n",
        "        except:\n",
        "            try:\n",
        "                os.mkdir(f'inference/{current_time}')\n",
        "                generated_image.save(f'inference/{current_time}/{caption}.png') # save image\n",
        "                #plt.savefig(f'inference/{current_time}/{caption}.png')\n",
        "                #PIL.Image.fromarray(generated_image.to(device).numpy(), 'RGB').save(f'inference/{current_time}/{caption}.png') # save image\n",
        "            except:\n",
        "                os.mkdir('./inference')\n",
        "                os.mkdir(f'inference/{current_time}')\n",
        "                generated_image.save(f'inference/{current_time}/{caption}.png') # save image\n",
        "                #plt.savefig(f'inference/{current_time}/{caption}.png')\n",
        "                #PIL.Image.fromarray(generated_image.to(device).numpy(), 'RGB').save(f'inference/{current_time}/{caption}.png') # save image\n",
        "    elif save_fig == True and index != None:\n",
        "            try:\n",
        "                generated_image.save(f'inference/{current_time}/{index:05d}.png') # save image\n",
        "                #PIL.Image.fromarray(generated_image.to(device).numpy(), 'RGB').save(f'inference/{current_time}/{caption}.png') # save image\n",
        "                #plt.savefig(f'inference/{current_time}/{caption}.png')\n",
        "            except:\n",
        "                try:\n",
        "                    os.mkdir(f'inference/{current_time}')\n",
        "                    generated_image.save(f'inference/{current_time}/{index:05d}.png') # save image\n",
        "                    #plt.savefig(f'inference/{current_time}/{caption}.png')\n",
        "                    #PIL.Image.fromarray(generated_image.to(device).numpy(), 'RGB').save(f'inference/{current_time}/{caption}.png') # save image\n",
        "                except:\n",
        "                    os.mkdir('./inference')\n",
        "                    os.mkdir(f'inference/{current_time}')\n",
        "                    generated_image.save(f'inference/{current_time}/{index:05d}.png') # save image\n",
        "                    #plt.savefig(f'inference/{current_time}/{caption}.png')\n",
        "                    #PIL.Image.fromarray(generated_image.to(device).numpy(), 'RGB').save(f'inference/{current_time}/{caption}.png') # save image\n",
        "\n",
        "    if show_pic == True:\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "c9b0fa72dd22433988ddda78bc36f2cc",
            "d2d1a881eeec46b88370797410dca11f",
            "d9d9cc6480bb456d81d8b764b5caacf0",
            "256afac74e6e4dc3870b22ae338717af",
            "1da19676282649d1a97df9c182892312",
            "6e4839096a654f3299bdd60efe29d36c",
            "063f87ec6fe34988bc2db11108e67fe8",
            "749bb6b5f15a4023ad0da3b8e5300448",
            "88d10d7b5d2447babac9621968ce34b0",
            "6dd477f3a90747fa95e7737c1f8bd566",
            "82cdf5aeb98a4bf7b938f685f84f39dc"
          ]
        },
        "id": "0YlqJsbq7I7b",
        "outputId": "4bf454ef-1552-4692-ccd4-37562de4ea47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2048 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9b0fa72dd22433988ddda78bc36f2cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "2048 images are saved.\n"
          ]
        }
      ],
      "source": [
        "# Multiple captions in loop\n",
        "from datetime import datetime\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "current_time = 'stylegan2-db'\n",
        "index = 0\n",
        "for idx in tqdm(saved_captions):\n",
        "    index += 1\n",
        "    Inference(idx, current_time, save_fig = True, show_pic = False, index = index)\n",
        "\n",
        "import os\n",
        "print(str(len(os.listdir('/content/inference/'+current_time)))+' images are saved.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd inference && zip -r stylegan2-db.zip stylegan2-db/\n",
        "# To save inference output zip to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r /content/inference/stylegan2-db.zip /content/drive/MyDrive/stylegan2-db.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezR3Wy0faoTK",
        "outputId": "928f6f84-ac0e-4e03-a527-d6804fba7b38"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: stylegan2-db/ (stored 0%)\n",
            "  adding: stylegan2-db/00028.png (deflated 0%)\n",
            "  adding: stylegan2-db/01195.png (deflated 0%)\n",
            "  adding: stylegan2-db/01462.png (deflated 0%)\n",
            "  adding: stylegan2-db/01921.png (deflated 0%)\n",
            "  adding: stylegan2-db/00456.png (deflated 0%)\n",
            "  adding: stylegan2-db/01895.png (deflated 0%)\n",
            "  adding: stylegan2-db/00757.png (deflated 0%)\n",
            "  adding: stylegan2-db/00500.png (deflated 0%)\n",
            "  adding: stylegan2-db/00813.png (deflated 0%)\n",
            "  adding: stylegan2-db/00304.png (deflated 0%)\n",
            "  adding: stylegan2-db/02032.png (deflated 0%)\n",
            "  adding: stylegan2-db/00778.png (deflated 0%)\n",
            "  adding: stylegan2-db/00146.png (deflated 0%)\n",
            "  adding: stylegan2-db/00683.png (deflated 0%)\n",
            "  adding: stylegan2-db/00242.png (deflated 0%)\n",
            "  adding: stylegan2-db/01394.png (deflated 0%)\n",
            "  adding: stylegan2-db/00420.png (deflated 0%)\n",
            "  adding: stylegan2-db/01214.png (deflated 0%)\n",
            "  adding: stylegan2-db/00012.png (deflated 0%)\n",
            "  adding: stylegan2-db/01175.png (deflated 0%)\n",
            "  adding: stylegan2-db/01654.png (deflated 0%)\n",
            "  adding: stylegan2-db/01157.png (deflated 0%)\n",
            "  adding: stylegan2-db/01299.png (deflated 0%)\n",
            "  adding: stylegan2-db/00225.png (deflated 0%)\n",
            "  adding: stylegan2-db/02038.png (deflated 0%)\n",
            "  adding: stylegan2-db/00298.png (deflated 0%)\n",
            "  adding: stylegan2-db/01008.png (deflated 0%)\n",
            "  adding: stylegan2-db/00197.png (deflated 0%)\n",
            "  adding: stylegan2-db/00396.png (deflated 0%)\n",
            "  adding: stylegan2-db/00300.png (deflated 0%)\n",
            "  adding: stylegan2-db/00722.png (deflated 0%)\n",
            "  adding: stylegan2-db/01416.png (deflated 0%)\n",
            "  adding: stylegan2-db/00506.png (deflated 0%)\n",
            "  adding: stylegan2-db/01959.png (deflated 0%)\n",
            "  adding: stylegan2-db/01158.png (deflated 0%)\n",
            "  adding: stylegan2-db/00894.png (deflated 0%)\n",
            "  adding: stylegan2-db/01684.png (deflated 0%)\n",
            "  adding: stylegan2-db/00956.png (deflated 0%)\n",
            "  adding: stylegan2-db/00377.png (deflated 0%)\n",
            "  adding: stylegan2-db/00936.png (deflated 0%)\n",
            "  adding: stylegan2-db/01954.png (deflated 0%)\n",
            "  adding: stylegan2-db/00395.png (deflated 0%)\n",
            "  adding: stylegan2-db/00999.png (deflated 0%)\n",
            "  adding: stylegan2-db/00824.png (deflated 0%)\n",
            "  adding: stylegan2-db/01584.png (deflated 0%)\n",
            "  adding: stylegan2-db/01430.png (deflated 0%)\n",
            "  adding: stylegan2-db/01112.png (deflated 0%)\n",
            "  adding: stylegan2-db/01223.png (deflated 0%)\n",
            "  adding: stylegan2-db/01089.png (deflated 0%)\n",
            "  adding: stylegan2-db/00497.png (deflated 0%)\n",
            "  adding: stylegan2-db/00020.png (deflated 0%)\n",
            "  adding: stylegan2-db/01696.png (deflated 0%)\n",
            "  adding: stylegan2-db/00200.png (deflated 0%)\n",
            "  adding: stylegan2-db/00584.png (deflated 0%)\n",
            "  adding: stylegan2-db/00792.png (deflated 0%)\n",
            "  adding: stylegan2-db/01887.png (deflated 0%)\n",
            "  adding: stylegan2-db/01000.png (deflated 0%)\n",
            "  adding: stylegan2-db/01047.png (deflated 0%)\n",
            "  adding: stylegan2-db/00527.png (deflated 0%)\n",
            "  adding: stylegan2-db/01805.png (deflated 0%)\n",
            "  adding: stylegan2-db/00088.png (deflated 0%)\n",
            "  adding: stylegan2-db/00160.png (deflated 0%)\n",
            "  adding: stylegan2-db/01889.png (deflated 0%)\n",
            "  adding: stylegan2-db/00684.png (deflated 0%)\n",
            "  adding: stylegan2-db/01414.png (deflated 0%)\n",
            "  adding: stylegan2-db/01770.png (deflated 0%)\n",
            "  adding: stylegan2-db/00141.png (deflated 0%)\n",
            "  adding: stylegan2-db/00284.png (deflated 0%)\n",
            "  adding: stylegan2-db/00007.png (deflated 0%)\n",
            "  adding: stylegan2-db/01700.png (deflated 0%)\n",
            "  adding: stylegan2-db/00493.png (deflated 0%)\n",
            "  adding: stylegan2-db/01880.png (deflated 0%)\n",
            "  adding: stylegan2-db/01650.png (deflated 0%)\n",
            "  adding: stylegan2-db/01824.png (deflated 0%)\n",
            "  adding: stylegan2-db/00291.png (deflated 0%)\n",
            "  adding: stylegan2-db/01785.png (deflated 0%)\n",
            "  adding: stylegan2-db/00988.png (deflated 0%)\n",
            "  adding: stylegan2-db/00292.png (deflated 0%)\n",
            "  adding: stylegan2-db/01996.png (deflated 0%)\n",
            "  adding: stylegan2-db/01732.png (deflated 0%)\n",
            "  adding: stylegan2-db/00127.png (deflated 0%)\n",
            "  adding: stylegan2-db/00358.png (deflated 0%)\n",
            "  adding: stylegan2-db/00896.png (deflated 0%)\n",
            "  adding: stylegan2-db/01297.png (deflated 0%)\n",
            "  adding: stylegan2-db/01329.png (deflated 0%)\n",
            "  adding: stylegan2-db/00421.png (deflated 0%)\n",
            "  adding: stylegan2-db/01625.png (deflated 0%)\n",
            "  adding: stylegan2-db/01505.png (deflated 0%)\n",
            "  adding: stylegan2-db/01807.png (deflated 0%)\n",
            "  adding: stylegan2-db/01506.png (deflated 0%)\n",
            "  adding: stylegan2-db/01204.png (deflated 0%)\n",
            "  adding: stylegan2-db/01327.png (deflated 0%)\n",
            "  adding: stylegan2-db/00580.png (deflated 0%)\n",
            "  adding: stylegan2-db/00546.png (deflated 0%)\n",
            "  adding: stylegan2-db/01828.png (deflated 0%)\n",
            "  adding: stylegan2-db/00656.png (deflated 0%)\n",
            "  adding: stylegan2-db/01760.png (deflated 0%)\n",
            "  adding: stylegan2-db/00840.png (deflated 0%)\n",
            "  adding: stylegan2-db/01140.png (deflated 0%)\n",
            "  adding: stylegan2-db/01120.png (deflated 0%)\n",
            "  adding: stylegan2-db/01411.png (deflated 0%)\n",
            "  adding: stylegan2-db/00218.png (deflated 0%)\n",
            "  adding: stylegan2-db/01454.png (deflated 0%)\n",
            "  adding: stylegan2-db/00384.png (deflated 0%)\n",
            "  adding: stylegan2-db/00561.png (deflated 0%)\n",
            "  adding: stylegan2-db/01731.png (deflated 0%)\n",
            "  adding: stylegan2-db/00051.png (deflated 0%)\n",
            "  adding: stylegan2-db/00157.png (deflated 0%)\n",
            "  adding: stylegan2-db/01634.png (deflated 0%)\n",
            "  adding: stylegan2-db/00998.png (deflated 0%)\n",
            "  adding: stylegan2-db/00184.png (deflated 0%)\n",
            "  adding: stylegan2-db/00765.png (deflated 0%)\n",
            "  adding: stylegan2-db/01144.png (deflated 0%)\n",
            "  adding: stylegan2-db/01370.png (deflated 0%)\n",
            "  adding: stylegan2-db/01442.png (deflated 0%)\n",
            "  adding: stylegan2-db/01574.png (deflated 0%)\n",
            "  adding: stylegan2-db/00208.png (deflated 0%)\n",
            "  adding: stylegan2-db/01040.png (deflated 0%)\n",
            "  adding: stylegan2-db/01913.png (deflated 0%)\n",
            "  adding: stylegan2-db/01456.png (deflated 0%)\n",
            "  adding: stylegan2-db/01023.png (deflated 0%)\n",
            "  adding: stylegan2-db/01606.png (deflated 0%)\n",
            "  adding: stylegan2-db/00776.png (deflated 0%)\n",
            "  adding: stylegan2-db/01126.png (deflated 0%)\n",
            "  adding: stylegan2-db/01367.png (deflated 0%)\n",
            "  adding: stylegan2-db/01925.png (deflated 0%)\n",
            "  adding: stylegan2-db/00374.png (deflated 0%)\n",
            "  adding: stylegan2-db/00849.png (deflated 0%)\n",
            "  adding: stylegan2-db/00310.png (deflated 0%)\n",
            "  adding: stylegan2-db/01305.png (deflated 0%)\n",
            "  adding: stylegan2-db/00982.png (deflated 0%)\n",
            "  adding: stylegan2-db/01758.png (deflated 0%)\n",
            "  adding: stylegan2-db/00823.png (deflated 0%)\n",
            "  adding: stylegan2-db/01236.png (deflated 0%)\n",
            "  adding: stylegan2-db/01614.png (deflated 0%)\n",
            "  adding: stylegan2-db/00737.png (deflated 0%)\n",
            "  adding: stylegan2-db/01438.png (deflated 0%)\n",
            "  adding: stylegan2-db/01514.png (deflated 0%)\n",
            "  adding: stylegan2-db/00666.png (deflated 0%)\n",
            "  adding: stylegan2-db/00655.png (deflated 0%)\n",
            "  adding: stylegan2-db/01312.png (deflated 0%)\n",
            "  adding: stylegan2-db/01736.png (deflated 0%)\n",
            "  adding: stylegan2-db/00198.png (deflated 0%)\n",
            "  adding: stylegan2-db/00214.png (deflated 0%)\n",
            "  adding: stylegan2-db/00734.png (deflated 0%)\n",
            "  adding: stylegan2-db/00326.png (deflated 0%)\n",
            "  adding: stylegan2-db/00887.png (deflated 0%)\n",
            "  adding: stylegan2-db/01508.png (deflated 0%)\n",
            "  adding: stylegan2-db/01374.png (deflated 0%)\n",
            "  adding: stylegan2-db/00709.png (deflated 0%)\n",
            "  adding: stylegan2-db/00424.png (deflated 0%)\n",
            "  adding: stylegan2-db/00463.png (deflated 0%)\n",
            "  adding: stylegan2-db/00161.png (deflated 0%)\n",
            "  adding: stylegan2-db/00705.png (deflated 0%)\n",
            "  adding: stylegan2-db/00351.png (deflated 0%)\n",
            "  adding: stylegan2-db/01264.png (deflated 0%)\n",
            "  adding: stylegan2-db/00063.png (deflated 0%)\n",
            "  adding: stylegan2-db/01445.png (deflated 0%)\n",
            "  adding: stylegan2-db/01457.png (deflated 0%)\n",
            "  adding: stylegan2-db/01633.png (deflated 0%)\n",
            "  adding: stylegan2-db/01475.png (deflated 0%)\n",
            "  adding: stylegan2-db/00815.png (deflated 0%)\n",
            "  adding: stylegan2-db/01348.png (deflated 0%)\n",
            "  adding: stylegan2-db/01333.png (deflated 0%)\n",
            "  adding: stylegan2-db/00992.png (deflated 0%)\n",
            "  adding: stylegan2-db/01373.png (deflated 0%)\n",
            "  adding: stylegan2-db/01652.png (deflated 0%)\n",
            "  adding: stylegan2-db/00321.png (deflated 0%)\n",
            "  adding: stylegan2-db/00937.png (deflated 0%)\n",
            "  adding: stylegan2-db/01740.png (deflated 0%)\n",
            "  adding: stylegan2-db/01290.png (deflated 0%)\n",
            "  adding: stylegan2-db/01686.png (deflated 0%)\n",
            "  adding: stylegan2-db/01369.png (deflated 0%)\n",
            "  adding: stylegan2-db/00886.png (deflated 0%)\n",
            "  adding: stylegan2-db/00882.png (deflated 0%)\n",
            "  adding: stylegan2-db/01106.png (deflated 0%)\n",
            "  adding: stylegan2-db/01639.png (deflated 0%)\n",
            "  adding: stylegan2-db/01470.png (deflated 0%)\n",
            "  adding: stylegan2-db/00275.png (deflated 0%)\n",
            "  adding: stylegan2-db/01006.png (deflated 0%)\n",
            "  adding: stylegan2-db/01318.png (deflated 0%)\n",
            "  adding: stylegan2-db/01557.png (deflated 0%)\n",
            "  adding: stylegan2-db/01737.png (deflated 0%)\n",
            "  adding: stylegan2-db/01790.png (deflated 0%)\n",
            "  adding: stylegan2-db/01748.png (deflated 0%)\n",
            "  adding: stylegan2-db/02036.png (deflated 0%)\n",
            "  adding: stylegan2-db/01325.png (deflated 0%)\n",
            "  adding: stylegan2-db/01035.png (deflated 0%)\n",
            "  adding: stylegan2-db/01409.png (deflated 0%)\n",
            "  adding: stylegan2-db/00039.png (deflated 0%)\n",
            "  adding: stylegan2-db/00094.png (deflated 0%)\n",
            "  adding: stylegan2-db/01588.png (deflated 0%)\n",
            "  adding: stylegan2-db/01661.png (deflated 0%)\n",
            "  adding: stylegan2-db/00006.png (deflated 0%)\n",
            "  adding: stylegan2-db/01485.png (deflated 0%)\n",
            "  adding: stylegan2-db/00816.png (deflated 0%)\n",
            "  adding: stylegan2-db/01010.png (deflated 0%)\n",
            "  adding: stylegan2-db/01001.png (deflated 0%)\n",
            "  adding: stylegan2-db/00541.png (deflated 0%)\n",
            "  adding: stylegan2-db/00694.png (deflated 0%)\n",
            "  adding: stylegan2-db/01915.png (deflated 0%)\n",
            "  adding: stylegan2-db/00495.png (deflated 0%)\n",
            "  adding: stylegan2-db/01754.png (deflated 0%)\n",
            "  adding: stylegan2-db/01501.png (deflated 0%)\n",
            "  adding: stylegan2-db/00725.png (deflated 0%)\n",
            "  adding: stylegan2-db/00975.png (deflated 0%)\n",
            "  adding: stylegan2-db/01495.png (deflated 0%)\n",
            "  adding: stylegan2-db/00082.png (deflated 0%)\n",
            "  adding: stylegan2-db/01763.png (deflated 0%)\n",
            "  adding: stylegan2-db/00003.png (deflated 0%)\n",
            "  adding: stylegan2-db/01419.png (deflated 0%)\n",
            "  adding: stylegan2-db/01349.png (deflated 0%)\n",
            "  adding: stylegan2-db/00586.png (deflated 0%)\n",
            "  adding: stylegan2-db/00330.png (deflated 0%)\n",
            "  adding: stylegan2-db/00303.png (deflated 0%)\n",
            "  adding: stylegan2-db/02002.png (deflated 0%)\n",
            "  adding: stylegan2-db/01212.png (deflated 0%)\n",
            "  adding: stylegan2-db/00517.png (deflated 0%)\n",
            "  adding: stylegan2-db/00106.png (deflated 0%)\n",
            "  adding: stylegan2-db/01269.png (deflated 0%)\n",
            "  adding: stylegan2-db/01075.png (deflated 0%)\n",
            "  adding: stylegan2-db/02045.png (deflated 0%)\n",
            "  adding: stylegan2-db/01701.png (deflated 0%)\n",
            "  adding: stylegan2-db/01842.png (deflated 0%)\n",
            "  adding: stylegan2-db/00183.png (deflated 0%)\n",
            "  adding: stylegan2-db/00186.png (deflated 0%)\n",
            "  adding: stylegan2-db/00437.png (deflated 0%)\n",
            "  adding: stylegan2-db/00302.png (deflated 0%)\n",
            "  adding: stylegan2-db/01384.png (deflated 0%)\n",
            "  adding: stylegan2-db/00843.png (deflated 0%)\n",
            "  adding: stylegan2-db/01733.png (deflated 0%)\n",
            "  adding: stylegan2-db/00332.png (deflated 0%)\n",
            "  adding: stylegan2-db/01071.png (deflated 0%)\n",
            "  adding: stylegan2-db/01512.png (deflated 0%)\n",
            "  adding: stylegan2-db/00716.png (deflated 0%)\n",
            "  adding: stylegan2-db/01009.png (deflated 0%)\n",
            "  adding: stylegan2-db/00247.png (deflated 0%)\n",
            "  adding: stylegan2-db/00698.png (deflated 0%)\n",
            "  adding: stylegan2-db/00477.png (deflated 0%)\n",
            "  adding: stylegan2-db/01871.png (deflated 0%)\n",
            "  adding: stylegan2-db/00411.png (deflated 0%)\n",
            "  adding: stylegan2-db/00689.png (deflated 0%)\n",
            "  adding: stylegan2-db/00295.png (deflated 0%)\n",
            "  adding: stylegan2-db/01709.png (deflated 0%)\n",
            "  adding: stylegan2-db/00253.png (deflated 0%)\n",
            "  adding: stylegan2-db/00072.png (deflated 0%)\n",
            "  adding: stylegan2-db/01251.png (deflated 0%)\n",
            "  adding: stylegan2-db/01854.png (deflated 0%)\n",
            "  adding: stylegan2-db/01022.png (deflated 0%)\n",
            "  adding: stylegan2-db/01841.png (deflated 0%)\n",
            "  adding: stylegan2-db/01225.png (deflated 0%)\n",
            "  adding: stylegan2-db/01862.png (deflated 0%)\n",
            "  adding: stylegan2-db/00692.png (deflated 0%)\n",
            "  adding: stylegan2-db/01738.png (deflated 0%)\n",
            "  adding: stylegan2-db/01728.png (deflated 0%)\n",
            "  adding: stylegan2-db/01432.png (deflated 0%)\n",
            "  adding: stylegan2-db/01061.png (deflated 0%)\n",
            "  adding: stylegan2-db/00881.png (deflated 0%)\n",
            "  adding: stylegan2-db/01116.png (deflated 0%)\n",
            "  adding: stylegan2-db/00309.png (deflated 0%)\n",
            "  adding: stylegan2-db/01029.png (deflated 0%)\n",
            "  adding: stylegan2-db/00859.png (deflated 0%)\n",
            "  adding: stylegan2-db/01599.png (deflated 0%)\n",
            "  adding: stylegan2-db/01056.png (deflated 0%)\n",
            "  adding: stylegan2-db/01103.png (deflated 0%)\n",
            "  adding: stylegan2-db/01443.png (deflated 0%)\n",
            "  adding: stylegan2-db/01065.png (deflated 0%)\n",
            "  adding: stylegan2-db/00344.png (deflated 0%)\n",
            "  adding: stylegan2-db/01780.png (deflated 0%)\n",
            "  adding: stylegan2-db/01730.png (deflated 0%)\n",
            "  adding: stylegan2-db/01170.png (deflated 0%)\n",
            "  adding: stylegan2-db/00508.png (deflated 0%)\n",
            "  adding: stylegan2-db/01233.png (deflated 0%)\n",
            "  adding: stylegan2-db/00899.png (deflated 0%)\n",
            "  adding: stylegan2-db/00693.png (deflated 0%)\n",
            "  adding: stylegan2-db/00280.png (deflated 0%)\n",
            "  adding: stylegan2-db/00073.png (deflated 0%)\n",
            "  adding: stylegan2-db/00010.png (deflated 0%)\n",
            "  adding: stylegan2-db/01720.png (deflated 0%)\n",
            "  adding: stylegan2-db/01657.png (deflated 0%)\n",
            "  adding: stylegan2-db/01797.png (deflated 0%)\n",
            "  adding: stylegan2-db/00206.png (deflated 0%)\n",
            "  adding: stylegan2-db/01786.png (deflated 0%)\n",
            "  adding: stylegan2-db/00122.png (deflated 0%)\n",
            "  adding: stylegan2-db/01315.png (deflated 0%)\n",
            "  adding: stylegan2-db/01621.png (deflated 0%)\n",
            "  adding: stylegan2-db/01743.png (deflated 0%)\n",
            "  adding: stylegan2-db/00559.png (deflated 0%)\n",
            "  adding: stylegan2-db/00910.png (deflated 0%)\n",
            "  adding: stylegan2-db/00677.png (deflated 0%)\n",
            "  adding: stylegan2-db/01386.png (deflated 0%)\n",
            "  adding: stylegan2-db/00596.png (deflated 0%)\n",
            "  adding: stylegan2-db/01635.png (deflated 0%)\n",
            "  adding: stylegan2-db/01861.png (deflated 0%)\n",
            "  adding: stylegan2-db/00230.png (deflated 0%)\n",
            "  adding: stylegan2-db/00355.png (deflated 0%)\n",
            "  adding: stylegan2-db/01274.png (deflated 0%)\n",
            "  adding: stylegan2-db/01453.png (deflated 0%)\n",
            "  adding: stylegan2-db/01231.png (deflated 0%)\n",
            "  adding: stylegan2-db/00429.png (deflated 0%)\n",
            "  adding: stylegan2-db/00550.png (deflated 0%)\n",
            "  adding: stylegan2-db/00192.png (deflated 0%)\n",
            "  adding: stylegan2-db/01596.png (deflated 0%)\n",
            "  adding: stylegan2-db/01020.png (deflated 0%)\n",
            "  adding: stylegan2-db/01961.png (deflated 0%)\n",
            "  adding: stylegan2-db/01708.png (deflated 0%)\n",
            "  adding: stylegan2-db/01484.png (deflated 0%)\n",
            "  adding: stylegan2-db/01477.png (deflated 0%)\n",
            "  adding: stylegan2-db/01502.png (deflated 0%)\n",
            "  adding: stylegan2-db/01773.png (deflated 0%)\n",
            "  adding: stylegan2-db/00644.png (deflated 0%)\n",
            "  adding: stylegan2-db/01704.png (deflated 0%)\n",
            "  adding: stylegan2-db/01611.png (deflated 0%)\n",
            "  adding: stylegan2-db/00017.png (deflated 0%)\n",
            "  adding: stylegan2-db/00851.png (deflated 0%)\n",
            "  adding: stylegan2-db/00953.png (deflated 0%)\n",
            "  adding: stylegan2-db/00334.png (deflated 0%)\n",
            "  adding: stylegan2-db/01674.png (deflated 0%)\n",
            "  adding: stylegan2-db/00058.png (deflated 0%)\n",
            "  adding: stylegan2-db/01220.png (deflated 0%)\n",
            "  adding: stylegan2-db/01603.png (deflated 0%)\n",
            "  adding: stylegan2-db/00581.png (deflated 0%)\n",
            "  adding: stylegan2-db/01497.png (deflated 0%)\n",
            "  adding: stylegan2-db/01197.png (deflated 0%)\n",
            "  adding: stylegan2-db/00069.png (deflated 0%)\n",
            "  adding: stylegan2-db/00102.png (deflated 0%)\n",
            "  adding: stylegan2-db/01923.png (deflated 0%)\n",
            "  adding: stylegan2-db/01819.png (deflated 0%)\n",
            "  adding: stylegan2-db/00742.png (deflated 0%)\n",
            "  adding: stylegan2-db/01893.png (deflated 0%)\n",
            "  adding: stylegan2-db/01934.png (deflated 0%)\n",
            "  adding: stylegan2-db/00425.png (deflated 0%)\n",
            "  adding: stylegan2-db/01850.png (deflated 0%)\n",
            "  adding: stylegan2-db/01649.png (deflated 0%)\n",
            "  adding: stylegan2-db/01525.png (deflated 0%)\n",
            "  adding: stylegan2-db/01084.png (deflated 0%)\n",
            "  adding: stylegan2-db/01883.png (deflated 0%)\n",
            "  adding: stylegan2-db/01172.png (deflated 0%)\n",
            "  adding: stylegan2-db/01381.png (deflated 0%)\n",
            "  adding: stylegan2-db/01202.png (deflated 0%)\n",
            "  adding: stylegan2-db/00050.png (deflated 0%)\n",
            "  adding: stylegan2-db/01050.png (deflated 0%)\n",
            "  adding: stylegan2-db/00109.png (deflated 0%)\n",
            "  adding: stylegan2-db/01702.png (deflated 0%)\n",
            "  adding: stylegan2-db/01767.png (deflated 0%)\n",
            "  adding: stylegan2-db/01945.png (deflated 0%)\n",
            "  adding: stylegan2-db/00224.png (deflated 0%)\n",
            "  adding: stylegan2-db/01431.png (deflated 0%)\n",
            "  adding: stylegan2-db/01555.png (deflated 0%)\n",
            "  adding: stylegan2-db/01872.png (deflated 0%)\n",
            "  adding: stylegan2-db/00854.png (deflated 0%)\n",
            "  adding: stylegan2-db/01510.png (deflated 0%)\n",
            "  adding: stylegan2-db/00985.png (deflated 0%)\n",
            "  adding: stylegan2-db/00582.png (deflated 0%)\n",
            "  adding: stylegan2-db/01117.png (deflated 0%)\n",
            "  adding: stylegan2-db/00171.png (deflated 0%)\n",
            "  adding: stylegan2-db/00079.png (deflated 0%)\n",
            "  adding: stylegan2-db/01330.png (deflated 0%)\n",
            "  adding: stylegan2-db/01145.png (deflated 0%)\n",
            "  adding: stylegan2-db/00333.png (deflated 0%)\n",
            "  adding: stylegan2-db/01919.png (deflated 0%)\n",
            "  adding: stylegan2-db/01118.png (deflated 0%)\n",
            "  adding: stylegan2-db/01393.png (deflated 0%)\n",
            "  adding: stylegan2-db/01215.png (deflated 0%)\n",
            "  adding: stylegan2-db/01410.png (deflated 0%)\n",
            "  adding: stylegan2-db/01408.png (deflated 0%)\n",
            "  adding: stylegan2-db/00930.png (deflated 0%)\n",
            "  adding: stylegan2-db/00068.png (deflated 0%)\n",
            "  adding: stylegan2-db/01812.png (deflated 0%)\n",
            "  adding: stylegan2-db/01955.png (deflated 0%)\n",
            "  adding: stylegan2-db/01016.png (deflated 0%)\n",
            "  adding: stylegan2-db/00621.png (deflated 0%)\n",
            "  adding: stylegan2-db/01229.png (deflated 0%)\n",
            "  adding: stylegan2-db/01490.png (deflated 0%)\n",
            "  adding: stylegan2-db/00625.png (deflated 0%)\n",
            "  adding: stylegan2-db/01833.png (deflated 0%)\n",
            "  adding: stylegan2-db/00491.png (deflated 0%)\n",
            "  adding: stylegan2-db/01026.png (deflated 0%)\n",
            "  adding: stylegan2-db/01200.png (deflated 0%)\n",
            "  adding: stylegan2-db/01935.png (deflated 0%)\n",
            "  adding: stylegan2-db/01287.png (deflated 0%)\n",
            "  adding: stylegan2-db/00524.png (deflated 0%)\n",
            "  adding: stylegan2-db/00087.png (deflated 0%)\n",
            "  adding: stylegan2-db/01689.png (deflated 0%)\n",
            "  adding: stylegan2-db/01585.png (deflated 0%)\n",
            "  adding: stylegan2-db/02024.png (deflated 0%)\n",
            "  adding: stylegan2-db/01131.png (deflated 0%)\n",
            "  adding: stylegan2-db/01906.png (deflated 0%)\n",
            "  adding: stylegan2-db/00872.png (deflated 0%)\n",
            "  adding: stylegan2-db/00180.png (deflated 0%)\n",
            "  adding: stylegan2-db/00018.png (deflated 0%)\n",
            "  adding: stylegan2-db/01928.png (deflated 0%)\n",
            "  adding: stylegan2-db/01074.png (deflated 0%)\n",
            "  adding: stylegan2-db/00560.png (deflated 0%)\n",
            "  adding: stylegan2-db/01086.png (deflated 0%)\n",
            "  adding: stylegan2-db/02007.png (deflated 0%)\n",
            "  adding: stylegan2-db/00361.png (deflated 0%)\n",
            "  adding: stylegan2-db/00365.png (deflated 0%)\n",
            "  adding: stylegan2-db/00962.png (deflated 0%)\n",
            "  adding: stylegan2-db/00520.png (deflated 0%)\n",
            "  adding: stylegan2-db/01664.png (deflated 0%)\n",
            "  adding: stylegan2-db/00187.png (deflated 0%)\n",
            "  adding: stylegan2-db/01343.png (deflated 0%)\n",
            "  adding: stylegan2-db/00325.png (deflated 0%)\n",
            "  adding: stylegan2-db/00606.png (deflated 0%)\n",
            "  adding: stylegan2-db/00551.png (deflated 0%)\n",
            "  adding: stylegan2-db/00369.png (deflated 0%)\n",
            "  adding: stylegan2-db/00462.png (deflated 0%)\n",
            "  adding: stylegan2-db/01450.png (deflated 0%)\n",
            "  adding: stylegan2-db/00480.png (deflated 0%)\n",
            "  adding: stylegan2-db/00664.png (deflated 0%)\n",
            "  adding: stylegan2-db/00831.png (deflated 0%)\n",
            "  adding: stylegan2-db/00446.png (deflated 0%)\n",
            "  adding: stylegan2-db/00507.png (deflated 0%)\n",
            "  adding: stylegan2-db/00846.png (deflated 0%)\n",
            "  adding: stylegan2-db/01938.png (deflated 0%)\n",
            "  adding: stylegan2-db/00023.png (deflated 0%)\n",
            "  adding: stylegan2-db/00074.png (deflated 0%)\n",
            "  adding: stylegan2-db/01115.png (deflated 0%)\n",
            "  adding: stylegan2-db/00091.png (deflated 0%)\n",
            "  adding: stylegan2-db/00821.png (deflated 0%)\n",
            "  adding: stylegan2-db/01939.png (deflated 0%)\n",
            "  adding: stylegan2-db/01487.png (deflated 0%)\n",
            "  adding: stylegan2-db/00153.png (deflated 0%)\n",
            "  adding: stylegan2-db/00276.png (deflated 0%)\n",
            "  adding: stylegan2-db/00648.png (deflated 0%)\n",
            "  adding: stylegan2-db/00195.png (deflated 0%)\n",
            "  adding: stylegan2-db/01909.png (deflated 0%)\n",
            "  adding: stylegan2-db/00353.png (deflated 0%)\n",
            "  adding: stylegan2-db/01439.png (deflated 0%)\n",
            "  adding: stylegan2-db/01834.png (deflated 0%)\n",
            "  adding: stylegan2-db/00804.png (deflated 0%)\n",
            "  adding: stylegan2-db/00512.png (deflated 0%)\n",
            "  adding: stylegan2-db/00464.png (deflated 0%)\n",
            "  adding: stylegan2-db/01473.png (deflated 0%)\n",
            "  adding: stylegan2-db/00312.png (deflated 0%)\n",
            "  adding: stylegan2-db/00264.png (deflated 0%)\n",
            "  adding: stylegan2-db/01478.png (deflated 0%)\n",
            "  adding: stylegan2-db/00054.png (deflated 0%)\n",
            "  adding: stylegan2-db/01224.png (deflated 0%)\n",
            "  adding: stylegan2-db/00388.png (deflated 0%)\n",
            "  adding: stylegan2-db/01844.png (deflated 0%)\n",
            "  adding: stylegan2-db/00715.png (deflated 0%)\n",
            "  adding: stylegan2-db/00623.png (deflated 0%)\n",
            "  adding: stylegan2-db/01977.png (deflated 0%)\n",
            "  adding: stylegan2-db/01055.png (deflated 0%)\n",
            "  adding: stylegan2-db/01789.png (deflated 0%)\n",
            "  adding: stylegan2-db/01448.png (deflated 0%)\n",
            "  adding: stylegan2-db/00022.png (deflated 0%)\n",
            "  adding: stylegan2-db/00032.png (deflated 0%)\n",
            "  adding: stylegan2-db/01427.png (deflated 0%)\n",
            "  adding: stylegan2-db/01594.png (deflated 0%)\n",
            "  adding: stylegan2-db/01564.png (deflated 0%)\n",
            "  adding: stylegan2-db/01412.png (deflated 0%)\n",
            "  adding: stylegan2-db/01771.png (deflated 0%)\n",
            "  adding: stylegan2-db/01663.png (deflated 0%)\n",
            "  adding: stylegan2-db/01073.png (deflated 0%)\n",
            "  adding: stylegan2-db/02046.png (deflated 0%)\n",
            "  adding: stylegan2-db/01252.png (deflated 0%)\n",
            "  adding: stylegan2-db/01176.png (deflated 0%)\n",
            "  adding: stylegan2-db/00033.png (deflated 0%)\n",
            "  adding: stylegan2-db/00827.png (deflated 0%)\n",
            "  adding: stylegan2-db/01524.png (deflated 0%)\n",
            "  adding: stylegan2-db/00408.png (deflated 0%)\n",
            "  adding: stylegan2-db/00784.png (deflated 0%)\n",
            "  adding: stylegan2-db/00597.png (deflated 0%)\n",
            "  adding: stylegan2-db/00339.png (deflated 0%)\n",
            "  adding: stylegan2-db/00759.png (deflated 0%)\n",
            "  adding: stylegan2-db/00724.png (deflated 0%)\n",
            "  adding: stylegan2-db/01288.png (deflated 0%)\n",
            "  adding: stylegan2-db/00061.png (deflated 0%)\n",
            "  adding: stylegan2-db/01044.png (deflated 0%)\n",
            "  adding: stylegan2-db/00609.png (deflated 0%)\n",
            "  adding: stylegan2-db/00155.png (deflated 0%)\n",
            "  adding: stylegan2-db/00812.png (deflated 0%)\n",
            "  adding: stylegan2-db/00691.png (deflated 0%)\n",
            "  adding: stylegan2-db/01355.png (deflated 0%)\n",
            "  adding: stylegan2-db/00448.png (deflated 0%)\n",
            "  adding: stylegan2-db/00193.png (deflated 0%)\n",
            "  adding: stylegan2-db/01538.png (deflated 0%)\n",
            "  adding: stylegan2-db/01168.png (deflated 0%)\n",
            "  adding: stylegan2-db/01997.png (deflated 0%)\n",
            "  adding: stylegan2-db/00179.png (deflated 0%)\n",
            "  adding: stylegan2-db/01774.png (deflated 0%)\n",
            "  adding: stylegan2-db/00159.png (deflated 0%)\n",
            "  adding: stylegan2-db/01171.png (deflated 0%)\n",
            "  adding: stylegan2-db/00617.png (deflated 0%)\n",
            "  adding: stylegan2-db/00081.png (deflated 0%)\n",
            "  adding: stylegan2-db/00174.png (deflated 0%)\n",
            "  adding: stylegan2-db/01995.png (deflated 0%)\n",
            "  adding: stylegan2-db/00318.png (deflated 0%)\n",
            "  adding: stylegan2-db/00362.png (deflated 0%)\n",
            "  adding: stylegan2-db/00392.png (deflated 0%)\n",
            "  adding: stylegan2-db/00782.png (deflated 0%)\n",
            "  adding: stylegan2-db/00467.png (deflated 0%)\n",
            "  adding: stylegan2-db/01237.png (deflated 0%)\n",
            "  adding: stylegan2-db/00912.png (deflated 0%)\n",
            "  adding: stylegan2-db/00948.png (deflated 0%)\n",
            "  adding: stylegan2-db/01413.png (deflated 0%)\n",
            "  adding: stylegan2-db/01038.png (deflated 0%)\n",
            "  adding: stylegan2-db/00730.png (deflated 0%)\n",
            "  adding: stylegan2-db/00989.png (deflated 0%)\n",
            "  adding: stylegan2-db/01943.png (deflated 0%)\n",
            "  adding: stylegan2-db/00474.png (deflated 0%)\n",
            "  adding: stylegan2-db/00450.png (deflated 0%)\n",
            "  adding: stylegan2-db/00635.png (deflated 0%)\n",
            "  adding: stylegan2-db/00839.png (deflated 0%)\n",
            "  adding: stylegan2-db/00614.png (deflated 0%)\n",
            "  adding: stylegan2-db/00718.png (deflated 0%)\n",
            "  adding: stylegan2-db/01132.png (deflated 0%)\n",
            "  adding: stylegan2-db/01958.png (deflated 0%)\n",
            "  adding: stylegan2-db/00670.png (deflated 0%)\n",
            "  adding: stylegan2-db/00240.png (deflated 0%)\n",
            "  adding: stylegan2-db/01082.png (deflated 0%)\n",
            "  adding: stylegan2-db/00838.png (deflated 0%)\n",
            "  adding: stylegan2-db/01210.png (deflated 0%)\n",
            "  adding: stylegan2-db/00745.png (deflated 0%)\n",
            "  adding: stylegan2-db/01219.png (deflated 0%)\n",
            "  adding: stylegan2-db/00406.png (deflated 0%)\n",
            "  adding: stylegan2-db/01612.png (deflated 0%)\n",
            "  adding: stylegan2-db/00107.png (deflated 0%)\n",
            "  adding: stylegan2-db/00702.png (deflated 0%)\n",
            "  adding: stylegan2-db/00137.png (deflated 0%)\n",
            "  adding: stylegan2-db/01087.png (deflated 0%)\n",
            "  adding: stylegan2-db/00166.png (deflated 0%)\n",
            "  adding: stylegan2-db/01446.png (deflated 0%)\n",
            "  adding: stylegan2-db/01917.png (deflated 0%)\n",
            "  adding: stylegan2-db/01870.png (deflated 0%)\n",
            "  adding: stylegan2-db/00252.png (deflated 0%)\n",
            "  adding: stylegan2-db/01166.png (deflated 0%)\n",
            "  adding: stylegan2-db/00502.png (deflated 0%)\n",
            "  adding: stylegan2-db/00608.png (deflated 0%)\n",
            "  adding: stylegan2-db/01972.png (deflated 0%)\n",
            "  adding: stylegan2-db/00249.png (deflated 0%)\n",
            "  adding: stylegan2-db/01372.png (deflated 0%)\n",
            "  adding: stylegan2-db/01843.png (deflated 0%)\n",
            "  adding: stylegan2-db/00865.png (deflated 0%)\n",
            "  adding: stylegan2-db/01128.png (deflated 0%)\n",
            "  adding: stylegan2-db/01982.png (deflated 0%)\n",
            "  adding: stylegan2-db/01907.png (deflated 0%)\n",
            "  adding: stylegan2-db/01901.png (deflated 0%)\n",
            "  adding: stylegan2-db/01904.png (deflated 0%)\n",
            "  adding: stylegan2-db/00763.png (deflated 0%)\n",
            "  adding: stylegan2-db/00390.png (deflated 0%)\n",
            "  adding: stylegan2-db/01280.png (deflated 0%)\n",
            "  adding: stylegan2-db/00993.png (deflated 0%)\n",
            "  adding: stylegan2-db/01530.png (deflated 0%)\n",
            "  adding: stylegan2-db/01875.png (deflated 0%)\n",
            "  adding: stylegan2-db/01638.png (deflated 0%)\n",
            "  adding: stylegan2-db/00565.png (deflated 0%)\n",
            "  adding: stylegan2-db/01011.png (deflated 0%)\n",
            "  adding: stylegan2-db/01563.png (deflated 0%)\n",
            "  adding: stylegan2-db/01984.png (deflated 0%)\n",
            "  adding: stylegan2-db/01831.png (deflated 0%)\n",
            "  adding: stylegan2-db/00755.png (deflated 0%)\n",
            "  adding: stylegan2-db/01529.png (deflated 0%)\n",
            "  adding: stylegan2-db/00124.png (deflated 0%)\n",
            "  adding: stylegan2-db/00380.png (deflated 0%)\n",
            "  adding: stylegan2-db/01353.png (deflated 0%)\n",
            "  adding: stylegan2-db/01756.png (deflated 0%)\n",
            "  adding: stylegan2-db/00892.png (deflated 0%)\n",
            "  adding: stylegan2-db/01111.png (deflated 0%)\n",
            "  adding: stylegan2-db/00473.png (deflated 0%)\n",
            "  adding: stylegan2-db/00492.png (deflated 0%)\n",
            "  adding: stylegan2-db/00736.png (deflated 0%)\n",
            "  adding: stylegan2-db/00296.png (deflated 0%)\n",
            "  adding: stylegan2-db/00443.png (deflated 0%)\n",
            "  adding: stylegan2-db/01715.png (deflated 0%)\n",
            "  adding: stylegan2-db/02010.png (deflated 0%)\n",
            "  adding: stylegan2-db/01735.png (deflated 0%)\n",
            "  adding: stylegan2-db/01837.png (deflated 0%)\n",
            "  adding: stylegan2-db/01322.png (deflated 0%)\n",
            "  adding: stylegan2-db/01942.png (deflated 0%)\n",
            "  adding: stylegan2-db/00599.png (deflated 0%)\n",
            "  adding: stylegan2-db/01616.png (deflated 0%)\n",
            "  adding: stylegan2-db/00928.png (deflated 0%)\n",
            "  adding: stylegan2-db/01383.png (deflated 0%)\n",
            "  adding: stylegan2-db/00880.png (deflated 0%)\n",
            "  adding: stylegan2-db/01094.png (deflated 0%)\n",
            "  adding: stylegan2-db/00657.png (deflated 0%)\n",
            "  adding: stylegan2-db/01707.png (deflated 0%)\n",
            "  adding: stylegan2-db/00646.png (deflated 0%)\n",
            "  adding: stylegan2-db/00257.png (deflated 0%)\n",
            "  adding: stylegan2-db/01706.png (deflated 0%)\n",
            "  adding: stylegan2-db/00349.png (deflated 0%)\n",
            "  adding: stylegan2-db/01002.png (deflated 0%)\n",
            "  adding: stylegan2-db/00151.png (deflated 0%)\n",
            "  adding: stylegan2-db/00363.png (deflated 0%)\n",
            "  adding: stylegan2-db/01777.png (deflated 0%)\n",
            "  adding: stylegan2-db/01683.png (deflated 0%)\n",
            "  adding: stylegan2-db/01138.png (deflated 0%)\n",
            "  adding: stylegan2-db/01660.png (deflated 0%)\n",
            "  adding: stylegan2-db/00771.png (deflated 0%)\n",
            "  adding: stylegan2-db/00037.png (deflated 0%)\n",
            "  adding: stylegan2-db/00727.png (deflated 0%)\n",
            "  adding: stylegan2-db/01134.png (deflated 0%)\n",
            "  adding: stylegan2-db/01878.png (deflated 0%)\n",
            "  adding: stylegan2-db/00632.png (deflated 0%)\n",
            "  adding: stylegan2-db/01243.png (deflated 0%)\n",
            "  adding: stylegan2-db/01275.png (deflated 0%)\n",
            "  adding: stylegan2-db/01041.png (deflated 0%)\n",
            "  adding: stylegan2-db/00093.png (deflated 0%)\n",
            "  adding: stylegan2-db/00788.png (deflated 0%)\n",
            "  adding: stylegan2-db/00498.png (deflated 0%)\n",
            "  adding: stylegan2-db/00112.png (deflated 0%)\n",
            "  adding: stylegan2-db/01079.png (deflated 0%)\n",
            "  adding: stylegan2-db/01583.png (deflated 0%)\n",
            "  adding: stylegan2-db/00142.png (deflated 0%)\n",
            "  adding: stylegan2-db/01159.png (deflated 0%)\n",
            "  adding: stylegan2-db/01607.png (deflated 0%)\n",
            "  adding: stylegan2-db/00869.png (deflated 0%)\n",
            "  adding: stylegan2-db/00120.png (deflated 0%)\n",
            "  adding: stylegan2-db/00631.png (deflated 0%)\n",
            "  adding: stylegan2-db/01152.png (deflated 0%)\n",
            "  adding: stylegan2-db/02000.png (deflated 0%)\n",
            "  adding: stylegan2-db/01550.png (deflated 0%)\n",
            "  adding: stylegan2-db/00123.png (deflated 0%)\n",
            "  adding: stylegan2-db/00130.png (deflated 0%)\n",
            "  adding: stylegan2-db/00583.png (deflated 0%)\n",
            "  adding: stylegan2-db/00241.png (deflated 0%)\n",
            "  adding: stylegan2-db/00669.png (deflated 0%)\n",
            "  adding: stylegan2-db/00856.png (deflated 0%)\n",
            "  adding: stylegan2-db/00790.png (deflated 0%)\n",
            "  adding: stylegan2-db/01829.png (deflated 0%)\n",
            "  adding: stylegan2-db/00959.png (deflated 0%)\n",
            "  adding: stylegan2-db/00236.png (deflated 0%)\n",
            "  adding: stylegan2-db/00101.png (deflated 0%)\n",
            "  adding: stylegan2-db/00809.png (deflated 0%)\n",
            "  adding: stylegan2-db/01568.png (deflated 0%)\n",
            "  adding: stylegan2-db/00712.png (deflated 0%)\n",
            "  adding: stylegan2-db/01017.png (deflated 0%)\n",
            "  adding: stylegan2-db/01169.png (deflated 0%)\n",
            "  adding: stylegan2-db/01839.png (deflated 0%)\n",
            "  adding: stylegan2-db/00460.png (deflated 0%)\n",
            "  adding: stylegan2-db/01208.png (deflated 0%)\n",
            "  adding: stylegan2-db/00255.png (deflated 0%)\n",
            "  adding: stylegan2-db/00204.png (deflated 0%)\n",
            "  adding: stylegan2-db/00046.png (deflated 0%)\n",
            "  adding: stylegan2-db/01392.png (deflated 0%)\n",
            "  adding: stylegan2-db/00444.png (deflated 0%)\n",
            "  adding: stylegan2-db/01644.png (deflated 0%)\n",
            "  adding: stylegan2-db/00441.png (deflated 0%)\n",
            "  adding: stylegan2-db/01962.png (deflated 0%)\n",
            "  adding: stylegan2-db/00201.png (deflated 0%)\n",
            "  adding: stylegan2-db/01520.png (deflated 0%)\n",
            "  adding: stylegan2-db/00059.png (deflated 0%)\n",
            "  adding: stylegan2-db/00732.png (deflated 0%)\n",
            "  adding: stylegan2-db/01642.png (deflated 0%)\n",
            "  adding: stylegan2-db/00002.png (deflated 0%)\n",
            "  adding: stylegan2-db/02021.png (deflated 0%)\n",
            "  adding: stylegan2-db/01558.png (deflated 0%)\n",
            "  adding: stylegan2-db/01582.png (deflated 0%)\n",
            "  adding: stylegan2-db/00259.png (deflated 0%)\n",
            "  adding: stylegan2-db/01929.png (deflated 0%)\n",
            "  adding: stylegan2-db/00642.png (deflated 0%)\n",
            "  adding: stylegan2-db/00526.png (deflated 0%)\n",
            "  adding: stylegan2-db/01682.png (deflated 0%)\n",
            "  adding: stylegan2-db/01417.png (deflated 0%)\n",
            "  adding: stylegan2-db/01440.png (deflated 0%)\n",
            "  adding: stylegan2-db/00643.png (deflated 0%)\n",
            "  adding: stylegan2-db/01746.png (deflated 0%)\n",
            "  adding: stylegan2-db/00986.png (deflated 0%)\n",
            "  adding: stylegan2-db/01049.png (deflated 0%)\n",
            "  adding: stylegan2-db/00234.png (deflated 0%)\n",
            "  adding: stylegan2-db/01365.png (deflated 0%)\n",
            "  adding: stylegan2-db/01283.png (deflated 0%)\n",
            "  adding: stylegan2-db/01101.png (deflated 0%)\n",
            "  adding: stylegan2-db/01808.png (deflated 0%)\n",
            "  adding: stylegan2-db/01979.png (deflated 0%)\n",
            "  adding: stylegan2-db/00786.png (deflated 0%)\n",
            "  adding: stylegan2-db/01597.png (deflated 0%)\n",
            "  adding: stylegan2-db/00447.png (deflated 0%)\n",
            "  adding: stylegan2-db/01804.png (deflated 0%)\n",
            "  adding: stylegan2-db/01826.png (deflated 0%)\n",
            "  adding: stylegan2-db/01064.png (deflated 0%)\n",
            "  adding: stylegan2-db/00667.png (deflated 0%)\n",
            "  adding: stylegan2-db/01209.png (deflated 0%)\n",
            "  adding: stylegan2-db/00173.png (deflated 0%)\n",
            "  adding: stylegan2-db/01641.png (deflated 0%)\n",
            "  adding: stylegan2-db/01794.png (deflated 0%)\n",
            "  adding: stylegan2-db/00976.png (deflated 0%)\n",
            "  adding: stylegan2-db/01311.png (deflated 0%)\n",
            "  adding: stylegan2-db/00505.png (deflated 0%)\n",
            "  adding: stylegan2-db/00602.png (deflated 0%)\n",
            "  adding: stylegan2-db/00490.png (deflated 0%)\n",
            "  adding: stylegan2-db/00891.png (deflated 0%)\n",
            "  adding: stylegan2-db/01800.png (deflated 0%)\n",
            "  adding: stylegan2-db/00504.png (deflated 0%)\n",
            "  adding: stylegan2-db/01265.png (deflated 0%)\n",
            "  adding: stylegan2-db/00167.png (deflated 0%)\n",
            "  adding: stylegan2-db/01494.png (deflated 0%)\n",
            "  adding: stylegan2-db/01235.png (deflated 0%)\n",
            "  adding: stylegan2-db/01130.png (deflated 0%)\n",
            "  adding: stylegan2-db/01114.png (deflated 0%)\n",
            "  adding: stylegan2-db/00967.png (deflated 0%)\n",
            "  adding: stylegan2-db/01821.png (deflated 0%)\n",
            "  adding: stylegan2-db/00697.png (deflated 0%)\n",
            "  adding: stylegan2-db/00105.png (deflated 0%)\n",
            "  adding: stylegan2-db/01667.png (deflated 0%)\n",
            "  adding: stylegan2-db/00585.png (deflated 0%)\n",
            "  adding: stylegan2-db/01078.png (deflated 0%)\n",
            "  adding: stylegan2-db/01940.png (deflated 0%)\n",
            "  adding: stylegan2-db/01791.png (deflated 0%)\n",
            "  adding: stylegan2-db/00793.png (deflated 0%)\n",
            "  adding: stylegan2-db/00086.png (deflated 0%)\n",
            "  adding: stylegan2-db/00857.png (deflated 0%)\n",
            "  adding: stylegan2-db/00940.png (deflated 0%)\n",
            "  adding: stylegan2-db/00721.png (deflated 0%)\n",
            "  adding: stylegan2-db/01998.png (deflated 0%)\n",
            "  adding: stylegan2-db/00530.png (deflated 0%)\n",
            "  adding: stylegan2-db/01098.png (deflated 0%)\n",
            "  adding: stylegan2-db/00968.png (deflated 0%)\n",
            "  adding: stylegan2-db/00645.png (deflated 0%)\n",
            "  adding: stylegan2-db/00114.png (deflated 0%)\n",
            "  adding: stylegan2-db/01816.png (deflated 0%)\n",
            "  adding: stylegan2-db/01376.png (deflated 0%)\n",
            "  adding: stylegan2-db/00407.png (deflated 0%)\n",
            "  adding: stylegan2-db/00454.png (deflated 0%)\n",
            "  adding: stylegan2-db/00278.png (deflated 0%)\n",
            "  adding: stylegan2-db/01124.png (deflated 0%)\n",
            "  adding: stylegan2-db/00618.png (deflated 0%)\n",
            "  adding: stylegan2-db/00366.png (deflated 0%)\n",
            "  adding: stylegan2-db/01573.png (deflated 0%)\n",
            "  adding: stylegan2-db/00345.png (deflated 0%)\n",
            "  adding: stylegan2-db/00619.png (deflated 0%)\n",
            "  adding: stylegan2-db/00219.png (deflated 0%)\n",
            "  adding: stylegan2-db/00750.png (deflated 0%)\n",
            "  adding: stylegan2-db/00681.png (deflated 0%)\n",
            "  adding: stylegan2-db/01399.png (deflated 0%)\n",
            "  adding: stylegan2-db/00154.png (deflated 0%)\n",
            "  adding: stylegan2-db/00739.png (deflated 0%)\n",
            "  adding: stylegan2-db/00923.png (deflated 0%)\n",
            "  adding: stylegan2-db/01319.png (deflated 0%)\n",
            "  adding: stylegan2-db/01846.png (deflated 0%)\n",
            "  adding: stylegan2-db/00423.png (deflated 0%)\n",
            "  adding: stylegan2-db/00929.png (deflated 0%)\n",
            "  adding: stylegan2-db/01147.png (deflated 0%)\n",
            "  adding: stylegan2-db/00540.png (deflated 0%)\n",
            "  adding: stylegan2-db/00513.png (deflated 0%)\n",
            "  adding: stylegan2-db/01310.png (deflated 0%)\n",
            "  adding: stylegan2-db/00706.png (deflated 0%)\n",
            "  adding: stylegan2-db/01572.png (deflated 0%)\n",
            "  adding: stylegan2-db/00245.png (deflated 0%)\n",
            "  adding: stylegan2-db/01916.png (deflated 0%)\n",
            "  adding: stylegan2-db/01999.png (deflated 0%)\n",
            "  adding: stylegan2-db/00379.png (deflated 0%)\n",
            "  adding: stylegan2-db/02001.png (deflated 0%)\n",
            "  adding: stylegan2-db/00083.png (deflated 0%)\n",
            "  adding: stylegan2-db/01629.png (deflated 0%)\n",
            "  adding: stylegan2-db/01551.png (deflated 0%)\n",
            "  adding: stylegan2-db/00537.png (deflated 0%)\n",
            "  adding: stylegan2-db/00269.png (deflated 0%)\n",
            "  adding: stylegan2-db/00261.png (deflated 0%)\n",
            "  adding: stylegan2-db/00004.png (deflated 0%)\n",
            "  adding: stylegan2-db/01966.png (deflated 0%)\n",
            "  adding: stylegan2-db/00337.png (deflated 0%)\n",
            "  adding: stylegan2-db/01713.png (deflated 0%)\n",
            "  adding: stylegan2-db/01937.png (deflated 0%)\n",
            "  adding: stylegan2-db/00370.png (deflated 0%)\n",
            "  adding: stylegan2-db/00335.png (deflated 0%)\n",
            "  adding: stylegan2-db/01375.png (deflated 0%)\n",
            "  adding: stylegan2-db/01852.png (deflated 0%)\n",
            "  adding: stylegan2-db/01068.png (deflated 0%)\n",
            "  adding: stylegan2-db/00485.png (deflated 0%)\n",
            "  adding: stylegan2-db/00279.png (deflated 0%)\n",
            "  adding: stylegan2-db/01723.png (deflated 0%)\n",
            "  adding: stylegan2-db/01277.png (deflated 0%)\n",
            "  adding: stylegan2-db/00836.png (deflated 0%)\n",
            "  adding: stylegan2-db/01123.png (deflated 0%)\n",
            "  adding: stylegan2-db/01795.png (deflated 0%)\n",
            "  adding: stylegan2-db/00760.png (deflated 0%)\n",
            "  adding: stylegan2-db/01211.png (deflated 0%)\n",
            "  adding: stylegan2-db/01390.png (deflated 0%)\n",
            "  adding: stylegan2-db/00459.png (deflated 0%)\n",
            "  adding: stylegan2-db/00162.png (deflated 0%)\n",
            "  adding: stylegan2-db/00501.png (deflated 0%)\n",
            "  adding: stylegan2-db/00556.png (deflated 0%)\n",
            "  adding: stylegan2-db/00479.png (deflated 0%)\n",
            "  adding: stylegan2-db/00115.png (deflated 0%)\n",
            "  adding: stylegan2-db/00266.png (deflated 0%)\n",
            "  adding: stylegan2-db/00258.png (deflated 0%)\n",
            "  adding: stylegan2-db/00413.png (deflated 0%)\n",
            "  adding: stylegan2-db/01534.png (deflated 0%)\n",
            "  adding: stylegan2-db/00139.png (deflated 0%)\n",
            "  adding: stylegan2-db/01156.png (deflated 0%)\n",
            "  adding: stylegan2-db/00213.png (deflated 0%)\n",
            "  adding: stylegan2-db/00864.png (deflated 0%)\n",
            "  adding: stylegan2-db/01769.png (deflated 0%)\n",
            "  adding: stylegan2-db/00548.png (deflated 0%)\n",
            "  adding: stylegan2-db/01670.png (deflated 0%)\n",
            "  adding: stylegan2-db/00216.png (deflated 0%)\n",
            "  adding: stylegan2-db/01258.png (deflated 0%)\n",
            "  adding: stylegan2-db/00726.png (deflated 0%)\n",
            "  adding: stylegan2-db/00138.png (deflated 0%)\n",
            "  adding: stylegan2-db/00468.png (deflated 0%)\n",
            "  adding: stylegan2-db/01509.png (deflated 0%)\n",
            "  adding: stylegan2-db/00042.png (deflated 0%)\n",
            "  adding: stylegan2-db/00931.png (deflated 0%)\n",
            "  adding: stylegan2-db/01278.png (deflated 0%)\n",
            "  adding: stylegan2-db/00328.png (deflated 0%)\n",
            "  adding: stylegan2-db/01227.png (deflated 0%)\n",
            "  adding: stylegan2-db/00013.png (deflated 0%)\n",
            "  adding: stylegan2-db/00364.png (deflated 0%)\n",
            "  adding: stylegan2-db/00126.png (deflated 0%)\n",
            "  adding: stylegan2-db/01268.png (deflated 0%)\n",
            "  adding: stylegan2-db/01321.png (deflated 0%)\n",
            "  adding: stylegan2-db/00751.png (deflated 0%)\n",
            "  adding: stylegan2-db/00331.png (deflated 0%)\n",
            "  adding: stylegan2-db/01433.png (deflated 0%)\n",
            "  adding: stylegan2-db/00323.png (deflated 0%)\n",
            "  adding: stylegan2-db/01076.png (deflated 0%)\n",
            "  adding: stylegan2-db/00777.png (deflated 0%)\n",
            "  adding: stylegan2-db/00935.png (deflated 0%)\n",
            "  adding: stylegan2-db/00946.png (deflated 0%)\n",
            "  adding: stylegan2-db/00714.png (deflated 0%)\n",
            "  adding: stylegan2-db/01898.png (deflated 0%)\n",
            "  adding: stylegan2-db/01167.png (deflated 0%)\n",
            "  adding: stylegan2-db/00855.png (deflated 0%)\n",
            "  adding: stylegan2-db/00795.png (deflated 0%)\n",
            "  adding: stylegan2-db/01788.png (deflated 0%)\n",
            "  adding: stylegan2-db/01489.png (deflated 0%)\n",
            "  adding: stylegan2-db/01260.png (deflated 0%)\n",
            "  adding: stylegan2-db/00780.png (deflated 0%)\n",
            "  adding: stylegan2-db/01185.png (deflated 0%)\n",
            "  adding: stylegan2-db/01554.png (deflated 0%)\n",
            "  adding: stylegan2-db/01155.png (deflated 0%)\n",
            "  adding: stylegan2-db/00431.png (deflated 0%)\n",
            "  adding: stylegan2-db/01968.png (deflated 0%)\n",
            "  adding: stylegan2-db/01479.png (deflated 0%)\n",
            "  adding: stylegan2-db/01591.png (deflated 0%)\n",
            "  adding: stylegan2-db/01993.png (deflated 0%)\n",
            "  adding: stylegan2-db/01347.png (deflated 0%)\n",
            "  adding: stylegan2-db/01964.png (deflated 0%)\n",
            "  adding: stylegan2-db/01796.png (deflated 0%)\n",
            "  adding: stylegan2-db/00909.png (deflated 0%)\n",
            "  adding: stylegan2-db/01936.png (deflated 0%)\n",
            "  adding: stylegan2-db/01263.png (deflated 0%)\n",
            "  adding: stylegan2-db/00182.png (deflated 0%)\n",
            "  adding: stylegan2-db/00481.png (deflated 0%)\n",
            "  adding: stylegan2-db/01428.png (deflated 0%)\n",
            "  adding: stylegan2-db/00601.png (deflated 0%)\n",
            "  adding: stylegan2-db/00047.png (deflated 0%)\n",
            "  adding: stylegan2-db/01739.png (deflated 0%)\n",
            "  adding: stylegan2-db/01576.png (deflated 0%)\n",
            "  adding: stylegan2-db/01726.png (deflated 0%)\n",
            "  adding: stylegan2-db/00461.png (deflated 0%)\n",
            "  adding: stylegan2-db/01314.png (deflated 0%)\n",
            "  adding: stylegan2-db/00346.png (deflated 0%)\n",
            "  adding: stylegan2-db/00852.png (deflated 0%)\n",
            "  adding: stylegan2-db/01099.png (deflated 0%)\n",
            "  adding: stylegan2-db/00057.png (deflated 0%)\n",
            "  adding: stylegan2-db/00288.png (deflated 0%)\n",
            "  adding: stylegan2-db/01577.png (deflated 0%)\n",
            "  adding: stylegan2-db/01874.png (deflated 0%)\n",
            "  adding: stylegan2-db/00371.png (deflated 0%)\n",
            "  adding: stylegan2-db/01189.png (deflated 0%)\n",
            "  adding: stylegan2-db/01048.png (deflated 0%)\n",
            "  adding: stylegan2-db/00905.png (deflated 0%)\n",
            "  adding: stylegan2-db/00359.png (deflated 0%)\n",
            "  adding: stylegan2-db/00453.png (deflated 0%)\n",
            "  adding: stylegan2-db/01326.png (deflated 0%)\n",
            "  adding: stylegan2-db/01261.png (deflated 0%)\n",
            "  adding: stylegan2-db/01865.png (deflated 0%)\n",
            "  adding: stylegan2-db/01618.png (deflated 0%)\n",
            "  adding: stylegan2-db/00248.png (deflated 0%)\n",
            "  adding: stylegan2-db/00660.png (deflated 0%)\n",
            "  adding: stylegan2-db/00630.png (deflated 0%)\n",
            "  adding: stylegan2-db/00246.png (deflated 0%)\n",
            "  adding: stylegan2-db/01360.png (deflated 0%)\n",
            "  adding: stylegan2-db/00779.png (deflated 0%)\n",
            "  adding: stylegan2-db/01847.png (deflated 0%)\n",
            "  adding: stylegan2-db/01627.png (deflated 0%)\n",
            "  adding: stylegan2-db/00873.png (deflated 0%)\n",
            "  adding: stylegan2-db/01719.png (deflated 0%)\n",
            "  adding: stylegan2-db/00089.png (deflated 0%)\n",
            "  adding: stylegan2-db/00273.png (deflated 0%)\n",
            "  adding: stylegan2-db/00686.png (deflated 0%)\n",
            "  adding: stylegan2-db/00688.png (deflated 0%)\n",
            "  adding: stylegan2-db/00562.png (deflated 0%)\n",
            "  adding: stylegan2-db/00926.png (deflated 0%)\n",
            "  adding: stylegan2-db/00850.png (deflated 0%)\n",
            "  adding: stylegan2-db/00528.png (deflated 0%)\n",
            "  adding: stylegan2-db/01983.png (deflated 0%)\n",
            "  adding: stylegan2-db/01136.png (deflated 0%)\n",
            "  adding: stylegan2-db/01926.png (deflated 0%)\n",
            "  adding: stylegan2-db/00044.png (deflated 0%)\n",
            "  adding: stylegan2-db/00514.png (deflated 0%)\n",
            "  adding: stylegan2-db/00422.png (deflated 0%)\n",
            "  adding: stylegan2-db/01516.png (deflated 0%)\n",
            "  adding: stylegan2-db/00136.png (deflated 0%)\n",
            "  adding: stylegan2-db/00972.png (deflated 0%)\n",
            "  adding: stylegan2-db/00260.png (deflated 0%)\n",
            "  adding: stylegan2-db/01569.png (deflated 0%)\n",
            "  adding: stylegan2-db/01531.png (deflated 0%)\n",
            "  adding: stylegan2-db/01679.png (deflated 0%)\n",
            "  adding: stylegan2-db/01052.png (deflated 0%)\n",
            "  adding: stylegan2-db/00637.png (deflated 0%)\n",
            "  adding: stylegan2-db/00265.png (deflated 0%)\n",
            "  adding: stylegan2-db/00558.png (deflated 0%)\n",
            "  adding: stylegan2-db/02047.png (deflated 0%)\n",
            "  adding: stylegan2-db/01622.png (deflated 0%)\n",
            "  adding: stylegan2-db/01899.png (deflated 0%)\n",
            "  adding: stylegan2-db/01604.png (deflated 0%)\n",
            "  adding: stylegan2-db/00133.png (deflated 0%)\n",
            "  adding: stylegan2-db/00145.png (deflated 0%)\n",
            "  adding: stylegan2-db/00027.png (deflated 0%)\n",
            "  adding: stylegan2-db/00282.png (deflated 0%)\n",
            "  adding: stylegan2-db/00917.png (deflated 0%)\n",
            "  adding: stylegan2-db/00744.png (deflated 0%)\n",
            "  adding: stylegan2-db/00566.png (deflated 0%)\n",
            "  adding: stylegan2-db/00449.png (deflated 0%)\n",
            "  adding: stylegan2-db/01884.png (deflated 0%)\n",
            "  adding: stylegan2-db/01953.png (deflated 0%)\n",
            "  adding: stylegan2-db/01121.png (deflated 0%)\n",
            "  adding: stylegan2-db/01262.png (deflated 0%)\n",
            "  adding: stylegan2-db/00607.png (deflated 0%)\n",
            "  adding: stylegan2-db/00307.png (deflated 0%)\n",
            "  adding: stylegan2-db/01725.png (deflated 0%)\n",
            "  adding: stylegan2-db/00207.png (deflated 0%)\n",
            "  adding: stylegan2-db/00853.png (deflated 0%)\n",
            "  adding: stylegan2-db/00902.png (deflated 0%)\n",
            "  adding: stylegan2-db/00409.png (deflated 0%)\n",
            "  adding: stylegan2-db/00052.png (deflated 0%)\n",
            "  adding: stylegan2-db/00113.png (deflated 0%)\n",
            "  adding: stylegan2-db/01522.png (deflated 0%)\n",
            "  adding: stylegan2-db/00525.png (deflated 0%)\n",
            "  adding: stylegan2-db/01645.png (deflated 0%)\n",
            "  adding: stylegan2-db/00308.png (deflated 0%)\n",
            "  adding: stylegan2-db/00535.png (deflated 0%)\n",
            "  adding: stylegan2-db/00808.png (deflated 0%)\n",
            "  adding: stylegan2-db/01113.png (deflated 0%)\n",
            "  adding: stylegan2-db/00687.png (deflated 0%)\n",
            "  adding: stylegan2-db/01876.png (deflated 0%)\n",
            "  adding: stylegan2-db/01658.png (deflated 0%)\n",
            "  adding: stylegan2-db/00329.png (deflated 0%)\n",
            "  adding: stylegan2-db/01536.png (deflated 0%)\n",
            "  adding: stylegan2-db/01493.png (deflated 0%)\n",
            "  adding: stylegan2-db/01361.png (deflated 0%)\n",
            "  adding: stylegan2-db/00148.png (deflated 0%)\n",
            "  adding: stylegan2-db/01581.png (deflated 0%)\n",
            "  adding: stylegan2-db/01080.png (deflated 0%)\n",
            "  adding: stylegan2-db/01400.png (deflated 0%)\n",
            "  adding: stylegan2-db/00471.png (deflated 0%)\n",
            "  adding: stylegan2-db/01429.png (deflated 0%)\n",
            "  adding: stylegan2-db/00486.png (deflated 0%)\n",
            "  adding: stylegan2-db/01199.png (deflated 0%)\n",
            "  adding: stylegan2-db/01814.png (deflated 0%)\n",
            "  adding: stylegan2-db/00613.png (deflated 0%)\n",
            "  adding: stylegan2-db/00215.png (deflated 0%)\n",
            "  adding: stylegan2-db/00011.png (deflated 0%)\n",
            "  adding: stylegan2-db/00016.png (deflated 0%)\n",
            "  adding: stylegan2-db/01095.png (deflated 0%)\n",
            "  adding: stylegan2-db/00389.png (deflated 0%)\n",
            "  adding: stylegan2-db/00628.png (deflated 0%)\n",
            "  adding: stylegan2-db/01051.png (deflated 0%)\n",
            "  adding: stylegan2-db/01491.png (deflated 0%)\n",
            "  adding: stylegan2-db/00826.png (deflated 0%)\n",
            "  adding: stylegan2-db/00573.png (deflated 0%)\n",
            "  adding: stylegan2-db/02037.png (deflated 0%)\n",
            "  adding: stylegan2-db/00767.png (deflated 0%)\n",
            "  adding: stylegan2-db/01186.png (deflated 0%)\n",
            "  adding: stylegan2-db/00313.png (deflated 0%)\n",
            "  adding: stylegan2-db/00974.png (deflated 0%)\n",
            "  adding: stylegan2-db/00918.png (deflated 0%)\n",
            "  adding: stylegan2-db/00578.png (deflated 0%)\n",
            "  adding: stylegan2-db/01503.png (deflated 0%)\n",
            "  adding: stylegan2-db/00503.png (deflated 0%)\n",
            "  adding: stylegan2-db/01447.png (deflated 0%)\n",
            "  adding: stylegan2-db/00543.png (deflated 0%)\n",
            "  adding: stylegan2-db/00805.png (deflated 0%)\n",
            "  adding: stylegan2-db/01469.png (deflated 0%)\n",
            "  adding: stylegan2-db/01515.png (deflated 0%)\n",
            "  adding: stylegan2-db/02044.png (deflated 0%)\n",
            "  adding: stylegan2-db/01471.png (deflated 0%)\n",
            "  adding: stylegan2-db/00978.png (deflated 0%)\n",
            "  adding: stylegan2-db/01991.png (deflated 0%)\n",
            "  adding: stylegan2-db/01244.png (deflated 0%)\n",
            "  adding: stylegan2-db/01255.png (deflated 0%)\n",
            "  adding: stylegan2-db/01896.png (deflated 0%)\n",
            "  adding: stylegan2-db/00567.png (deflated 0%)\n",
            "  adding: stylegan2-db/00675.png (deflated 0%)\n",
            "  adding: stylegan2-db/01234.png (deflated 0%)\n",
            "  adding: stylegan2-db/01782.png (deflated 0%)\n",
            "  adding: stylegan2-db/00803.png (deflated 0%)\n",
            "  adding: stylegan2-db/01513.png (deflated 0%)\n",
            "  adding: stylegan2-db/00356.png (deflated 0%)\n",
            "  adding: stylegan2-db/00239.png (deflated 0%)\n",
            "  adding: stylegan2-db/01570.png (deflated 0%)\n",
            "  adding: stylegan2-db/01886.png (deflated 0%)\n",
            "  adding: stylegan2-db/01967.png (deflated 0%)\n",
            "  adding: stylegan2-db/01096.png (deflated 0%)\n",
            "  adding: stylegan2-db/01043.png (deflated 0%)\n",
            "  adding: stylegan2-db/00367.png (deflated 0%)\n",
            "  adding: stylegan2-db/01990.png (deflated 0%)\n",
            "  adding: stylegan2-db/00877.png (deflated 0%)\n",
            "  adding: stylegan2-db/00970.png (deflated 0%)\n",
            "  adding: stylegan2-db/01249.png (deflated 0%)\n",
            "  adding: stylegan2-db/00451.png (deflated 0%)\n",
            "  adding: stylegan2-db/01460.png (deflated 0%)\n",
            "  adding: stylegan2-db/01532.png (deflated 0%)\n",
            "  adding: stylegan2-db/00921.png (deflated 0%)\n",
            "  adding: stylegan2-db/00828.png (deflated 0%)\n",
            "  adding: stylegan2-db/01675.png (deflated 0%)\n",
            "  adding: stylegan2-db/01873.png (deflated 0%)\n",
            "  adding: stylegan2-db/00085.png (deflated 0%)\n",
            "  adding: stylegan2-db/00984.png (deflated 0%)\n",
            "  adding: stylegan2-db/01793.png (deflated 0%)\n",
            "  adding: stylegan2-db/01877.png (deflated 0%)\n",
            "  adding: stylegan2-db/01544.png (deflated 0%)\n",
            "  adding: stylegan2-db/00588.png (deflated 0%)\n",
            "  adding: stylegan2-db/01910.png (deflated 0%)\n",
            "  adding: stylegan2-db/00104.png (deflated 0%)\n",
            "  adding: stylegan2-db/01042.png (deflated 0%)\n",
            "  adding: stylegan2-db/01507.png (deflated 0%)\n",
            "  adding: stylegan2-db/00482.png (deflated 0%)\n",
            "  adding: stylegan2-db/00576.png (deflated 0%)\n",
            "  adding: stylegan2-db/00005.png (deflated 0%)\n",
            "  adding: stylegan2-db/00381.png (deflated 0%)\n",
            "  adding: stylegan2-db/01742.png (deflated 0%)\n",
            "  adding: stylegan2-db/01137.png (deflated 0%)\n",
            "  adding: stylegan2-db/01500.png (deflated 0%)\n",
            "  adding: stylegan2-db/00382.png (deflated 0%)\n",
            "  adding: stylegan2-db/01543.png (deflated 0%)\n",
            "  adding: stylegan2-db/00542.png (deflated 0%)\n",
            "  adding: stylegan2-db/01021.png (deflated 0%)\n",
            "  adding: stylegan2-db/01285.png (deflated 0%)\n",
            "  adding: stylegan2-db/01930.png (deflated 0%)\n",
            "  adding: stylegan2-db/01207.png (deflated 0%)\n",
            "  adding: stylegan2-db/01989.png (deflated 0%)\n",
            "  adding: stylegan2-db/01085.png (deflated 0%)\n",
            "  adding: stylegan2-db/01142.png (deflated 0%)\n",
            "  adding: stylegan2-db/00572.png (deflated 0%)\n",
            "  adding: stylegan2-db/00756.png (deflated 0%)\n",
            "  adding: stylegan2-db/01918.png (deflated 0%)\n",
            "  adding: stylegan2-db/00080.png (deflated 0%)\n",
            "  adding: stylegan2-db/00250.png (deflated 0%)\n",
            "  adding: stylegan2-db/01669.png (deflated 0%)\n",
            "  adding: stylegan2-db/00888.png (deflated 0%)\n",
            "  adding: stylegan2-db/01303.png (deflated 0%)\n",
            "  adding: stylegan2-db/01306.png (deflated 0%)\n",
            "  adding: stylegan2-db/00190.png (deflated 0%)\n",
            "  adding: stylegan2-db/01933.png (deflated 0%)\n",
            "  adding: stylegan2-db/01905.png (deflated 0%)\n",
            "  adding: stylegan2-db/01775.png (deflated 0%)\n",
            "  adding: stylegan2-db/00372.png (deflated 0%)\n",
            "  adding: stylegan2-db/01559.png (deflated 0%)\n",
            "  adding: stylegan2-db/01226.png (deflated 0%)\n",
            "  adding: stylegan2-db/01974.png (deflated 0%)\n",
            "  adding: stylegan2-db/00977.png (deflated 0%)\n",
            "  adding: stylegan2-db/00196.png (deflated 0%)\n",
            "  adding: stylegan2-db/01911.png (deflated 0%)\n",
            "  adding: stylegan2-db/01192.png (deflated 0%)\n",
            "  adding: stylegan2-db/00874.png (deflated 0%)\n",
            "  adding: stylegan2-db/00861.png (deflated 0%)\n",
            "  adding: stylegan2-db/01751.png (deflated 0%)\n",
            "  adding: stylegan2-db/00571.png (deflated 0%)\n",
            "  adding: stylegan2-db/01717.png (deflated 0%)\n",
            "  adding: stylegan2-db/01950.png (deflated 0%)\n",
            "  adding: stylegan2-db/00536.png (deflated 0%)\n",
            "  adding: stylegan2-db/00665.png (deflated 0%)\n",
            "  adding: stylegan2-db/01480.png (deflated 0%)\n",
            "  adding: stylegan2-db/02023.png (deflated 0%)\n",
            "  adding: stylegan2-db/01254.png (deflated 0%)\n",
            "  adding: stylegan2-db/00753.png (deflated 0%)\n",
            "  adding: stylegan2-db/01282.png (deflated 0%)\n",
            "  adding: stylegan2-db/01952.png (deflated 0%)\n",
            "  adding: stylegan2-db/00539.png (deflated 0%)\n",
            "  adding: stylegan2-db/00438.png (deflated 0%)\n",
            "  adding: stylegan2-db/00799.png (deflated 0%)\n",
            "  adding: stylegan2-db/01710.png (deflated 0%)\n",
            "  adding: stylegan2-db/00605.png (deflated 0%)\n",
            "  adding: stylegan2-db/01820.png (deflated 0%)\n",
            "  adding: stylegan2-db/01541.png (deflated 0%)\n",
            "  adding: stylegan2-db/01864.png (deflated 0%)\n",
            "  adding: stylegan2-db/01289.png (deflated 0%)\n",
            "  adding: stylegan2-db/00342.png (deflated 0%)\n",
            "  adding: stylegan2-db/01028.png (deflated 0%)\n",
            "  adding: stylegan2-db/00430.png (deflated 0%)\n",
            "  adding: stylegan2-db/01598.png (deflated 0%)\n",
            "  adding: stylegan2-db/01662.png (deflated 0%)\n",
            "  adding: stylegan2-db/00746.png (deflated 0%)\n",
            "  adding: stylegan2-db/01058.png (deflated 0%)\n",
            "  adding: stylegan2-db/01592.png (deflated 0%)\n",
            "  adding: stylegan2-db/01397.png (deflated 0%)\n",
            "  adding: stylegan2-db/00671.png (deflated 0%)\n",
            "  adding: stylegan2-db/00428.png (deflated 0%)\n",
            "  adding: stylegan2-db/01761.png (deflated 0%)\n",
            "  adding: stylegan2-db/02035.png (deflated 0%)\n",
            "  adding: stylegan2-db/01335.png (deflated 0%)\n",
            "  adding: stylegan2-db/01466.png (deflated 0%)\n",
            "  adding: stylegan2-db/01232.png (deflated 0%)\n",
            "  adding: stylegan2-db/01007.png (deflated 0%)\n",
            "  adding: stylegan2-db/01054.png (deflated 0%)\n",
            "  adding: stylegan2-db/00639.png (deflated 0%)\n",
            "  adding: stylegan2-db/00593.png (deflated 0%)\n",
            "  adding: stylegan2-db/00629.png (deflated 0%)\n",
            "  adding: stylegan2-db/00144.png (deflated 0%)\n",
            "  adding: stylegan2-db/00549.png (deflated 0%)\n",
            "  adding: stylegan2-db/00636.png (deflated 0%)\n",
            "  adding: stylegan2-db/00385.png (deflated 0%)\n",
            "  adding: stylegan2-db/00118.png (deflated 0%)\n",
            "  adding: stylegan2-db/01941.png (deflated 0%)\n",
            "  adding: stylegan2-db/01301.png (deflated 0%)\n",
            "  adding: stylegan2-db/00735.png (deflated 0%)\n",
            "  adding: stylegan2-db/01549.png (deflated 0%)\n",
            "  adding: stylegan2-db/00071.png (deflated 0%)\n",
            "  adding: stylegan2-db/01527.png (deflated 0%)\n",
            "  adding: stylegan2-db/01198.png (deflated 0%)\n",
            "  adding: stylegan2-db/01248.png (deflated 0%)\n",
            "  adding: stylegan2-db/01698.png (deflated 0%)\n",
            "  adding: stylegan2-db/01566.png (deflated 0%)\n",
            "  adding: stylegan2-db/00674.png (deflated 0%)\n",
            "  adding: stylegan2-db/01764.png (deflated 0%)\n",
            "  adding: stylegan2-db/02029.png (deflated 0%)\n",
            "  adding: stylegan2-db/01762.png (deflated 0%)\n",
            "  adding: stylegan2-db/00294.png (deflated 0%)\n",
            "  adding: stylegan2-db/01711.png (deflated 0%)\n",
            "  adding: stylegan2-db/00647.png (deflated 0%)\n",
            "  adding: stylegan2-db/01688.png (deflated 0%)\n",
            "  adding: stylegan2-db/01083.png (deflated 0%)\n",
            "  adding: stylegan2-db/00612.png (deflated 0%)\n",
            "  adding: stylegan2-db/00025.png (deflated 0%)\n",
            "  adding: stylegan2-db/01279.png (deflated 0%)\n",
            "  adding: stylegan2-db/00903.png (deflated 0%)\n",
            "  adding: stylegan2-db/01362.png (deflated 0%)\n",
            "  adding: stylegan2-db/01389.png (deflated 0%)\n",
            "  adding: stylegan2-db/01320.png (deflated 0%)\n",
            "  adding: stylegan2-db/01766.png (deflated 0%)\n",
            "  adding: stylegan2-db/00662.png (deflated 0%)\n",
            "  adding: stylegan2-db/00343.png (deflated 0%)\n",
            "  adding: stylegan2-db/01266.png (deflated 0%)\n",
            "  adding: stylegan2-db/00743.png (deflated 0%)\n",
            "  adding: stylegan2-db/00509.png (deflated 0%)\n",
            "  adding: stylegan2-db/01593.png (deflated 0%)\n",
            "  adding: stylegan2-db/00825.png (deflated 0%)\n",
            "  adding: stylegan2-db/00922.png (deflated 0%)\n",
            "  adding: stylegan2-db/01030.png (deflated 0%)\n",
            "  adding: stylegan2-db/01856.png (deflated 0%)\n",
            "  adding: stylegan2-db/00194.png (deflated 0%)\n",
            "  adding: stylegan2-db/00457.png (deflated 0%)\n",
            "  adding: stylegan2-db/01498.png (deflated 0%)\n",
            "  adding: stylegan2-db/00966.png (deflated 0%)\n",
            "  adding: stylegan2-db/01848.png (deflated 0%)\n",
            "  adding: stylegan2-db/01174.png (deflated 0%)\n",
            "  adding: stylegan2-db/01193.png (deflated 0%)\n",
            "  adding: stylegan2-db/01655.png (deflated 0%)\n",
            "  adding: stylegan2-db/00944.png (deflated 0%)\n",
            "  adding: stylegan2-db/00487.png (deflated 0%)\n",
            "  adding: stylegan2-db/00954.png (deflated 0%)\n",
            "  adding: stylegan2-db/01547.png (deflated 0%)\n",
            "  adding: stylegan2-db/00554.png (deflated 0%)\n",
            "  adding: stylegan2-db/01630.png (deflated 0%)\n",
            "  adding: stylegan2-db/01784.png (deflated 0%)\n",
            "  adding: stylegan2-db/01350.png (deflated 0%)\n",
            "  adding: stylegan2-db/01149.png (deflated 0%)\n",
            "  adding: stylegan2-db/00842.png (deflated 0%)\n",
            "  adding: stylegan2-db/00898.png (deflated 0%)\n",
            "  adding: stylegan2-db/00285.png (deflated 0%)\n",
            "  adding: stylegan2-db/00165.png (deflated 0%)\n",
            "  adding: stylegan2-db/01849.png (deflated 0%)\n",
            "  adding: stylegan2-db/01286.png (deflated 0%)\n",
            "  adding: stylegan2-db/01975.png (deflated 0%)\n",
            "  adding: stylegan2-db/01526.png (deflated 0%)\n",
            "  adding: stylegan2-db/00973.png (deflated 0%)\n",
            "  adding: stylegan2-db/01753.png (deflated 0%)\n",
            "  adding: stylegan2-db/00263.png (deflated 0%)\n",
            "  adding: stylegan2-db/01467.png (deflated 0%)\n",
            "  adding: stylegan2-db/01459.png (deflated 0%)\n",
            "  adding: stylegan2-db/01104.png (deflated 0%)\n",
            "  adding: stylegan2-db/01868.png (deflated 0%)\n",
            "  adding: stylegan2-db/00835.png (deflated 0%)\n",
            "  adding: stylegan2-db/00848.png (deflated 0%)\n",
            "  adding: stylegan2-db/01620.png (deflated 0%)\n",
            "  adding: stylegan2-db/01441.png (deflated 0%)\n",
            "  adding: stylegan2-db/01595.png (deflated 0%)\n",
            "  adding: stylegan2-db/00135.png (deflated 0%)\n",
            "  adding: stylegan2-db/01987.png (deflated 0%)\n",
            "  adding: stylegan2-db/01163.png (deflated 0%)\n",
            "  adding: stylegan2-db/00552.png (deflated 0%)\n",
            "  adding: stylegan2-db/01556.png (deflated 0%)\n",
            "  adding: stylegan2-db/00600.png (deflated 0%)\n",
            "  adding: stylegan2-db/00555.png (deflated 0%)\n",
            "  adding: stylegan2-db/01672.png (deflated 0%)\n",
            "  adding: stylegan2-db/01673.png (deflated 0%)\n",
            "  adding: stylegan2-db/00019.png (deflated 0%)\n",
            "  adding: stylegan2-db/00315.png (deflated 0%)\n",
            "  adding: stylegan2-db/00650.png (deflated 0%)\n",
            "  adding: stylegan2-db/00231.png (deflated 0%)\n",
            "  adding: stylegan2-db/01858.png (deflated 0%)\n",
            "  adding: stylegan2-db/00773.png (deflated 0%)\n",
            "  adding: stylegan2-db/00147.png (deflated 0%)\n",
            "  adding: stylegan2-db/00951.png (deflated 0%)\n",
            "  adding: stylegan2-db/01013.png (deflated 0%)\n",
            "  adding: stylegan2-db/01496.png (deflated 0%)\n",
            "  adding: stylegan2-db/01463.png (deflated 0%)\n",
            "  adding: stylegan2-db/01324.png (deflated 0%)\n",
            "  adding: stylegan2-db/01160.png (deflated 0%)\n",
            "  adding: stylegan2-db/01100.png (deflated 0%)\n",
            "  adding: stylegan2-db/01567.png (deflated 0%)\n",
            "  adding: stylegan2-db/01246.png (deflated 0%)\n",
            "  adding: stylegan2-db/00152.png (deflated 0%)\n",
            "  adding: stylegan2-db/01206.png (deflated 0%)\n",
            "  adding: stylegan2-db/00398.png (deflated 0%)\n",
            "  adding: stylegan2-db/00350.png (deflated 0%)\n",
            "  adding: stylegan2-db/00417.png (deflated 0%)\n",
            "  adding: stylegan2-db/00232.png (deflated 0%)\n",
            "  adding: stylegan2-db/02031.png (deflated 0%)\n",
            "  adding: stylegan2-db/00845.png (deflated 0%)\n",
            "  adding: stylegan2-db/00731.png (deflated 0%)\n",
            "  adding: stylegan2-db/00373.png (deflated 0%)\n",
            "  adding: stylegan2-db/01978.png (deflated 0%)\n",
            "  adding: stylegan2-db/01956.png (deflated 0%)\n",
            "  adding: stylegan2-db/01368.png (deflated 0%)\n",
            "  adding: stylegan2-db/01690.png (deflated 0%)\n",
            "  adding: stylegan2-db/01590.png (deflated 0%)\n",
            "  adding: stylegan2-db/01546.png (deflated 0%)\n",
            "  adding: stylegan2-db/00747.png (deflated 0%)\n",
            "  adding: stylegan2-db/01571.png (deflated 0%)\n",
            "  adding: stylegan2-db/01464.png (deflated 0%)\n",
            "  adding: stylegan2-db/00791.png (deflated 0%)\n",
            "  adding: stylegan2-db/01271.png (deflated 0%)\n",
            "  adding: stylegan2-db/00870.png (deflated 0%)\n",
            "  adding: stylegan2-db/01146.png (deflated 0%)\n",
            "  adding: stylegan2-db/00217.png (deflated 0%)\n",
            "  adding: stylegan2-db/01749.png (deflated 0%)\n",
            "  adding: stylegan2-db/00439.png (deflated 0%)\n",
            "  adding: stylegan2-db/00268.png (deflated 0%)\n",
            "  adding: stylegan2-db/00534.png (deflated 0%)\n",
            "  adding: stylegan2-db/01745.png (deflated 0%)\n",
            "  adding: stylegan2-db/00695.png (deflated 0%)\n",
            "  adding: stylegan2-db/00041.png (deflated 0%)\n",
            "  adding: stylegan2-db/00427.png (deflated 0%)\n",
            "  adding: stylegan2-db/01734.png (deflated 0%)\n",
            "  adding: stylegan2-db/00652.png (deflated 0%)\n",
            "  adding: stylegan2-db/00128.png (deflated 0%)\n",
            "  adding: stylegan2-db/00140.png (deflated 0%)\n",
            "  adding: stylegan2-db/00885.png (deflated 0%)\n",
            "  adding: stylegan2-db/02012.png (deflated 0%)\n",
            "  adding: stylegan2-db/01668.png (deflated 0%)\n",
            "  adding: stylegan2-db/02030.png (deflated 0%)\n",
            "  adding: stylegan2-db/00758.png (deflated 0%)\n",
            "  adding: stylegan2-db/00060.png (deflated 0%)\n",
            "  adding: stylegan2-db/00289.png (deflated 0%)\n",
            "  adding: stylegan2-db/00203.png (deflated 0%)\n",
            "  adding: stylegan2-db/01922.png (deflated 0%)\n",
            "  adding: stylegan2-db/01257.png (deflated 0%)\n",
            "  adding: stylegan2-db/00075.png (deflated 0%)\n",
            "  adding: stylegan2-db/01302.png (deflated 0%)\n",
            "  adding: stylegan2-db/01822.png (deflated 0%)\n",
            "  adding: stylegan2-db/01024.png (deflated 0%)\n",
            "  adding: stylegan2-db/01610.png (deflated 0%)\n",
            "  adding: stylegan2-db/01284.png (deflated 0%)\n",
            "  adding: stylegan2-db/00096.png (deflated 0%)\n",
            "  adding: stylegan2-db/00672.png (deflated 0%)\n",
            "  adding: stylegan2-db/00678.png (deflated 0%)\n",
            "  adding: stylegan2-db/01676.png (deflated 0%)\n",
            "  adding: stylegan2-db/01031.png (deflated 0%)\n",
            "  adding: stylegan2-db/00538.png (deflated 0%)\n",
            "  adding: stylegan2-db/01499.png (deflated 0%)\n",
            "  adding: stylegan2-db/01119.png (deflated 0%)\n",
            "  adding: stylegan2-db/00994.png (deflated 0%)\n",
            "  adding: stylegan2-db/01750.png (deflated 0%)\n",
            "  adding: stylegan2-db/00749.png (deflated 0%)\n",
            "  adding: stylegan2-db/00690.png (deflated 0%)\n",
            "  adding: stylegan2-db/00391.png (deflated 0%)\n",
            "  adding: stylegan2-db/00867.png (deflated 0%)\n",
            "  adding: stylegan2-db/00704.png (deflated 0%)\n",
            "  adding: stylegan2-db/00311.png (deflated 0%)\n",
            "  adding: stylegan2-db/01602.png (deflated 0%)\n",
            "  adding: stylegan2-db/01317.png (deflated 0%)\n",
            "  adding: stylegan2-db/00914.png (deflated 0%)\n",
            "  adding: stylegan2-db/01253.png (deflated 0%)\n",
            "  adding: stylegan2-db/01695.png (deflated 0%)\n",
            "  adding: stylegan2-db/02011.png (deflated 0%)\n",
            "  adding: stylegan2-db/01608.png (deflated 0%)\n",
            "  adding: stylegan2-db/02025.png (deflated 0%)\n",
            "  adding: stylegan2-db/00484.png (deflated 0%)\n",
            "  adding: stylegan2-db/00499.png (deflated 0%)\n",
            "  adding: stylegan2-db/01802.png (deflated 0%)\n",
            "  adding: stylegan2-db/01539.png (deflated 0%)\n",
            "  adding: stylegan2-db/01141.png (deflated 0%)\n",
            "  adding: stylegan2-db/00293.png (deflated 0%)\n",
            "  adding: stylegan2-db/01729.png (deflated 0%)\n",
            "  adding: stylegan2-db/01435.png (deflated 0%)\n",
            "  adding: stylegan2-db/00040.png (deflated 0%)\n",
            "  adding: stylegan2-db/00733.png (deflated 0%)\n",
            "  adding: stylegan2-db/01338.png (deflated 0%)\n",
            "  adding: stylegan2-db/00368.png (deflated 0%)\n",
            "  adding: stylegan2-db/01004.png (deflated 0%)\n",
            "  adding: stylegan2-db/00393.png (deflated 0%)\n",
            "  adding: stylegan2-db/01809.png (deflated 0%)\n",
            "  adding: stylegan2-db/01486.png (deflated 0%)\n",
            "  adding: stylegan2-db/00205.png (deflated 0%)\n",
            "  adding: stylegan2-db/01855.png (deflated 0%)\n",
            "  adding: stylegan2-db/01671.png (deflated 0%)\n",
            "  adding: stylegan2-db/01337.png (deflated 0%)\n",
            "  adding: stylegan2-db/01741.png (deflated 0%)\n",
            "  adding: stylegan2-db/00958.png (deflated 0%)\n",
            "  adding: stylegan2-db/01665.png (deflated 0%)\n",
            "  adding: stylegan2-db/01356.png (deflated 0%)\n",
            "  adding: stylegan2-db/01090.png (deflated 0%)\n",
            "  adding: stylegan2-db/02040.png (deflated 0%)\n",
            "  adding: stylegan2-db/00563.png (deflated 0%)\n",
            "  adding: stylegan2-db/00766.png (deflated 0%)\n",
            "  adding: stylegan2-db/00829.png (deflated 0%)\n",
            "  adding: stylegan2-db/01971.png (deflated 0%)\n",
            "  adding: stylegan2-db/01779.png (deflated 0%)\n",
            "  adding: stylegan2-db/00879.png (deflated 0%)\n",
            "  adding: stylegan2-db/01420.png (deflated 0%)\n",
            "  adding: stylegan2-db/00354.png (deflated 0%)\n",
            "  adding: stylegan2-db/01426.png (deflated 0%)\n",
            "  adding: stylegan2-db/01845.png (deflated 0%)\n",
            "  adding: stylegan2-db/01019.png (deflated 0%)\n",
            "  adding: stylegan2-db/01685.png (deflated 0%)\n",
            "  adding: stylegan2-db/01827.png (deflated 0%)\n",
            "  adding: stylegan2-db/00668.png (deflated 0%)\n",
            "  adding: stylegan2-db/01396.png (deflated 0%)\n",
            "  adding: stylegan2-db/00414.png (deflated 0%)\n",
            "  adding: stylegan2-db/01027.png (deflated 0%)\n",
            "  adding: stylegan2-db/00590.png (deflated 0%)\n",
            "  adding: stylegan2-db/01692.png (deflated 0%)\n",
            "  adding: stylegan2-db/00616.png (deflated 0%)\n",
            "  adding: stylegan2-db/00971.png (deflated 0%)\n",
            "  adding: stylegan2-db/00515.png (deflated 0%)\n",
            "  adding: stylegan2-db/01037.png (deflated 0%)\n",
            "  adding: stylegan2-db/00211.png (deflated 0%)\n",
            "  adding: stylegan2-db/01783.png (deflated 0%)\n",
            "  adding: stylegan2-db/00604.png (deflated 0%)\n",
            "  adding: stylegan2-db/01640.png (deflated 0%)\n",
            "  adding: stylegan2-db/01165.png (deflated 0%)\n",
            "  adding: stylegan2-db/01342.png (deflated 0%)\n",
            "  adding: stylegan2-db/00158.png (deflated 0%)\n",
            "  adding: stylegan2-db/02028.png (deflated 0%)\n",
            "  adding: stylegan2-db/00405.png (deflated 0%)\n",
            "  adding: stylegan2-db/00049.png (deflated 0%)\n",
            "  adding: stylegan2-db/00620.png (deflated 0%)\n",
            "  adding: stylegan2-db/01535.png (deflated 0%)\n",
            "  adding: stylegan2-db/01346.png (deflated 0%)\n",
            "  adding: stylegan2-db/00435.png (deflated 0%)\n",
            "  adding: stylegan2-db/00416.png (deflated 0%)\n",
            "  adding: stylegan2-db/01331.png (deflated 0%)\n",
            "  adding: stylegan2-db/01230.png (deflated 0%)\n",
            "  adding: stylegan2-db/01102.png (deflated 0%)\n",
            "  adding: stylegan2-db/01803.png (deflated 0%)\n",
            "  adding: stylegan2-db/01744.png (deflated 0%)\n",
            "  adding: stylegan2-db/01133.png (deflated 0%)\n",
            "  adding: stylegan2-db/01105.png (deflated 0%)\n",
            "  adding: stylegan2-db/00516.png (deflated 0%)\n",
            "  adding: stylegan2-db/01798.png (deflated 0%)\n",
            "  adding: stylegan2-db/00015.png (deflated 0%)\n",
            "  adding: stylegan2-db/00340.png (deflated 0%)\n",
            "  adding: stylegan2-db/01069.png (deflated 0%)\n",
            "  adding: stylegan2-db/00064.png (deflated 0%)\n",
            "  adding: stylegan2-db/00820.png (deflated 0%)\n",
            "  adding: stylegan2-db/01387.png (deflated 0%)\n",
            "  adding: stylegan2-db/02048.png (deflated 0%)\n",
            "  adding: stylegan2-db/01294.png (deflated 0%)\n",
            "  adding: stylegan2-db/01882.png (deflated 0%)\n",
            "  adding: stylegan2-db/02006.png (deflated 0%)\n",
            "  adding: stylegan2-db/01270.png (deflated 0%)\n",
            "  adding: stylegan2-db/01366.png (deflated 0%)\n",
            "  adding: stylegan2-db/01540.png (deflated 0%)\n",
            "  adding: stylegan2-db/00679.png (deflated 0%)\n",
            "  adding: stylegan2-db/01626.png (deflated 0%)\n",
            "  adding: stylegan2-db/00844.png (deflated 0%)\n",
            "  adding: stylegan2-db/01825.png (deflated 0%)\n",
            "  adding: stylegan2-db/00445.png (deflated 0%)\n",
            "  adding: stylegan2-db/00510.png (deflated 0%)\n",
            "  adding: stylegan2-db/01545.png (deflated 0%)\n",
            "  adding: stylegan2-db/01908.png (deflated 0%)\n",
            "  adding: stylegan2-db/00436.png (deflated 0%)\n",
            "  adding: stylegan2-db/00822.png (deflated 0%)\n",
            "  adding: stylegan2-db/01492.png (deflated 0%)\n",
            "  adding: stylegan2-db/01986.png (deflated 0%)\n",
            "  adding: stylegan2-db/00640.png (deflated 0%)\n",
            "  adding: stylegan2-db/01518.png (deflated 0%)\n",
            "  adding: stylegan2-db/01291.png (deflated 0%)\n",
            "  adding: stylegan2-db/00901.png (deflated 0%)\n",
            "  adding: stylegan2-db/01063.png (deflated 0%)\n",
            "  adding: stylegan2-db/00511.png (deflated 0%)\n",
            "  adding: stylegan2-db/00301.png (deflated 0%)\n",
            "  adding: stylegan2-db/00955.png (deflated 0%)\n",
            "  adding: stylegan2-db/01339.png (deflated 0%)\n",
            "  adding: stylegan2-db/01032.png (deflated 0%)\n",
            "  adding: stylegan2-db/00496.png (deflated 0%)\n",
            "  adding: stylegan2-db/00110.png (deflated 0%)\n",
            "  adding: stylegan2-db/00469.png (deflated 0%)\n",
            "  adding: stylegan2-db/01259.png (deflated 0%)\n",
            "  adding: stylegan2-db/00117.png (deflated 0%)\n",
            "  adding: stylegan2-db/01272.png (deflated 0%)\n",
            "  adding: stylegan2-db/01045.png (deflated 0%)\n",
            "  adding: stylegan2-db/00810.png (deflated 0%)\n",
            "  adding: stylegan2-db/00729.png (deflated 0%)\n",
            "  adding: stylegan2-db/00170.png (deflated 0%)\n",
            "  adding: stylegan2-db/01631.png (deflated 0%)\n",
            "  adding: stylegan2-db/00963.png (deflated 0%)\n",
            "  adding: stylegan2-db/00256.png (deflated 0%)\n",
            "  adding: stylegan2-db/00132.png (deflated 0%)\n",
            "  adding: stylegan2-db/01778.png (deflated 0%)\n",
            "  adding: stylegan2-db/01832.png (deflated 0%)\n",
            "  adding: stylegan2-db/00711.png (deflated 0%)\n",
            "  adding: stylegan2-db/01482.png (deflated 0%)\n",
            "  adding: stylegan2-db/00801.png (deflated 0%)\n",
            "  adding: stylegan2-db/01295.png (deflated 0%)\n",
            "  adding: stylegan2-db/01401.png (deflated 0%)\n",
            "  adding: stylegan2-db/01890.png (deflated 0%)\n",
            "  adding: stylegan2-db/01407.png (deflated 0%)\n",
            "  adding: stylegan2-db/00878.png (deflated 0%)\n",
            "  adding: stylegan2-db/01587.png (deflated 0%)\n",
            "  adding: stylegan2-db/01651.png (deflated 0%)\n",
            "  adding: stylegan2-db/00014.png (deflated 0%)\n",
            "  adding: stylegan2-db/01018.png (deflated 0%)\n",
            "  adding: stylegan2-db/00798.png (deflated 0%)\n",
            "  adding: stylegan2-db/01164.png (deflated 0%)\n",
            "  adding: stylegan2-db/00682.png (deflated 0%)\n",
            "  adding: stylegan2-db/02015.png (deflated 0%)\n",
            "  adding: stylegan2-db/00455.png (deflated 0%)\n",
            "  adding: stylegan2-db/00719.png (deflated 0%)\n",
            "  adding: stylegan2-db/00860.png (deflated 0%)\n",
            "  adding: stylegan2-db/00740.png (deflated 0%)\n",
            "  adding: stylegan2-db/00244.png (deflated 0%)\n",
            "  adding: stylegan2-db/00942.png (deflated 0%)\n",
            "  adding: stylegan2-db/00494.png (deflated 0%)\n",
            "  adding: stylegan2-db/00227.png (deflated 0%)\n",
            "  adding: stylegan2-db/02009.png (deflated 0%)\n",
            "  adding: stylegan2-db/01838.png (deflated 0%)\n",
            "  adding: stylegan2-db/00904.png (deflated 0%)\n",
            "  adding: stylegan2-db/00638.png (deflated 0%)\n",
            "  adding: stylegan2-db/00021.png (deflated 0%)\n",
            "  adding: stylegan2-db/01894.png (deflated 0%)\n",
            "  adding: stylegan2-db/01256.png (deflated 0%)\n",
            "  adding: stylegan2-db/01151.png (deflated 0%)\n",
            "  adding: stylegan2-db/00772.png (deflated 0%)\n",
            "  adding: stylegan2-db/01179.png (deflated 0%)\n",
            "  adding: stylegan2-db/00837.png (deflated 0%)\n",
            "  adding: stylegan2-db/00626.png (deflated 0%)\n",
            "  adding: stylegan2-db/00748.png (deflated 0%)\n",
            "  adding: stylegan2-db/01059.png (deflated 0%)\n",
            "  adding: stylegan2-db/00834.png (deflated 0%)\n",
            "  adding: stylegan2-db/01014.png (deflated 0%)\n",
            "  adding: stylegan2-db/00680.png (deflated 0%)\n",
            "  adding: stylegan2-db/01351.png (deflated 0%)\n",
            "  adding: stylegan2-db/01451.png (deflated 0%)\n",
            "  adding: stylegan2-db/00466.png (deflated 0%)\n",
            "  adding: stylegan2-db/00036.png (deflated 0%)\n",
            "  adding: stylegan2-db/01057.png (deflated 0%)\n",
            "  adding: stylegan2-db/01341.png (deflated 0%)\n",
            "  adding: stylegan2-db/01293.png (deflated 0%)\n",
            "  adding: stylegan2-db/01759.png (deflated 0%)\n",
            "  adding: stylegan2-db/01892.png (deflated 0%)\n",
            "  adding: stylegan2-db/02026.png (deflated 0%)\n",
            "  adding: stylegan2-db/01150.png (deflated 0%)\n",
            "  adding: stylegan2-db/01528.png (deflated 0%)\n",
            "  adding: stylegan2-db/00920.png (deflated 0%)\n",
            "  adding: stylegan2-db/00775.png (deflated 0%)\n",
            "  adding: stylegan2-db/00034.png (deflated 0%)\n",
            "  adding: stylegan2-db/00306.png (deflated 0%)\n",
            "  adding: stylegan2-db/02014.png (deflated 0%)\n",
            "  adding: stylegan2-db/01811.png (deflated 0%)\n",
            "  adding: stylegan2-db/01703.png (deflated 0%)\n",
            "  adding: stylegan2-db/00547.png (deflated 0%)\n",
            "  adding: stylegan2-db/01575.png (deflated 0%)\n",
            "  adding: stylegan2-db/01458.png (deflated 0%)\n",
            "  adding: stylegan2-db/00237.png (deflated 0%)\n",
            "  adding: stylegan2-db/01879.png (deflated 0%)\n",
            "  adding: stylegan2-db/00297.png (deflated 0%)\n",
            "  adding: stylegan2-db/01242.png (deflated 0%)\n",
            "  adding: stylegan2-db/00465.png (deflated 0%)\n",
            "  adding: stylegan2-db/00658.png (deflated 0%)\n",
            "  adding: stylegan2-db/01088.png (deflated 0%)\n",
            "  adding: stylegan2-db/01196.png (deflated 0%)\n",
            "  adding: stylegan2-db/00172.png (deflated 0%)\n",
            "  adding: stylegan2-db/00797.png (deflated 0%)\n",
            "  adding: stylegan2-db/00066.png (deflated 0%)\n",
            "  adding: stylegan2-db/01476.png (deflated 0%)\n",
            "  adding: stylegan2-db/01504.png (deflated 0%)\n",
            "  adding: stylegan2-db/00470.png (deflated 0%)\n",
            "  adding: stylegan2-db/01755.png (deflated 0%)\n",
            "  adding: stylegan2-db/01866.png (deflated 0%)\n",
            "  adding: stylegan2-db/01406.png (deflated 0%)\n",
            "  adding: stylegan2-db/01129.png (deflated 0%)\n",
            "  adding: stylegan2-db/00932.png (deflated 0%)\n",
            "  adding: stylegan2-db/01705.png (deflated 0%)\n",
            "  adding: stylegan2-db/00761.png (deflated 0%)\n",
            "  adding: stylegan2-db/00699.png (deflated 0%)\n",
            "  adding: stylegan2-db/00752.png (deflated 0%)\n",
            "  adding: stylegan2-db/01060.png (deflated 0%)\n",
            "  adding: stylegan2-db/00611.png (deflated 0%)\n",
            "  adding: stylegan2-db/00375.png (deflated 0%)\n",
            "  adding: stylegan2-db/00769.png (deflated 0%)\n",
            "  adding: stylegan2-db/01077.png (deflated 0%)\n",
            "  adding: stylegan2-db/01656.png (deflated 0%)\n",
            "  adding: stylegan2-db/00832.png (deflated 0%)\n",
            "  adding: stylegan2-db/02003.png (deflated 0%)\n",
            "  adding: stylegan2-db/00762.png (deflated 0%)\n",
            "  adding: stylegan2-db/00426.png (deflated 0%)\n",
            "  adding: stylegan2-db/01810.png (deflated 0%)\n",
            "  adding: stylegan2-db/01003.png (deflated 0%)\n",
            "  adding: stylegan2-db/01110.png (deflated 0%)\n",
            "  adding: stylegan2-db/01239.png (deflated 0%)\n",
            "  adding: stylegan2-db/01680.png (deflated 0%)\n",
            "  adding: stylegan2-db/02008.png (deflated 0%)\n",
            "  adding: stylegan2-db/00281.png (deflated 0%)\n",
            "  adding: stylegan2-db/00587.png (deflated 0%)\n",
            "  adding: stylegan2-db/01398.png (deflated 0%)\n",
            "  adding: stylegan2-db/00728.png (deflated 0%)\n",
            "  adding: stylegan2-db/00544.png (deflated 0%)\n",
            "  adding: stylegan2-db/00009.png (deflated 0%)\n",
            "  adding: stylegan2-db/00577.png (deflated 0%)\n",
            "  adding: stylegan2-db/02005.png (deflated 0%)\n",
            "  adding: stylegan2-db/01747.png (deflated 0%)\n",
            "  adding: stylegan2-db/00919.png (deflated 0%)\n",
            "  adding: stylegan2-db/00191.png (deflated 0%)\n",
            "  adding: stylegan2-db/01194.png (deflated 0%)\n",
            "  adding: stylegan2-db/01127.png (deflated 0%)\n",
            "  adding: stylegan2-db/00238.png (deflated 0%)\n",
            "  adding: stylegan2-db/00713.png (deflated 0%)\n",
            "  adding: stylegan2-db/01404.png (deflated 0%)\n",
            "  adding: stylegan2-db/00357.png (deflated 0%)\n",
            "  adding: stylegan2-db/00789.png (deflated 0%)\n",
            "  adding: stylegan2-db/00189.png (deflated 0%)\n",
            "  adding: stylegan2-db/00996.png (deflated 0%)\n",
            "  adding: stylegan2-db/01869.png (deflated 0%)\n",
            "  adding: stylegan2-db/01613.png (deflated 0%)\n",
            "  adding: stylegan2-db/01377.png (deflated 0%)\n",
            "  adding: stylegan2-db/01617.png (deflated 0%)\n",
            "  adding: stylegan2-db/00997.png (deflated 0%)\n",
            "  adding: stylegan2-db/00979.png (deflated 0%)\n",
            "  adding: stylegan2-db/01985.png (deflated 0%)\n",
            "  adding: stylegan2-db/00262.png (deflated 0%)\n",
            "  adding: stylegan2-db/00957.png (deflated 0%)\n",
            "  adding: stylegan2-db/01776.png (deflated 0%)\n",
            "  adding: stylegan2-db/01624.png (deflated 0%)\n",
            "  adding: stylegan2-db/01853.png (deflated 0%)\n",
            "  adding: stylegan2-db/00818.png (deflated 0%)\n",
            "  adding: stylegan2-db/02034.png (deflated 0%)\n",
            "  adding: stylegan2-db/01228.png (deflated 0%)\n",
            "  adding: stylegan2-db/01815.png (deflated 0%)\n",
            "  adding: stylegan2-db/00783.png (deflated 0%)\n",
            "  adding: stylegan2-db/01772.png (deflated 0%)\n",
            "  adding: stylegan2-db/01187.png (deflated 0%)\n",
            "  adding: stylegan2-db/01403.png (deflated 0%)\n",
            "  adding: stylegan2-db/00770.png (deflated 0%)\n",
            "  adding: stylegan2-db/00941.png (deflated 0%)\n",
            "  adding: stylegan2-db/01714.png (deflated 0%)\n",
            "  adding: stylegan2-db/01238.png (deflated 0%)\n",
            "  adding: stylegan2-db/01081.png (deflated 0%)\n",
            "  adding: stylegan2-db/01304.png (deflated 0%)\n",
            "  adding: stylegan2-db/00178.png (deflated 0%)\n",
            "  adding: stylegan2-db/00415.png (deflated 0%)\n",
            "  adding: stylegan2-db/01062.png (deflated 0%)\n",
            "  adding: stylegan2-db/00317.png (deflated 0%)\n",
            "  adding: stylegan2-db/00707.png (deflated 0%)\n",
            "  adding: stylegan2-db/01292.png (deflated 0%)\n",
            "  adding: stylegan2-db/00796.png (deflated 0%)\n",
            "  adding: stylegan2-db/01519.png (deflated 0%)\n",
            "  adding: stylegan2-db/01517.png (deflated 0%)\n",
            "  adding: stylegan2-db/00412.png (deflated 0%)\n",
            "  adding: stylegan2-db/01091.png (deflated 0%)\n",
            "  adding: stylegan2-db/00653.png (deflated 0%)\n",
            "  adding: stylegan2-db/00717.png (deflated 0%)\n",
            "  adding: stylegan2-db/01944.png (deflated 0%)\n",
            "  adding: stylegan2-db/01005.png (deflated 0%)\n",
            "  adding: stylegan2-db/00710.png (deflated 0%)\n",
            "  adding: stylegan2-db/00098.png (deflated 0%)\n",
            "  adding: stylegan2-db/00410.png (deflated 0%)\n",
            "  adding: stylegan2-db/00785.png (deflated 0%)\n",
            "  adding: stylegan2-db/00927.png (deflated 0%)\n",
            "  adding: stylegan2-db/00489.png (deflated 0%)\n",
            "  adding: stylegan2-db/00876.png (deflated 0%)\n",
            "  adding: stylegan2-db/00569.png (deflated 0%)\n",
            "  adding: stylegan2-db/00519.png (deflated 0%)\n",
            "  adding: stylegan2-db/00131.png (deflated 0%)\n",
            "  adding: stylegan2-db/00915.png (deflated 0%)\n",
            "  adding: stylegan2-db/00802.png (deflated 0%)\n",
            "  adding: stylegan2-db/00897.png (deflated 0%)\n",
            "  adding: stylegan2-db/00983.png (deflated 0%)\n",
            "  adding: stylegan2-db/00095.png (deflated 0%)\n",
            "  adding: stylegan2-db/00806.png (deflated 0%)\n",
            "  adding: stylegan2-db/01912.png (deflated 0%)\n",
            "  adding: stylegan2-db/01323.png (deflated 0%)\n",
            "  adding: stylegan2-db/01718.png (deflated 0%)\n",
            "  adding: stylegan2-db/00163.png (deflated 0%)\n",
            "  adding: stylegan2-db/01066.png (deflated 0%)\n",
            "  adding: stylegan2-db/00483.png (deflated 0%)\n",
            "  adding: stylegan2-db/01125.png (deflated 0%)\n",
            "  adding: stylegan2-db/00125.png (deflated 0%)\n",
            "  adding: stylegan2-db/00651.png (deflated 0%)\n",
            "  adding: stylegan2-db/01976.png (deflated 0%)\n",
            "  adding: stylegan2-db/01357.png (deflated 0%)\n",
            "  adding: stylegan2-db/00404.png (deflated 0%)\n",
            "  adding: stylegan2-db/02043.png (deflated 0%)\n",
            "  adding: stylegan2-db/00703.png (deflated 0%)\n",
            "  adding: stylegan2-db/01946.png (deflated 0%)\n",
            "  adding: stylegan2-db/00906.png (deflated 0%)\n",
            "  adding: stylegan2-db/00488.png (deflated 0%)\n",
            "  adding: stylegan2-db/00830.png (deflated 0%)\n",
            "  adding: stylegan2-db/00043.png (deflated 0%)\n",
            "  adding: stylegan2-db/01205.png (deflated 0%)\n",
            "  adding: stylegan2-db/00290.png (deflated 0%)\n",
            "  adding: stylegan2-db/00053.png (deflated 0%)\n",
            "  adding: stylegan2-db/01183.png (deflated 0%)\n",
            "  adding: stylegan2-db/01693.png (deflated 0%)\n",
            "  adding: stylegan2-db/01721.png (deflated 0%)\n",
            "  adding: stylegan2-db/00433.png (deflated 0%)\n",
            "  adding: stylegan2-db/00035.png (deflated 0%)\n",
            "  adding: stylegan2-db/01553.png (deflated 0%)\n",
            "  adding: stylegan2-db/01628.png (deflated 0%)\n",
            "  adding: stylegan2-db/01250.png (deflated 0%)\n",
            "  adding: stylegan2-db/00995.png (deflated 0%)\n",
            "  adding: stylegan2-db/00720.png (deflated 0%)\n",
            "  adding: stylegan2-db/00969.png (deflated 0%)\n",
            "  adding: stylegan2-db/02042.png (deflated 0%)\n",
            "  adding: stylegan2-db/01900.png (deflated 0%)\n",
            "  adding: stylegan2-db/01218.png (deflated 0%)\n",
            "  adding: stylegan2-db/01332.png (deflated 0%)\n",
            "  adding: stylegan2-db/01092.png (deflated 0%)\n",
            "  adding: stylegan2-db/01154.png (deflated 0%)\n",
            "  adding: stylegan2-db/00212.png (deflated 0%)\n",
            "  adding: stylegan2-db/01162.png (deflated 0%)\n",
            "  adding: stylegan2-db/00347.png (deflated 0%)\n",
            "  adding: stylegan2-db/00001.png (deflated 0%)\n",
            "  adding: stylegan2-db/00889.png (deflated 0%)\n",
            "  adding: stylegan2-db/01203.png (deflated 0%)\n",
            "  adding: stylegan2-db/01067.png (deflated 0%)\n",
            "  adding: stylegan2-db/00440.png (deflated 0%)\n",
            "  adding: stylegan2-db/00591.png (deflated 0%)\n",
            "  adding: stylegan2-db/01863.png (deflated 0%)\n",
            "  adding: stylegan2-db/00774.png (deflated 0%)\n",
            "  adding: stylegan2-db/00235.png (deflated 0%)\n",
            "  adding: stylegan2-db/01787.png (deflated 0%)\n",
            "  adding: stylegan2-db/01677.png (deflated 0%)\n",
            "  adding: stylegan2-db/01472.png (deflated 0%)\n",
            "  adding: stylegan2-db/01580.png (deflated 0%)\n",
            "  adding: stylegan2-db/00531.png (deflated 0%)\n",
            "  adding: stylegan2-db/00960.png (deflated 0%)\n",
            "  adding: stylegan2-db/01434.png (deflated 0%)\n",
            "  adding: stylegan2-db/01994.png (deflated 0%)\n",
            "  adding: stylegan2-db/00685.png (deflated 0%)\n",
            "  adding: stylegan2-db/01615.png (deflated 0%)\n",
            "  adding: stylegan2-db/01352.png (deflated 0%)\n",
            "  adding: stylegan2-db/01947.png (deflated 0%)\n",
            "  adding: stylegan2-db/00324.png (deflated 0%)\n",
            "  adding: stylegan2-db/00768.png (deflated 0%)\n",
            "  adding: stylegan2-db/00149.png (deflated 0%)\n",
            "  adding: stylegan2-db/00943.png (deflated 0%)\n",
            "  adding: stylegan2-db/01046.png (deflated 0%)\n",
            "  adding: stylegan2-db/00338.png (deflated 0%)\n",
            "  adding: stylegan2-db/01422.png (deflated 0%)\n",
            "  adding: stylegan2-db/00991.png (deflated 0%)\n",
            "  adding: stylegan2-db/01313.png (deflated 0%)\n",
            "  adding: stylegan2-db/01388.png (deflated 0%)\n",
            "  adding: stylegan2-db/00452.png (deflated 0%)\n",
            "  adding: stylegan2-db/00432.png (deflated 0%)\n",
            "  adding: stylegan2-db/00030.png (deflated 0%)\n",
            "  adding: stylegan2-db/00807.png (deflated 0%)\n",
            "  adding: stylegan2-db/01542.png (deflated 0%)\n",
            "  adding: stylegan2-db/01565.png (deflated 0%)\n",
            "  adding: stylegan2-db/01188.png (deflated 0%)\n",
            "  adding: stylegan2-db/01143.png (deflated 0%)\n",
            "  adding: stylegan2-db/01177.png (deflated 0%)\n",
            "  adding: stylegan2-db/00434.png (deflated 0%)\n",
            "  adding: stylegan2-db/00156.png (deflated 0%)\n",
            "  adding: stylegan2-db/01241.png (deflated 0%)\n",
            "  adding: stylegan2-db/00119.png (deflated 0%)\n",
            "  adding: stylegan2-db/01653.png (deflated 0%)\n",
            "  adding: stylegan2-db/01139.png (deflated 0%)\n",
            "  adding: stylegan2-db/01981.png (deflated 0%)\n",
            "  adding: stylegan2-db/01296.png (deflated 0%)\n",
            "  adding: stylegan2-db/01813.png (deflated 0%)\n",
            "  adding: stylegan2-db/02018.png (deflated 0%)\n",
            "  adding: stylegan2-db/01190.png (deflated 0%)\n",
            "  adding: stylegan2-db/01097.png (deflated 0%)\n",
            "  adding: stylegan2-db/00226.png (deflated 0%)\n",
            "  adding: stylegan2-db/01948.png (deflated 0%)\n",
            "  adding: stylegan2-db/00522.png (deflated 0%)\n",
            "  adding: stylegan2-db/01888.png (deflated 0%)\n",
            "  adding: stylegan2-db/00841.png (deflated 0%)\n",
            "  adding: stylegan2-db/01578.png (deflated 0%)\n",
            "  adding: stylegan2-db/00875.png (deflated 0%)\n",
            "  adding: stylegan2-db/01072.png (deflated 0%)\n",
            "  adding: stylegan2-db/01903.png (deflated 0%)\n",
            "  adding: stylegan2-db/01316.png (deflated 0%)\n",
            "  adding: stylegan2-db/01216.png (deflated 0%)\n",
            "  adding: stylegan2-db/00811.png (deflated 0%)\n",
            "  adding: stylegan2-db/01405.png (deflated 0%)\n",
            "  adding: stylegan2-db/01666.png (deflated 0%)\n",
            "  adding: stylegan2-db/01697.png (deflated 0%)\n",
            "  adding: stylegan2-db/01965.png (deflated 0%)\n",
            "  adding: stylegan2-db/01623.png (deflated 0%)\n",
            "  adding: stylegan2-db/00533.png (deflated 0%)\n",
            "  adding: stylegan2-db/01345.png (deflated 0%)\n",
            "  adding: stylegan2-db/01636.png (deflated 0%)\n",
            "  adding: stylegan2-db/00952.png (deflated 0%)\n",
            "  adding: stylegan2-db/00564.png (deflated 0%)\n",
            "  adding: stylegan2-db/00320.png (deflated 0%)\n",
            "  adding: stylegan2-db/01691.png (deflated 0%)\n",
            "  adding: stylegan2-db/00108.png (deflated 0%)\n",
            "  adding: stylegan2-db/01093.png (deflated 0%)\n",
            "  adding: stylegan2-db/01560.png (deflated 0%)\n",
            "  adding: stylegan2-db/01727.png (deflated 0%)\n",
            "  adding: stylegan2-db/01358.png (deflated 0%)\n",
            "  adding: stylegan2-db/00078.png (deflated 0%)\n",
            "  adding: stylegan2-db/01245.png (deflated 0%)\n",
            "  adding: stylegan2-db/01681.png (deflated 0%)\n",
            "  adding: stylegan2-db/00568.png (deflated 0%)\n",
            "  adding: stylegan2-db/00121.png (deflated 0%)\n",
            "  adding: stylegan2-db/00223.png (deflated 0%)\n",
            "  adding: stylegan2-db/02019.png (deflated 0%)\n",
            "  adding: stylegan2-db/01415.png (deflated 0%)\n",
            "  adding: stylegan2-db/00521.png (deflated 0%)\n",
            "  adding: stylegan2-db/00649.png (deflated 0%)\n",
            "  adding: stylegan2-db/01818.png (deflated 0%)\n",
            "  adding: stylegan2-db/01070.png (deflated 0%)\n",
            "  adding: stylegan2-db/00175.png (deflated 0%)\n",
            "  adding: stylegan2-db/00442.png (deflated 0%)\n",
            "  adding: stylegan2-db/00070.png (deflated 0%)\n",
            "  adding: stylegan2-db/01181.png (deflated 0%)\n",
            "  adding: stylegan2-db/01914.png (deflated 0%)\n",
            "  adding: stylegan2-db/01201.png (deflated 0%)\n",
            "  adding: stylegan2-db/00229.png (deflated 0%)\n",
            "  adding: stylegan2-db/00038.png (deflated 0%)\n",
            "  adding: stylegan2-db/01182.png (deflated 0%)\n",
            "  adding: stylegan2-db/00202.png (deflated 0%)\n",
            "  adding: stylegan2-db/00938.png (deflated 0%)\n",
            "  adding: stylegan2-db/01488.png (deflated 0%)\n",
            "  adding: stylegan2-db/00394.png (deflated 0%)\n",
            "  adding: stylegan2-db/01902.png (deflated 0%)\n",
            "  adding: stylegan2-db/00076.png (deflated 0%)\n",
            "  adding: stylegan2-db/00641.png (deflated 0%)\n",
            "  adding: stylegan2-db/01817.png (deflated 0%)\n",
            "  adding: stylegan2-db/01436.png (deflated 0%)\n",
            "  adding: stylegan2-db/00314.png (deflated 0%)\n",
            "  adding: stylegan2-db/00794.png (deflated 0%)\n",
            "  adding: stylegan2-db/00084.png (deflated 0%)\n",
            "  adding: stylegan2-db/00890.png (deflated 0%)\n",
            "  adding: stylegan2-db/00134.png (deflated 0%)\n",
            "  adding: stylegan2-db/00274.png (deflated 0%)\n",
            "  adding: stylegan2-db/01963.png (deflated 0%)\n",
            "  adding: stylegan2-db/00961.png (deflated 0%)\n",
            "  adding: stylegan2-db/00908.png (deflated 0%)\n",
            "  adding: stylegan2-db/01379.png (deflated 0%)\n",
            "  adding: stylegan2-db/00925.png (deflated 0%)\n",
            "  adding: stylegan2-db/01247.png (deflated 0%)\n",
            "  adding: stylegan2-db/00884.png (deflated 0%)\n",
            "  adding: stylegan2-db/01178.png (deflated 0%)\n",
            "  adding: stylegan2-db/00062.png (deflated 0%)\n",
            "  adding: stylegan2-db/00673.png (deflated 0%)\n",
            "  adding: stylegan2-db/02016.png (deflated 0%)\n",
            "  adding: stylegan2-db/00472.png (deflated 0%)\n",
            "  adding: stylegan2-db/00987.png (deflated 0%)\n",
            "  adding: stylegan2-db/02027.png (deflated 0%)\n",
            "  adding: stylegan2-db/00708.png (deflated 0%)\n",
            "  adding: stylegan2-db/01191.png (deflated 0%)\n",
            "  adding: stylegan2-db/01012.png (deflated 0%)\n",
            "  adding: stylegan2-db/00738.png (deflated 0%)\n",
            "  adding: stylegan2-db/00168.png (deflated 0%)\n",
            "  adding: stylegan2-db/01308.png (deflated 0%)\n",
            "  adding: stylegan2-db/01716.png (deflated 0%)\n",
            "  adding: stylegan2-db/00545.png (deflated 0%)\n",
            "  adding: stylegan2-db/00589.png (deflated 0%)\n",
            "  adding: stylegan2-db/01153.png (deflated 0%)\n",
            "  adding: stylegan2-db/00871.png (deflated 0%)\n",
            "  adding: stylegan2-db/00866.png (deflated 0%)\n",
            "  adding: stylegan2-db/00376.png (deflated 0%)\n",
            "  adding: stylegan2-db/00199.png (deflated 0%)\n",
            "  adding: stylegan2-db/00847.png (deflated 0%)\n",
            "  adding: stylegan2-db/01276.png (deflated 0%)\n",
            "  adding: stylegan2-db/01465.png (deflated 0%)\n",
            "  adding: stylegan2-db/00787.png (deflated 0%)\n",
            "  adding: stylegan2-db/01380.png (deflated 0%)\n",
            "  adding: stylegan2-db/01298.png (deflated 0%)\n",
            "  adding: stylegan2-db/01533.png (deflated 0%)\n",
            "  adding: stylegan2-db/01483.png (deflated 0%)\n",
            "  adding: stylegan2-db/00980.png (deflated 0%)\n",
            "  adding: stylegan2-db/00286.png (deflated 0%)\n",
            "  adding: stylegan2-db/00092.png (deflated 0%)\n",
            "  adding: stylegan2-db/01402.png (deflated 0%)\n",
            "  adding: stylegan2-db/00553.png (deflated 0%)\n",
            "  adding: stylegan2-db/01425.png (deflated 0%)\n",
            "  adding: stylegan2-db/00476.png (deflated 0%)\n",
            "  adding: stylegan2-db/02033.png (deflated 0%)\n",
            "  adding: stylegan2-db/00305.png (deflated 0%)\n",
            "  adding: stylegan2-db/00654.png (deflated 0%)\n",
            "  adding: stylegan2-db/00947.png (deflated 0%)\n",
            "  adding: stylegan2-db/00150.png (deflated 0%)\n",
            "  adding: stylegan2-db/01221.png (deflated 0%)\n",
            "  adding: stylegan2-db/01461.png (deflated 0%)\n",
            "  adding: stylegan2-db/00048.png (deflated 0%)\n",
            "  adding: stylegan2-db/00055.png (deflated 0%)\n",
            "  adding: stylegan2-db/00965.png (deflated 0%)\n",
            "  adding: stylegan2-db/00387.png (deflated 0%)\n",
            "  adding: stylegan2-db/00222.png (deflated 0%)\n",
            "  adding: stylegan2-db/01724.png (deflated 0%)\n",
            "  adding: stylegan2-db/00592.png (deflated 0%)\n",
            "  adding: stylegan2-db/01609.png (deflated 0%)\n",
            "  adding: stylegan2-db/00316.png (deflated 0%)\n",
            "  adding: stylegan2-db/00336.png (deflated 0%)\n",
            "  adding: stylegan2-db/00990.png (deflated 0%)\n",
            "  adding: stylegan2-db/00518.png (deflated 0%)\n",
            "  adding: stylegan2-db/00283.png (deflated 0%)\n",
            "  adding: stylegan2-db/00595.png (deflated 0%)\n",
            "  adding: stylegan2-db/01891.png (deflated 0%)\n",
            "  adding: stylegan2-db/01108.png (deflated 0%)\n",
            "  adding: stylegan2-db/00327.png (deflated 0%)\n",
            "  adding: stylegan2-db/01359.png (deflated 0%)\n",
            "  adding: stylegan2-db/01801.png (deflated 0%)\n",
            "  adding: stylegan2-db/01678.png (deflated 0%)\n",
            "  adding: stylegan2-db/01885.png (deflated 0%)\n",
            "  adding: stylegan2-db/01300.png (deflated 0%)\n",
            "  adding: stylegan2-db/01481.png (deflated 0%)\n",
            "  adding: stylegan2-db/01455.png (deflated 0%)\n",
            "  adding: stylegan2-db/01521.png (deflated 0%)\n",
            "  adding: stylegan2-db/00627.png (deflated 0%)\n",
            "  adding: stylegan2-db/01423.png (deflated 0%)\n",
            "  adding: stylegan2-db/00067.png (deflated 0%)\n",
            "  adding: stylegan2-db/00386.png (deflated 0%)\n",
            "  adding: stylegan2-db/00594.png (deflated 0%)\n",
            "  adding: stylegan2-db/01444.png (deflated 0%)\n",
            "  adding: stylegan2-db/01309.png (deflated 0%)\n",
            "  adding: stylegan2-db/01184.png (deflated 0%)\n",
            "  adding: stylegan2-db/01757.png (deflated 0%)\n",
            "  adding: stylegan2-db/01859.png (deflated 0%)\n",
            "  adding: stylegan2-db/00277.png (deflated 0%)\n",
            "  adding: stylegan2-db/00741.png (deflated 0%)\n",
            "  adding: stylegan2-db/00610.png (deflated 0%)\n",
            "  adding: stylegan2-db/01033.png (deflated 0%)\n",
            "  adding: stylegan2-db/01421.png (deflated 0%)\n",
            "  adding: stylegan2-db/00883.png (deflated 0%)\n",
            "  adding: stylegan2-db/00403.png (deflated 0%)\n",
            "  adding: stylegan2-db/01562.png (deflated 0%)\n",
            "  adding: stylegan2-db/01395.png (deflated 0%)\n",
            "  adding: stylegan2-db/00754.png (deflated 0%)\n",
            "  adding: stylegan2-db/00210.png (deflated 0%)\n",
            "  adding: stylegan2-db/00383.png (deflated 0%)\n",
            "  adding: stylegan2-db/02041.png (deflated 0%)\n",
            "  adding: stylegan2-db/01699.png (deflated 0%)\n",
            "  adding: stylegan2-db/00077.png (deflated 0%)\n",
            "  adding: stylegan2-db/00220.png (deflated 0%)\n",
            "  adding: stylegan2-db/00164.png (deflated 0%)\n",
            "  adding: stylegan2-db/01646.png (deflated 0%)\n",
            "  adding: stylegan2-db/00945.png (deflated 0%)\n",
            "  adding: stylegan2-db/00624.png (deflated 0%)\n",
            "  adding: stylegan2-db/00700.png (deflated 0%)\n",
            "  adding: stylegan2-db/00615.png (deflated 0%)\n",
            "  adding: stylegan2-db/00228.png (deflated 0%)\n",
            "  adding: stylegan2-db/01765.png (deflated 0%)\n",
            "  adding: stylegan2-db/00251.png (deflated 0%)\n",
            "  adding: stylegan2-db/00950.png (deflated 0%)\n",
            "  adding: stylegan2-db/00319.png (deflated 0%)\n",
            "  adding: stylegan2-db/01382.png (deflated 0%)\n",
            "  adding: stylegan2-db/00911.png (deflated 0%)\n",
            "  adding: stylegan2-db/01025.png (deflated 0%)\n",
            "  adding: stylegan2-db/01647.png (deflated 0%)\n",
            "  adding: stylegan2-db/00723.png (deflated 0%)\n",
            "  adding: stylegan2-db/00399.png (deflated 0%)\n",
            "  adding: stylegan2-db/00659.png (deflated 0%)\n",
            "  adding: stylegan2-db/01643.png (deflated 0%)\n",
            "  adding: stylegan2-db/00934.png (deflated 0%)\n",
            "  adding: stylegan2-db/00129.png (deflated 0%)\n",
            "  adding: stylegan2-db/01363.png (deflated 0%)\n",
            "  adding: stylegan2-db/01034.png (deflated 0%)\n",
            "  adding: stylegan2-db/01267.png (deflated 0%)\n",
            "  adding: stylegan2-db/01222.png (deflated 0%)\n",
            "  adding: stylegan2-db/01659.png (deflated 0%)\n",
            "  adding: stylegan2-db/01949.png (deflated 0%)\n",
            "  adding: stylegan2-db/01511.png (deflated 0%)\n",
            "  adding: stylegan2-db/01836.png (deflated 0%)\n",
            "  adding: stylegan2-db/00862.png (deflated 0%)\n",
            "  adding: stylegan2-db/01840.png (deflated 0%)\n",
            "  adding: stylegan2-db/00949.png (deflated 0%)\n",
            "  adding: stylegan2-db/01792.png (deflated 0%)\n",
            "  adding: stylegan2-db/00622.png (deflated 0%)\n",
            "  adding: stylegan2-db/00401.png (deflated 0%)\n",
            "  adding: stylegan2-db/00272.png (deflated 0%)\n",
            "  adding: stylegan2-db/00352.png (deflated 0%)\n",
            "  adding: stylegan2-db/01605.png (deflated 0%)\n",
            "  adding: stylegan2-db/01449.png (deflated 0%)\n",
            "  adding: stylegan2-db/00598.png (deflated 0%)\n",
            "  adding: stylegan2-db/01768.png (deflated 0%)\n",
            "  adding: stylegan2-db/00907.png (deflated 0%)\n",
            "  adding: stylegan2-db/01281.png (deflated 0%)\n",
            "  adding: stylegan2-db/01712.png (deflated 0%)\n",
            "  adding: stylegan2-db/00181.png (deflated 0%)\n",
            "  adding: stylegan2-db/00209.png (deflated 0%)\n",
            "  adding: stylegan2-db/00868.png (deflated 0%)\n",
            "  adding: stylegan2-db/00663.png (deflated 0%)\n",
            "  adding: stylegan2-db/01932.png (deflated 0%)\n",
            "  adding: stylegan2-db/01806.png (deflated 0%)\n",
            "  adding: stylegan2-db/01334.png (deflated 0%)\n",
            "  adding: stylegan2-db/01378.png (deflated 0%)\n",
            "  adding: stylegan2-db/01957.png (deflated 0%)\n",
            "  adding: stylegan2-db/01561.png (deflated 0%)\n",
            "  adding: stylegan2-db/01418.png (deflated 0%)\n",
            "  adding: stylegan2-db/01340.png (deflated 0%)\n",
            "  adding: stylegan2-db/00143.png (deflated 0%)\n",
            "  adding: stylegan2-db/01180.png (deflated 0%)\n",
            "  adding: stylegan2-db/00299.png (deflated 0%)\n",
            "  adding: stylegan2-db/00863.png (deflated 0%)\n",
            "  adding: stylegan2-db/01980.png (deflated 0%)\n",
            "  adding: stylegan2-db/00916.png (deflated 0%)\n",
            "  adding: stylegan2-db/00893.png (deflated 0%)\n",
            "  adding: stylegan2-db/01851.png (deflated 0%)\n",
            "  adding: stylegan2-db/00008.png (deflated 0%)\n",
            "  adding: stylegan2-db/01988.png (deflated 0%)\n",
            "  adding: stylegan2-db/00169.png (deflated 0%)\n",
            "  adding: stylegan2-db/01600.png (deflated 0%)\n",
            "  adding: stylegan2-db/00858.png (deflated 0%)\n",
            "  adding: stylegan2-db/01931.png (deflated 0%)\n",
            "  adding: stylegan2-db/01722.png (deflated 0%)\n",
            "  adding: stylegan2-db/00701.png (deflated 0%)\n",
            "  adding: stylegan2-db/01039.png (deflated 0%)\n",
            "  adding: stylegan2-db/00090.png (deflated 0%)\n",
            "  adding: stylegan2-db/00185.png (deflated 0%)\n",
            "  adding: stylegan2-db/01589.png (deflated 0%)\n",
            "  adding: stylegan2-db/01920.png (deflated 0%)\n",
            "  adding: stylegan2-db/02039.png (deflated 0%)\n",
            "  adding: stylegan2-db/00056.png (deflated 0%)\n",
            "  adding: stylegan2-db/01307.png (deflated 0%)\n",
            "  adding: stylegan2-db/01437.png (deflated 0%)\n",
            "  adding: stylegan2-db/00400.png (deflated 0%)\n",
            "  adding: stylegan2-db/00579.png (deflated 0%)\n",
            "  adding: stylegan2-db/00031.png (deflated 0%)\n",
            "  adding: stylegan2-db/01881.png (deflated 0%)\n",
            "  adding: stylegan2-db/01960.png (deflated 0%)\n",
            "  adding: stylegan2-db/00243.png (deflated 0%)\n",
            "  adding: stylegan2-db/00570.png (deflated 0%)\n",
            "  adding: stylegan2-db/00065.png (deflated 0%)\n",
            "  adding: stylegan2-db/01474.png (deflated 0%)\n",
            "  adding: stylegan2-db/00833.png (deflated 0%)\n",
            "  adding: stylegan2-db/01336.png (deflated 0%)\n",
            "  adding: stylegan2-db/00029.png (deflated 0%)\n",
            "  adding: stylegan2-db/00478.png (deflated 0%)\n",
            "  adding: stylegan2-db/01579.png (deflated 0%)\n",
            "  adding: stylegan2-db/00574.png (deflated 0%)\n",
            "  adding: stylegan2-db/00176.png (deflated 0%)\n",
            "  adding: stylegan2-db/00024.png (deflated 0%)\n",
            "  adding: stylegan2-db/01424.png (deflated 0%)\n",
            "  adding: stylegan2-db/01548.png (deflated 0%)\n",
            "  adding: stylegan2-db/00633.png (deflated 0%)\n",
            "  adding: stylegan2-db/00418.png (deflated 0%)\n",
            "  adding: stylegan2-db/00267.png (deflated 0%)\n",
            "  adding: stylegan2-db/01148.png (deflated 0%)\n",
            "  adding: stylegan2-db/01122.png (deflated 0%)\n",
            "  adding: stylegan2-db/00764.png (deflated 0%)\n",
            "  adding: stylegan2-db/00177.png (deflated 0%)\n",
            "  adding: stylegan2-db/02017.png (deflated 0%)\n",
            "  adding: stylegan2-db/01173.png (deflated 0%)\n",
            "  adding: stylegan2-db/01452.png (deflated 0%)\n",
            "  adding: stylegan2-db/00603.png (deflated 0%)\n",
            "  adding: stylegan2-db/01752.png (deflated 0%)\n",
            "  adding: stylegan2-db/01344.png (deflated 0%)\n",
            "  adding: stylegan2-db/00557.png (deflated 0%)\n",
            "  adding: stylegan2-db/01537.png (deflated 0%)\n",
            "  adding: stylegan2-db/01385.png (deflated 0%)\n",
            "  adding: stylegan2-db/00696.png (deflated 0%)\n",
            "  adding: stylegan2-db/00419.png (deflated 0%)\n",
            "  adding: stylegan2-db/01354.png (deflated 0%)\n",
            "  adding: stylegan2-db/01364.png (deflated 0%)\n",
            "  adding: stylegan2-db/00100.png (deflated 0%)\n",
            "  adding: stylegan2-db/01687.png (deflated 0%)\n",
            "  adding: stylegan2-db/00097.png (deflated 0%)\n",
            "  adding: stylegan2-db/01015.png (deflated 0%)\n",
            "  adding: stylegan2-db/00676.png (deflated 0%)\n",
            "  adding: stylegan2-db/01240.png (deflated 0%)\n",
            "  adding: stylegan2-db/00270.png (deflated 0%)\n",
            "  adding: stylegan2-db/00233.png (deflated 0%)\n",
            "  adding: stylegan2-db/01053.png (deflated 0%)\n",
            "  adding: stylegan2-db/01371.png (deflated 0%)\n",
            "  adding: stylegan2-db/01586.png (deflated 0%)\n",
            "  adding: stylegan2-db/01637.png (deflated 0%)\n",
            "  adding: stylegan2-db/01927.png (deflated 0%)\n",
            "  adding: stylegan2-db/00287.png (deflated 0%)\n",
            "  adding: stylegan2-db/01857.png (deflated 0%)\n",
            "  adding: stylegan2-db/00402.png (deflated 0%)\n",
            "  adding: stylegan2-db/01391.png (deflated 0%)\n",
            "  adding: stylegan2-db/01552.png (deflated 0%)\n",
            "  adding: stylegan2-db/01273.png (deflated 0%)\n",
            "  adding: stylegan2-db/00341.png (deflated 0%)\n",
            "  adding: stylegan2-db/01107.png (deflated 0%)\n",
            "  adding: stylegan2-db/00221.png (deflated 0%)\n",
            "  adding: stylegan2-db/00188.png (deflated 0%)\n",
            "  adding: stylegan2-db/01924.png (deflated 0%)\n",
            "  adding: stylegan2-db/00817.png (deflated 0%)\n",
            "  adding: stylegan2-db/02013.png (deflated 0%)\n",
            "  adding: stylegan2-db/01694.png (deflated 0%)\n",
            "  adding: stylegan2-db/00271.png (deflated 0%)\n",
            "  adding: stylegan2-db/01970.png (deflated 0%)\n",
            "  adding: stylegan2-db/01992.png (deflated 0%)\n",
            "  adding: stylegan2-db/01973.png (deflated 0%)\n",
            "  adding: stylegan2-db/01897.png (deflated 0%)\n",
            "  adding: stylegan2-db/01601.png (deflated 0%)\n",
            "  adding: stylegan2-db/00781.png (deflated 0%)\n",
            "  adding: stylegan2-db/01648.png (deflated 0%)\n",
            "  adding: stylegan2-db/02004.png (deflated 0%)\n",
            "  adding: stylegan2-db/00964.png (deflated 0%)\n",
            "  adding: stylegan2-db/00634.png (deflated 0%)\n",
            "  adding: stylegan2-db/00360.png (deflated 0%)\n",
            "  adding: stylegan2-db/00045.png (deflated 0%)\n",
            "  adding: stylegan2-db/00900.png (deflated 0%)\n",
            "  adding: stylegan2-db/01135.png (deflated 0%)\n",
            "  adding: stylegan2-db/01161.png (deflated 0%)\n",
            "  adding: stylegan2-db/01328.png (deflated 0%)\n",
            "  adding: stylegan2-db/01217.png (deflated 0%)\n",
            "  adding: stylegan2-db/01781.png (deflated 0%)\n",
            "  adding: stylegan2-db/01867.png (deflated 0%)\n",
            "  adding: stylegan2-db/00933.png (deflated 0%)\n",
            "  adding: stylegan2-db/01823.png (deflated 0%)\n",
            "  adding: stylegan2-db/00800.png (deflated 0%)\n",
            "  adding: stylegan2-db/00523.png (deflated 0%)\n",
            "  adding: stylegan2-db/00913.png (deflated 0%)\n",
            "  adding: stylegan2-db/00895.png (deflated 0%)\n",
            "  adding: stylegan2-db/00814.png (deflated 0%)\n",
            "  adding: stylegan2-db/00661.png (deflated 0%)\n",
            "  adding: stylegan2-db/02022.png (deflated 0%)\n",
            "  adding: stylegan2-db/00116.png (deflated 0%)\n",
            "  adding: stylegan2-db/01523.png (deflated 0%)\n",
            "  adding: stylegan2-db/00103.png (deflated 0%)\n",
            "  adding: stylegan2-db/02020.png (deflated 0%)\n",
            "  adding: stylegan2-db/00099.png (deflated 0%)\n",
            "  adding: stylegan2-db/01830.png (deflated 0%)\n",
            "  adding: stylegan2-db/00378.png (deflated 0%)\n",
            "  adding: stylegan2-db/01860.png (deflated 0%)\n",
            "  adding: stylegan2-db/00529.png (deflated 0%)\n",
            "  adding: stylegan2-db/00575.png (deflated 0%)\n",
            "  adding: stylegan2-db/01213.png (deflated 0%)\n",
            "  adding: stylegan2-db/00819.png (deflated 0%)\n",
            "  adding: stylegan2-db/00254.png (deflated 0%)\n",
            "  adding: stylegan2-db/00348.png (deflated 0%)\n",
            "  adding: stylegan2-db/00458.png (deflated 0%)\n",
            "  adding: stylegan2-db/01951.png (deflated 0%)\n",
            "  adding: stylegan2-db/00939.png (deflated 0%)\n",
            "  adding: stylegan2-db/00532.png (deflated 0%)\n",
            "  adding: stylegan2-db/00981.png (deflated 0%)\n",
            "  adding: stylegan2-db/01036.png (deflated 0%)\n",
            "  adding: stylegan2-db/00026.png (deflated 0%)\n",
            "  adding: stylegan2-db/01835.png (deflated 0%)\n",
            "  adding: stylegan2-db/00475.png (deflated 0%)\n",
            "  adding: stylegan2-db/01632.png (deflated 0%)\n",
            "  adding: stylegan2-db/00322.png (deflated 0%)\n",
            "  adding: stylegan2-db/00924.png (deflated 0%)\n",
            "  adding: stylegan2-db/01468.png (deflated 0%)\n",
            "  adding: stylegan2-db/00111.png (deflated 0%)\n",
            "  adding: stylegan2-db/01799.png (deflated 0%)\n",
            "  adding: stylegan2-db/01619.png (deflated 0%)\n",
            "  adding: stylegan2-db/00397.png (deflated 0%)\n",
            "  adding: stylegan2-db/01969.png (deflated 0%)\n",
            "  adding: stylegan2-db/01109.png (deflated 0%)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c94360be9a44ef9a7f9129731e67e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ece81f008934604ac7810f054cac90b",
              "IPY_MODEL_edc8f770484d4d4485fde4eb64ee98c2",
              "IPY_MODEL_7f2d2ba83b564483857265c48c8d1c8f"
            ],
            "layout": "IPY_MODEL_d96e2d1df44f408db5c7cbaae92cbe38"
          }
        },
        "3ece81f008934604ac7810f054cac90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b01514333e4894a15471071bced980",
            "placeholder": "​",
            "style": "IPY_MODEL_68ed7cb983d843b58a4152ba29225723",
            "value": "Downloading: 100%"
          }
        },
        "edc8f770484d4d4485fde4eb64ee98c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_730f22de44b44814bf76d2527232804a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ea253f4e0b341528830123b528fe8b5",
            "value": 231508
          }
        },
        "7f2d2ba83b564483857265c48c8d1c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf73982b62634479aaf38e9837deea6a",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbe50f5921346acba386f00ffd5e3fe",
            "value": " 226k/226k [00:00&lt;00:00, 6.81MB/s]"
          }
        },
        "d96e2d1df44f408db5c7cbaae92cbe38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b01514333e4894a15471071bced980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ed7cb983d843b58a4152ba29225723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "730f22de44b44814bf76d2527232804a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea253f4e0b341528830123b528fe8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf73982b62634479aaf38e9837deea6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbe50f5921346acba386f00ffd5e3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6606198120f04072840da5308cf2ca2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb48ae193975454895326d029e080274",
              "IPY_MODEL_95ea1267415d4d4c96ad52ac50489530",
              "IPY_MODEL_b802a0b506b040659e65c3a295df789b"
            ],
            "layout": "IPY_MODEL_75b91d6673214a9b8b4b426585aa282f"
          }
        },
        "eb48ae193975454895326d029e080274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f7288cb3ee34ce491ce2dfebe4e4549",
            "placeholder": "​",
            "style": "IPY_MODEL_9910724d208a449fac85118bbf7ab74f",
            "value": "Downloading: 100%"
          }
        },
        "95ea1267415d4d4c96ad52ac50489530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7182068d03b46adbe0275dd41836c3b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52a319263f214522835592b7b0d609c4",
            "value": 48
          }
        },
        "b802a0b506b040659e65c3a295df789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d243ba741b594afe87e605cabf570e0b",
            "placeholder": "​",
            "style": "IPY_MODEL_8586ab7011214b779322ef0955adb1da",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.37kB/s]"
          }
        },
        "75b91d6673214a9b8b4b426585aa282f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7288cb3ee34ce491ce2dfebe4e4549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9910724d208a449fac85118bbf7ab74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7182068d03b46adbe0275dd41836c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a319263f214522835592b7b0d609c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d243ba741b594afe87e605cabf570e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8586ab7011214b779322ef0955adb1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d03e96f859b474ebc302ebd5dd52ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87afe98a96eb4857b67884f0423553c5",
              "IPY_MODEL_99b4efa8045d49bebe53ce58e14ad0e8",
              "IPY_MODEL_82a55a9e87fe448d8ce7e05e8dcdebc9"
            ],
            "layout": "IPY_MODEL_1229bab150b544cd8e904608442783b1"
          }
        },
        "87afe98a96eb4857b67884f0423553c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40ea8a329c024007a8267cf20337a2e3",
            "placeholder": "​",
            "style": "IPY_MODEL_0d56180eedc948f7a616989a91de7f26",
            "value": "Downloading: 100%"
          }
        },
        "99b4efa8045d49bebe53ce58e14ad0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2c129c95b94c1fbf6c2bce855037df",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7570a9410ce249a9b05e29d65d5f3141",
            "value": 570
          }
        },
        "82a55a9e87fe448d8ce7e05e8dcdebc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c24b2b5f2804153b56fa6b3f4b59298",
            "placeholder": "​",
            "style": "IPY_MODEL_6dcc0d961a854397a7616a5a9a5bb155",
            "value": " 570/570 [00:00&lt;00:00, 51.3kB/s]"
          }
        },
        "1229bab150b544cd8e904608442783b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40ea8a329c024007a8267cf20337a2e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d56180eedc948f7a616989a91de7f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b2c129c95b94c1fbf6c2bce855037df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7570a9410ce249a9b05e29d65d5f3141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c24b2b5f2804153b56fa6b3f4b59298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dcc0d961a854397a7616a5a9a5bb155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf0aa96044584064b4202ab8d55e49ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b11a83aef5a64d1cbc61dbd30e0736e2",
              "IPY_MODEL_773307f59fa64bbcaf70da54ce56296a",
              "IPY_MODEL_aaf5e6c625e0413f8aebcbcf87cdd2e5"
            ],
            "layout": "IPY_MODEL_227dde3af3ed428b833aaa037a1d73af"
          }
        },
        "b11a83aef5a64d1cbc61dbd30e0736e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50d88fbb4ba4b89b3ed550a0cba0011",
            "placeholder": "​",
            "style": "IPY_MODEL_d019983df5a3446c88f6af58ef1745ea",
            "value": "100%"
          }
        },
        "773307f59fa64bbcaf70da54ce56296a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b71d8a307041c598961f34ecb5b052",
            "max": 2048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8cee7ef8dd14ff383f5cb53dd4d0ff6",
            "value": 2048
          }
        },
        "aaf5e6c625e0413f8aebcbcf87cdd2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9f9e508247457d88901314c78aa3f7",
            "placeholder": "​",
            "style": "IPY_MODEL_7060a7276111461ba60aae986c3beb5d",
            "value": " 2048/2048 [00:56&lt;00:00, 36.64it/s]"
          }
        },
        "227dde3af3ed428b833aaa037a1d73af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50d88fbb4ba4b89b3ed550a0cba0011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d019983df5a3446c88f6af58ef1745ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b71d8a307041c598961f34ecb5b052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cee7ef8dd14ff383f5cb53dd4d0ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb9f9e508247457d88901314c78aa3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7060a7276111461ba60aae986c3beb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b0fa72dd22433988ddda78bc36f2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2d1a881eeec46b88370797410dca11f",
              "IPY_MODEL_d9d9cc6480bb456d81d8b764b5caacf0",
              "IPY_MODEL_256afac74e6e4dc3870b22ae338717af"
            ],
            "layout": "IPY_MODEL_1da19676282649d1a97df9c182892312"
          }
        },
        "d2d1a881eeec46b88370797410dca11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e4839096a654f3299bdd60efe29d36c",
            "placeholder": "​",
            "style": "IPY_MODEL_063f87ec6fe34988bc2db11108e67fe8",
            "value": "100%"
          }
        },
        "d9d9cc6480bb456d81d8b764b5caacf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749bb6b5f15a4023ad0da3b8e5300448",
            "max": 2048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88d10d7b5d2447babac9621968ce34b0",
            "value": 2048
          }
        },
        "256afac74e6e4dc3870b22ae338717af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd477f3a90747fa95e7737c1f8bd566",
            "placeholder": "​",
            "style": "IPY_MODEL_82cdf5aeb98a4bf7b938f685f84f39dc",
            "value": " 2048/2048 [07:21&lt;00:00,  5.35it/s]"
          }
        },
        "1da19676282649d1a97df9c182892312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4839096a654f3299bdd60efe29d36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063f87ec6fe34988bc2db11108e67fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "749bb6b5f15a4023ad0da3b8e5300448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d10d7b5d2447babac9621968ce34b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dd477f3a90747fa95e7737c1f8bd566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82cdf5aeb98a4bf7b938f685f84f39dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}